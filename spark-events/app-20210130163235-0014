{"Event":"SparkListenerLogStart","Spark Version":"3.0.1"}
{"Event":"SparkListenerBlockManagerAdded","Block Manager ID":{"Executor ID":"driver","Host":"192.168.11.7","Port":55058},"Maximum Memory":428762726,"Timestamp":1611991955584,"Maximum Onheap Memory":428762726,"Maximum Offheap Memory":0}
{"Event":"SparkListenerEnvironmentUpdate","JVM Information":{"Java Home":"/Library/Java/JavaVirtualMachines/adoptopenjdk-8.jdk/Contents/Home/jre","Java Version":"1.8.0_232 (AdoptOpenJDK)","Scala Version":"version 2.12.10"},"Spark Properties":{"spark.driver.host":"192.168.11.7","spark.history.fs.logDirectory":"./spark-events","spark.eventLog.enabled":"true","spark.driver.port":"55052","spark.jars":"file:/Users/kinsho/workspace/spark-3.0.1/workspace/sample-spark-scala/target/scala-2.12/simple-project_2.12-1.0.jar","spark.app.name":"logTransform","spark.scheduler.mode":"FIFO","spark.submit.pyFiles":"","spark.executor.id":"driver","spark.submit.deployMode":"client","spark.master":"spark://ST000000035:7077","spark.eventLog.dir":"./spark-events","spark.executor.cores":"2","spark.app.id":"app-20210130163235-0014"},"Hadoop Properties":{"yarn.resourcemanager.amlauncher.thread-count":"50","dfs.namenode.resource.check.interval":"5000","yarn.sharedcache.enabled":"false","fs.s3a.connection.maximum":"15","mapreduce.jobtracker.jobhistory.task.numberprogresssplits":"12","mapreduce.tasktracker.healthchecker.script.timeout":"600000","fs.s3a.impl":"org.apache.hadoop.fs.s3a.S3AFileSystem","yarn.app.mapreduce.am.scheduler.heartbeat.interval-ms":"1000","hadoop.http.authentication.kerberos.principal":"HTTP/_HOST@LOCALHOST","mapreduce.framework.name":"local","yarn.sharedcache.uploader.server.thread-count":"50","yarn.nodemanager.linux-container-executor.nonsecure-mode.user-pattern":"^[_.A-Za-z0-9][-@_.A-Za-z0-9]{0,255}?[$]?$","dfs.cachereport.intervalMsec":"10000","dfs.namenode.checkpoint.txns":"1000000","tfile.fs.output.buffer.size":"262144","yarn.app.mapreduce.am.job.task.listener.thread-count":"30","mapreduce.tasktracker.local.dir.minspacekill":"0","yarn.resourcemanager.webapp.cross-origin.enabled":"false","fs.AbstractFileSystem.ftp.impl":"org.apache.hadoop.fs.ftp.FtpFs","fs.s3.block.size":"67108864","dfs.client.domain.socket.data.traffic":"false","hadoop.registry.secure":"false","hadoop.hdfs.configuration.version":"1","dfs.bytes-per-checksum":"512","fs.s3a.fast.buffer.size":"1048576","fs.s3.buffer.dir":"${hadoop.tmp.dir}/s3","mapreduce.job.acl-view-job":" ","mapreduce.jobhistory.loadedjobs.cache.size":"5","mapreduce.jobtracker.persist.jobstatus.hours":"1","dfs.datanode.slow.io.warning.threshold.ms":"300","dfs.namenode.handler.count":"10","mapreduce.input.fileinputformat.split.minsize":"0","dfs.datanode.failed.volumes.tolerated":"0","yarn.resourcemanager.container.liveness-monitor.interval-ms":"600000","yarn.resourcemanager.client.thread-count":"50","io.seqfile.compress.blocksize":"1000000","mapreduce.tasktracker.http.threads":"40","dfs.namenode.retrycache.expirytime.millis":"600000","dfs.namenode.backup.address":"0.0.0.0:50100","yarn.sharedcache.checksum.algo.impl":"org.apache.hadoop.yarn.sharedcache.ChecksumSHA256Impl","dfs.datanode.data.dir":"file://${hadoop.tmp.dir}/dfs/data","dfs.datanode.shared.file.descriptor.paths":"/dev/shm,/tmp","dfs.replication":"3","mapreduce.jobtracker.jobhistory.block.size":"3145728","dfs.encrypt.data.transfer.cipher.key.bitlength":"128","mapreduce.reduce.shuffle.fetch.retry.interval-ms":"1000","dfs.secondary.namenode.kerberos.internal.spnego.principal":"${dfs.web.authentication.kerberos.principal}","mapreduce.task.profile.maps":"0-2","dfs.datanode.block-pinning.enabled":"false","yarn.nodemanager.admin-env":"MALLOC_ARENA_MAX=$MALLOC_ARENA_MAX","mapreduce.jobtracker.retiredjobs.cache.size":"1000","mapreduce.am.max-attempts":"2","fs.trash.checkpoint.interval":"0","dfs.namenode.checkpoint.check.period":"60","yarn.nodemanager.container-monitor.interval-ms":"3000","mapreduce.job.map.output.collector.class":"org.apache.hadoop.mapred.MapTask$MapOutputBuffer","hadoop.http.authentication.signature.secret.file":"*********(redacted)","hadoop.jetty.logs.serve.aliases":"true","yarn.timeline-service.handler-thread-count":"10","yarn.resourcemanager.max-completed-applications":"10000","mapreduce.map.skip.proc.count.autoincr":"true","yarn.resourcemanager.system-metrics-publisher.enabled":"false","yarn.sharedcache.webapp.address":"0.0.0.0:8788","yarn.sharedcache.nm.uploader.replication.factor":"10","hadoop.security.groups.negative-cache.secs":"30","yarn.app.mapreduce.task.container.log.backups":"0","ipc.client.fallback-to-simple-auth-allowed":"false","dfs.namenode.fs-limits.max-component-length":"255","mapreduce.tasktracker.taskcontroller":"org.apache.hadoop.mapred.DefaultTaskController","yarn.client.failover-proxy-provider":"org.apache.hadoop.yarn.client.ConfiguredRMFailoverProxyProvider","yarn.timeline-service.http-authentication.simple.anonymous.allowed":"true","ha.health-monitor.check-interval.ms":"1000","dfs.namenode.top.window.num.buckets":"10","yarn.resourcemanager.store.class":"org.apache.hadoop.yarn.server.resourcemanager.recovery.FileSystemRMStateStore","yarn.app.mapreduce.am.hard-kill-timeout-ms":"10000","dfs.datanode.block.id.layout.upgrade.threads":"12","mapreduce.jobtracker.tasktracker.maxblacklists":"4","yarn.nodemanager.docker-container-executor.exec-name":"/usr/bin/docker","yarn.resourcemanager.nodemanagers.heartbeat-interval-ms":"1000","mapred.child.java.opts":"-Xmx200m","hadoop.common.configuration.version":"0.23.0","yarn.nodemanager.remote-app-log-dir-suffix":"logs","yarn.nodemanager.windows-container.cpu-limit.enabled":"false","dfs.namenode.decommission.max.concurrent.tracked.nodes":"100","file.blocksize":"67108864","hadoop.registry.zk.retry.ceiling.ms":"60000","yarn.sharedcache.store.in-memory.initial-delay-mins":"10","mapreduce.jobhistory.principal":"jhs/_HOST@REALM.TLD","dfs.client.read.shortcircuit.skip.checksum":"false","mapreduce.task.profile.reduces":"0-2","dfs.datanode.address":"0.0.0.0:50010","dfs.https.server.keystore.resource":"ssl-server.xml","yarn.timeline-service.webapp.https.address":"${yarn.timeline-service.hostname}:8190","yarn.resourcemanager.scheduler.address":"${yarn.resourcemanager.hostname}:8030","mapreduce.task.timeout":"600000","yarn.sharedcache.client-server.thread-count":"50","hadoop.security.crypto.cipher.suite":"AES/CTR/NoPadding","yarn.resourcemanager.connect.max-wait.ms":"900000","fs.defaultFS":"file:///","fs.har.impl.disable.cache":"true","io.compression.codec.bzip2.library":"system-native","dfs.namenode.audit.loggers":"default","dfs.block.access.key.update.interval":"600","mapreduce.shuffle.connection-keep-alive.timeout":"5","yarn.resourcemanager.webapp.https.address":"${yarn.resourcemanager.hostname}:8090","dfs.namenode.max.objects":"0","mapreduce.jobhistory.address":"0.0.0.0:10020","yarn.nodemanager.address":"${yarn.nodemanager.hostname}:0","mapreduce.task.combine.progress.records":"10000","yarn.resourcemanager.am.max-attempts":"2","yarn.nodemanager.linux-container-executor.cgroups.hierarchy":"/hadoop-yarn","dfs.client.mmap.cache.timeout.ms":"3600000","dfs.mover.max-no-move-interval":"60000","dfs.client.datanode-restart.timeout":"30","dfs.datanode.drop.cache.behind.reads":"false","ipc.server.log.slow.rpc":"false","yarn.nodemanager.webapp.cross-origin.enabled":"false","dfs.namenode.read-lock-reporting-threshold-ms":"5000","yarn.app.mapreduce.am.job.committer.cancel-timeout":"60000","dfs.namenode.checkpoint.edits.dir":"${dfs.namenode.checkpoint.dir}","dfs.balancer.block-move.timeout":"0","dfs.client.block.write.replace-datanode-on-failure.enable":"true","ftp.bytes-per-checksum":"512","yarn.nodemanager.resource.memory-mb":"8192","dfs.heartbeat.interval":"3","mapreduce.jobhistory.joblist.cache.size":"20000","fs.ftp.host":"0.0.0.0","dfs.ha.tail-edits.period":"60","dfs.datanode.max.locked.memory":"0","dfs.datanode.scan.period.hours":"504","yarn.resourcemanager.fs.state-store.num-retries":"0","mapreduce.jobtracker.expire.trackers.interval":"600000","yarn.resourcemanager.nodemanager-connect-retries":"10","hadoop.security.kms.client.encrypted.key.cache.low-watermark":"0.3f","yarn.timeline-service.client.max-retries":"30","dfs.ha.fencing.ssh.connect-timeout":"30000","yarn.log-aggregation-enable":"false","mapreduce.reduce.markreset.buffer.percent":"0.0","fs.AbstractFileSystem.viewfs.impl":"org.apache.hadoop.fs.viewfs.ViewFs","dfs.namenode.edits.noeditlogchannelflush":"false","mapreduce.task.io.sort.factor":"10","mapreduce.tasktracker.outofband.heartbeat":"false","ha.failover-controller.new-active.rpc-timeout.ms":"60000","mapreduce.jobhistory.datestring.cache.size":"200000","mapreduce.job.acl-modify-job":" ","dfs.namenode.https-address":"0.0.0.0:50470","yarn.nodemanager.windows-container.memory-limit.enabled":"false","yarn.timeline-service.webapp.address":"${yarn.timeline-service.hostname}:8188","yarn.app.mapreduce.am.job.committer.commit-window":"10000","yarn.nodemanager.container-manager.thread-count":"20","yarn.timeline-service.ttl-enable":"true","mapreduce.jobhistory.recovery.store.fs.uri":"${hadoop.tmp.dir}/mapred/history/recoverystore","ha.zookeeper.session-timeout.ms":"5000","tfile.io.chunk.size":"1048576","mapreduce.job.speculative.slowtaskthreshold":"1.0","io.serializations":"org.apache.hadoop.io.serializer.WritableSerialization,org.apache.hadoop.io.serializer.avro.AvroSpecificSerialization,org.apache.hadoop.io.serializer.avro.AvroReflectSerialization","hadoop.security.group.mapping.ldap.directory.search.timeout":"10000","dfs.ha.automatic-failover.enabled":"false","dfs.namenode.decommission.interval":"30","fs.swift.impl":"org.apache.hadoop.fs.swift.snative.SwiftNativeFileSystem","yarn.nodemanager.local-cache.max-files-per-directory":"8192","dfs.datanode.handler.count":"10","hadoop.http.cross-origin.enabled":"false","dfs.namenode.xattrs.enabled":"true","dfs.namenode.safemode.threshold-pct":"0.999f","mapreduce.map.sort.spill.percent":"0.80","yarn.timeline-service.client.best-effort":"false","yarn.resourcemanager.webapp.delegation-token-auth-filter.enabled":"*********(redacted)","dfs.datanode.sync.behind.writes":"false","dfs.namenode.stale.datanode.interval":"30000","mapreduce.ifile.readahead":"true","yarn.timeline-service.leveldb-timeline-store.ttl-interval-ms":"300000","hadoop.security.kms.client.encrypted.key.cache.num.refill.threads":"2","yarn.resourcemanager.scheduler.class":"org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler","yarn.app.mapreduce.am.command-opts":"-Xmx1024m","dfs.journalnode.https-address":"0.0.0.0:8481","mapreduce.cluster.local.dir":"${hadoop.tmp.dir}/mapred/local","io.mapfile.bloom.error.rate":"0.005","dfs.user.home.dir.prefix":"/user","yarn.sharedcache.store.class":"org.apache.hadoop.yarn.server.sharedcachemanager.store.InMemorySCMStore","ha.failover-controller.graceful-fence.rpc-timeout.ms":"5000","ftp.replication":"3","mapreduce.jobtracker.persist.jobstatus.dir":"/jobtracker/jobsInfo","hadoop.security.uid.cache.secs":"14400","mapreduce.job.maxtaskfailures.per.tracker":"3","io.skip.checksum.errors":"false","dfs.datanode.directoryscan.interval":"21600","yarn.app.mapreduce.client-am.ipc.max-retries-on-timeouts":"3","dfs.client.read.shortcircuit.streams.cache.expiry.ms":"300000","fs.s3a.connection.timeout":"50000","mapreduce.job.max.split.locations":"10","dfs.namenode.write.stale.datanode.ratio":"0.5f","hadoop.registry.zk.session.timeout.ms":"60000","mapreduce.shuffle.transfer.buffer.size":"131072","yarn.timeline-service.client.retry-interval-ms":"1000","mapreduce.jobtracker.taskcache.levels":"2","yarn.http.policy":"HTTP_ONLY","yarn.sharedcache.uploader.server.address":"0.0.0.0:8046","hadoop.http.authentication.token.validity":"*********(redacted)","mapreduce.shuffle.max.connections":"0","mapreduce.job.emit-timeline-data":"false","mapreduce.jobhistory.move.thread-count":"3","yarn.resourcemanager.admin.client.thread-count":"1","mapreduce.jobtracker.persist.jobstatus.active":"true","yarn.dispatcher.drain-events.timeout":"300000","fs.s3a.buffer.dir":"${hadoop.tmp.dir}/s3a","hadoop.ssl.enabled.protocols":"TLSv1","mapreduce.jobhistory.admin.address":"0.0.0.0:10033","mapreduce.shuffle.port":"13562","yarn.nodemanager.health-checker.interval-ms":"600000","mapreduce.tasktracker.report.address":"127.0.0.1:0","dfs.namenode.edit.log.autoroll.multiplier.threshold":"2.0","io.seqfile.lazydecompress":"true","ftp.blocksize":"67108864","dfs.namenode.backup.http-address":"0.0.0.0:50105","mapreduce.jobtracker.instrumentation":"org.apache.hadoop.mapred.JobTrackerMetricsInst","yarn.client.max-cached-nodemanagers-proxies":"0","yarn.nodemanager.delete.debug-delay-sec":"0","mapreduce.jobtracker.http.address":"0.0.0.0:50030","yarn.nodemanager.pmem-check-enabled":"true","yarn.nodemanager.disk-health-checker.max-disk-utilization-per-disk-percentage":"90.0","mapreduce.app-submission.cross-platform":"false","yarn.resourcemanager.work-preserving-recovery.scheduling-wait-ms":"10000","hadoop.security.groups.cache.secs":"300","yarn.resourcemanager.zk-retry-interval-ms":"1000","nfs.mountd.port":"4242","ipc.maximum.data.length":"67108864","mapreduce.shuffle.max.threads":"0","hadoop.security.authorization":"false","mapreduce.job.complete.cancel.delegation.tokens":"*********(redacted)","fs.s3a.paging.maximum":"5000","nfs.exports.allowed.hosts":"* rw","mapreduce.jobhistory.http.policy":"HTTP_ONLY","yarn.sharedcache.store.in-memory.check-period-mins":"720","dfs.datanode.dns.interface":"default","s3native.replication":"3","hadoop.security.group.mapping.ldap.ssl":"false","dfs.namenode.fs-limits.max-xattrs-per-inode":"32","yarn.client.application-client-protocol.poll-interval-ms":"200","dfs.namenode.fs-limits.max-xattr-size":"16384","dfs.client.write.exclude.nodes.cache.expiry.interval.millis":"600000","ha.zookeeper.parent-znode":"/hadoop-ha","dfs.namenode.safemode.extension":"30000","mapreduce.reduce.shuffle.merge.percent":"0.66","hadoop.security.group.mapping.ldap.search.filter.group":"(objectClass=group)","dfs.blocksize":"134217728","yarn.nodemanager.resourcemanager.minimum.version":"NONE","mapreduce.job.speculative.speculative-cap-running-tasks":"0.1","yarn.admin.acl":"*","yarn.sharedcache.admin.thread-count":"1","yarn.resourcemanager.ha.automatic-failover.enabled":"true","mapreduce.reduce.skip.maxgroups":"0","mapreduce.reduce.shuffle.connect.timeout":"180000","yarn.resourcemanager.address":"${yarn.resourcemanager.hostname}:8032","ipc.client.ping":"true","fs.s3a.threads.core":"15","dfs.namenode.resource.checked.volumes.minimum":"1","mapreduce.shuffle.ssl.file.buffer.size":"65536","yarn.resourcemanager.ha.automatic-failover.embedded":"true","dfs.journalnode.http-address":"0.0.0.0:8480","dfs.block.scanner.volume.bytes.per.second":"1048576","hadoop.ssl.enabled":"false","fs.s3a.multipart.purge":"false","dfs.storage.policy.enabled":"true","mapreduce.job.end-notification.max.attempts":"5","mapreduce.output.fileoutputformat.compress.codec":"org.apache.hadoop.io.compress.DefaultCodec","yarn.nodemanager.container-monitor.procfs-tree.smaps-based-rss.enabled":"false","dfs.namenode.edits.dir":"${dfs.namenode.name.dir}","ha.health-monitor.connect-retry-interval.ms":"1000","yarn.nodemanager.keytab":"/etc/krb5.keytab","dfs.namenode.support.allow.format":"true","mapreduce.jobhistory.keytab":"/etc/security/keytab/jhs.service.keytab","fs.s3a.threads.max":"256","mapreduce.reduce.shuffle.input.buffer.percent":"0.70","mapreduce.cluster.temp.dir":"${hadoop.tmp.dir}/mapred/temp","s3.replication":"3","dfs.client.failover.connection.retries":"0","hadoop.tmp.dir":"/tmp/hadoop-${user.name}","mapreduce.job.maps":"2","dfs.namenode.secondary.http-address":"0.0.0.0:50090","mapreduce.job.end-notification.max.retry.interval":"5000","yarn.log-aggregation.retain-check-interval-seconds":"-1","yarn.resourcemanager.resource-tracker.client.thread-count":"50","nfs.wtmax":"1048576","yarn.timeline-service.leveldb-timeline-store.start-time-read-cache-size":"10000","nfs.dump.dir":"/tmp/.hdfs-nfs","yarn.resourcemanager.ha.automatic-failover.zk-base-path":"/yarn-leader-election","io.seqfile.local.dir":"${hadoop.tmp.dir}/io/local","mapreduce.client.submit.file.replication":"10","mapreduce.jobhistory.minicluster.fixed.ports":"false","fs.s3a.multipart.threshold":"2147483647","dfs.datanode.data.dir.perm":"700","mapreduce.jobhistory.done-dir":"${yarn.app.mapreduce.am.staging-dir}/history/done","dfs.namenode.name.dir":"file://${hadoop.tmp.dir}/dfs/name","yarn.resourcemanager.zk-acl":"world:anyone:rwcda","ipc.client.idlethreshold":"4000","yarn.nodemanager.linux-container-executor.cgroups.strict-resource-usage":"false","mapreduce.reduce.input.buffer.percent":"0.0","fs.ftp.host.port":"21","ipc.ping.interval":"60000","dfs.namenode.num.checkpoints.retained":"2","dfs.namenode.kerberos.internal.spnego.principal":"${dfs.web.authentication.kerberos.principal}","yarn.resourcemanager.admin.address":"${yarn.resourcemanager.hostname}:8033","file.client-write-packet-size":"65536","ipc.client.kill.max":"10","mapreduce.reduce.speculative":"true","mapreduce.local.clientfactory.class.name":"org.apache.hadoop.mapred.LocalClientFactory","mapreduce.job.reducer.unconditional-preempt.delay.sec":"300","yarn.nodemanager.disk-health-checker.interval-ms":"120000","ipc.client.connection.maxidletime":"10000","mapreduce.task.io.sort.mb":"100","yarn.nodemanager.localizer.client.thread-count":"5","yarn.sharedcache.admin.address":"0.0.0.0:8047","dfs.namenode.checkpoint.max-retries":"3","dfs.namenode.reject-unresolved-dn-topology-mapping":"false","dfs.namenode.delegation.token.max-lifetime":"*********(redacted)","yarn.nodemanager.localizer.cache.cleanup.interval-ms":"600000","hadoop.security.crypto.codec.classes.aes.ctr.nopadding":"org.apache.hadoop.crypto.OpensslAesCtrCryptoCodec,org.apache.hadoop.crypto.JceAesCtrCryptoCodec","fs.s3a.connection.ssl.enabled":"true","yarn.nodemanager.process-kill-wait.ms":"2000","dfs.namenode.num.extra.edits.retained":"1000000","mapreduce.job.hdfs-servers":"${fs.defaultFS}","fs.df.interval":"60000","fs.s3.sleepTimeSeconds":"10","yarn.sharedcache.cleaner.resource-sleep-ms":"0","yarn.nodemanager.disk-health-checker.min-healthy-disks":"0.25","io.file.buffer.size":"65536","hadoop.work.around.non.threadsafe.getpwuid":"false","dfs.permissions.superusergroup":"supergroup","hadoop.security.group.mapping.ldap.search.attr.member":"member","hadoop.security.random.device.file.path":"/dev/urandom","mapreduce.tasktracker.dns.interface":"default","hadoop.security.sensitive-config-keys":"*********(redacted)","hadoop.rpc.socket.factory.class.default":"org.apache.hadoop.net.StandardSocketFactory","dfs.permissions.enabled":"true","yarn.resourcemanager.connect.retry-interval.ms":"30000","yarn.scheduler.minimum-allocation-mb":"1024","yarn.app.mapreduce.am.staging-dir":"/tmp/hadoop-yarn/staging","mapreduce.reduce.shuffle.read.timeout":"180000","dfs.datanode.https.address":"0.0.0.0:50475","hadoop.http.cross-origin.max-age":"1800","fs.s3a.connection.establish.timeout":"5000","dfs.namenode.fslock.fair":"true","mapreduce.job.running.map.limit":"0","hadoop.ssl.require.client.cert":"false","hadoop.kerberos.kinit.command":"kinit","hadoop.fuse.connection.timeout":"300","mapreduce.reduce.log.level":"INFO","mapreduce.job.ubertask.enable":"false","yarn.nodemanager.vmem-pmem-ratio":"2.1","dfs.client.slow.io.warning.threshold.ms":"30000","hadoop.rpc.protection":"authentication","ha.health-monitor.rpc-timeout.ms":"45000","s3native.stream-buffer-size":"4096","yarn.nodemanager.remote-app-log-dir":"/tmp/logs","dfs.client.read.shortcircuit.streams.cache.size":"256","dfs.client.use.legacy.blockreader.local":"false","yarn.app.mapreduce.am.containerlauncher.threadpool-initial-size":"10","fs.s3n.multipart.uploads.enabled":"false","dfs.namenode.path.based.cache.retry.interval.ms":"30000","hadoop.security.crypto.buffer.size":"8192","mapreduce.jobhistory.recovery.store.leveldb.path":"${hadoop.tmp.dir}/mapred/history/recoverystore","yarn.client.failover-retries-on-socket-timeouts":"0","dfs.balancer.keytab.enabled":"false","hadoop.security.instrumentation.requires.admin":"false","yarn.nodemanager.delete.thread-count":"4","dfs.datanode.balance.bandwidthPerSec":"1048576","dfs.namenode.name.dir.restore":"false","hadoop.registry.jaas.context":"Client","dfs.client.failover.sleep.max.millis":"15000","yarn.timeline-service.leveldb-timeline-store.path":"${hadoop.tmp.dir}/yarn/timeline","s3.blocksize":"67108864","io.map.index.interval":"128","mapreduce.job.counters.max":"120","dfs.namenode.datanode.registration.ip-hostname-check":"true","yarn.timeline-service.store-class":"org.apache.hadoop.yarn.server.timeline.LeveldbTimelineStore","mapreduce.jobhistory.move.interval-ms":"180000","dfs.namenode.resource.du.reserved":"104857600","dfs.datanode.bp-ready.timeout":"20","yarn.nodemanager.localizer.fetch.thread-count":"4","yarn.resourcemanager.scheduler.client.thread-count":"50","hadoop.ssl.hostname.verifier":"DEFAULT","mapreduce.tasktracker.instrumentation":"org.apache.hadoop.mapred.TaskTrackerMetricsInst","yarn.timeline-service.leveldb-state-store.path":"${hadoop.tmp.dir}/yarn/timeline","mapreduce.job.classloader":"false","mapreduce.task.profile.map.params":"${mapreduce.task.profile.params}","ipc.client.connect.timeout":"20000","s3.stream-buffer-size":"4096","yarn.nm.liveness-monitor.expiry-interval-ms":"600000","dfs.namenode.secondary.https-address":"0.0.0.0:50091","s3native.bytes-per-checksum":"512","dfs.namenode.fs-limits.max-directory-items":"1048576","nfs.server.port":"2049","dfs.namenode.delegation.token.renew-interval":"*********(redacted)","mapreduce.jobtracker.address":"local","yarn.nodemanager.recovery.enabled":"false","mapreduce.job.end-notification.retry.interval":"1000","fs.du.interval":"600000","hadoop.security.groups.cache.warn.after.ms":"5000","file.bytes-per-checksum":"512","dfs.namenode.blocks.per.postponedblocks.rescan":"10000","dfs.namenode.checkpoint.period":"3600","net.topology.script.number.args":"100","mapreduce.task.merge.progress.records":"10000","yarn.nodemanager.localizer.address":"${yarn.nodemanager.hostname}:8040","yarn.timeline-service.keytab":"/etc/krb5.keytab","mapreduce.reduce.shuffle.fetch.retry.timeout-ms":"30000","dfs.webhdfs.user.provider.user.pattern":"^[A-Za-z_][A-Za-z0-9._-]*[$]?$","mapreduce.fileoutputcommitter.algorithm.version":"1","yarn.resourcemanager.work-preserving-recovery.enabled":"true","mapreduce.map.skip.maxrecords":"0","yarn.sharedcache.root-dir":"/sharedcache","mapreduce.jobtracker.handler.count":"10","hadoop.http.authentication.type":"simple","mapreduce.jobtracker.taskscheduler":"org.apache.hadoop.mapred.JobQueueTaskScheduler","mapreduce.job.jvm.numtasks":"1","mapreduce.task.userlog.limit.kb":"0","yarn.resourcemanager.scheduler.monitor.enable":"false","fs.s3n.block.size":"67108864","ipc.client.connect.max.retries":"10","hadoop.registry.zk.retry.times":"5","mapreduce.jobtracker.staging.root.dir":"${hadoop.tmp.dir}/mapred/staging","dfs.namenode.http-address":"0.0.0.0:50070","mapreduce.jobtracker.jobhistory.lru.cache.size":"5","dfs.datanode.directoryscan.threads":"1","dfs.datanode.fsdatasetcache.max.threads.per.volume":"4","dfs.namenode.fs-limits.max-blocks-per-file":"1048576","mapreduce.shuffle.listen.queue.size":"128","mapreduce.tasktracker.local.dir.minspacestart":"0","mapreduce.map.cpu.vcores":"1","hadoop.user.group.static.mapping.overrides":"dr.who=;","dfs.datanode.cache.revocation.timeout.ms":"900000","mapreduce.jobhistory.recovery.store.class":"org.apache.hadoop.mapreduce.v2.hs.HistoryServerFileSystemStateStoreService","dfs.client.mmap.cache.size":"256","dfs.ha.log-roll.period":"120","dfs.client.failover.sleep.base.millis":"500","yarn.resourcemanager.fail-fast":"${yarn.fail-fast}","yarn.resourcemanager.proxy-user-privileges.enabled":"false","mapreduce.job.reducer.preempt.delay.sec":"0","hadoop.util.hash.type":"murmur","dfs.namenode.accesstime.precision":"3600000","yarn.app.mapreduce.client.job.max-retries":"0","mapreduce.reduce.shuffle.retry-delay.max.ms":"60000","mapreduce.task.profile.params":"-agentlib:hprof=cpu=samples,heap=sites,force=n,thread=y,verbose=n,file=%s","yarn.app.mapreduce.shuffle.log.backups":"0","hadoop.registry.zk.retry.interval.ms":"1000","fs.AbstractFileSystem.file.impl":"org.apache.hadoop.fs.local.LocalFs","yarn.nodemanager.log-aggregation.roll-monitoring-interval-seconds":"-1","dfs.client.context":"default","mapreduce.jobhistory.cleaner.interval-ms":"86400000","hadoop.registry.zk.quorum":"localhost:2181","mapreduce.output.fileoutputformat.compress":"false","yarn.resourcemanager.am-rm-tokens.master-key-rolling-interval-secs":"*********(redacted)","hadoop.ssl.server.conf":"ssl-server.xml","dfs.http.policy":"HTTP_ONLY","yarn.sharedcache.cleaner.initial-delay-mins":"10","dfs.client.https.keystore.resource":"ssl-client.xml","mapreduce.client.completion.pollinterval":"5000","hadoop.ssl.keystores.factory.class":"org.apache.hadoop.security.ssl.FileBasedKeyStoresFactory","yarn.app.mapreduce.am.resource.cpu-vcores":"1","yarn.timeline-service.enabled":"false","yarn.acl.enable":"false","dfs.image.transfer.chunksize":"65536","dfs.balancer.max-no-move-interval":"60000","mapreduce.tasktracker.map.tasks.maximum":"2","dfs.namenode.edits.journal-plugin.qjournal":"org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager","mapreduce.task.profile":"false","dfs.webhdfs.enabled":"true","yarn.resourcemanager.fs.state-store.uri":"${hadoop.tmp.dir}/yarn/system/rmstore","yarn.nodemanager.linux-container-executor.nonsecure-mode.local-user":"nobody","dfs.namenode.list.encryption.zones.num.responses":"100","yarn.resourcemanager.configuration.provider-class":"org.apache.hadoop.yarn.LocalConfigurationProvider","dfs.namenode.top.num.users":"10","yarn.nodemanager.resource.percentage-physical-cpu-limit":"100","mapreduce.jobhistory.client.thread-count":"10","tfile.fs.input.buffer.size":"262144","mapreduce.client.progressmonitor.pollinterval":"1000","yarn.nodemanager.log-dirs":"${yarn.log.dir}/userlogs","io.seqfile.sorter.recordlimit":"1000000","dfs.blockreport.initialDelay":"0","fs.automatic.close":"true","dfs.client.block.write.replace-datanode-on-failure.best-effort":"false","dfs.namenode.replication.min":"1","dfs.balancer.address":"0.0.0.0:0","fs.s3n.multipart.copy.block.size":"5368709120","yarn.nodemanager.hostname":"0.0.0.0","nfs.rtmax":"1048576","yarn.resourcemanager.zk-timeout-ms":"10000","ftp.stream-buffer-size":"4096","yarn.fail-fast":"false","hadoop.security.group.mapping.ldap.search.filter.user":"(&(objectClass=user)(sAMAccountName={0}))","dfs.datanode.directoryscan.throttle.limit.ms.per.sec":"0","yarn.timeline-service.address":"${yarn.timeline-service.hostname}:10200","dfs.namenode.replication.work.multiplier.per.iteration":"2","mapreduce.job.ubertask.maxmaps":"9","fs.s3a.threads.keepalivetime":"60","dfs.namenode.avoid.write.stale.datanode":"false","dfs.short.circuit.shared.memory.watcher.interrupt.check.ms":"60000","dfs.datanode.available-space-volume-choosing-policy.balanced-space-preference-fraction":"0.75f","mapreduce.task.files.preserve.failedtasks":"false","yarn.app.mapreduce.client.job.retry-interval":"2000","ha.failover-controller.graceful-fence.connection.retries":"1","dfs.client.mmap.enabled":"true","mapreduce.reduce.cpu.vcores":"1","fs.client.resolve.remote.symlinks":"true","dfs.image.compression.codec":"org.apache.hadoop.io.compress.DefaultCodec","mapreduce.jobtracker.restart.recover":"false","dfs.namenode.decommission.blocks.per.interval":"500000","hadoop.http.cross-origin.allowed-origins":"*","yarn.timeline-service.generic-application-history.max-applications":"10000","mapreduce.tasktracker.reduce.tasks.maximum":"2","yarn.nodemanager.local-dirs":"${hadoop.tmp.dir}/nm-local-dir","mapreduce.shuffle.connection-keep-alive.enable":"false","yarn.nodemanager.aux-services.mapreduce_shuffle.class":"org.apache.hadoop.mapred.ShuffleHandler","yarn.sharedcache.store.in-memory.staleness-period-mins":"10080","yarn.resourcemanager.nodemanager.minimum.version":"NONE","net.topology.impl":"org.apache.hadoop.net.NetworkTopology","io.map.index.skip":"0","dfs.namenode.safemode.min.datanodes":"0","mapreduce.job.userlog.retain.hours":"24","yarn.scheduler.maximum-allocation-vcores":"32","hadoop.http.cross-origin.allowed-headers":"X-Requested-With,Content-Type,Accept,Origin","yarn.nodemanager.log-aggregation.compression-type":"none","dfs.namenode.enable.retrycache":"true","yarn.ipc.rpc.class":"org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC","dfs.namenode.startup.delay.block.deletion.sec":"0","mapreduce.reduce.maxattempts":"4","mapreduce.job.committer.setup.cleanup.needed":"true","dfs.datanode.readahead.bytes":"4194304","mapreduce.jobtracker.heartbeats.in.second":"100","mapreduce.job.running.reduce.limit":"0","mapreduce.job.token.tracking.ids.enabled":"*********(redacted)","hadoop.registry.system.acls":"sasl:yarn@, sasl:mapred@, sasl:hdfs@","yarn.nodemanager.recovery.dir":"${hadoop.tmp.dir}/yarn-nm-recovery","mapreduce.jobhistory.intermediate-done-dir":"${yarn.app.mapreduce.am.staging-dir}/history/done_intermediate","yarn.app.mapreduce.shuffle.log.separate":"true","dfs.namenode.delegation.key.update-interval":"86400000","fs.s3a.max.total.tasks":"1000","dfs.client.file-block-storage-locations.num-threads":"10","mapreduce.tasktracker.healthchecker.interval":"60000","hadoop.http.authentication.simple.anonymous.allowed":"true","fs.s3a.fast.upload":"false","dfs.namenode.heartbeat.recheck-interval":"300000","fs.s3a.attempts.maximum":"10","dfs.namenode.avoid.read.stale.datanode":"false","hadoop.registry.zk.connection.timeout.ms":"15000","yarn.nodemanager.health-checker.script.timeout-ms":"1200000","yarn.timeline-service.leveldb-timeline-store.start-time-write-cache-size":"10000","mapreduce.map.log.level":"INFO","mapreduce.output.fileoutputformat.compress.type":"RECORD","yarn.resourcemanager.leveldb-state-store.path":"${hadoop.tmp.dir}/yarn/system/rmstore","hadoop.registry.rm.enabled":"false","mapreduce.ifile.readahead.bytes":"4194304","mapreduce.tasktracker.tasks.sleeptimebeforesigkill":"5000","yarn.resourcemanager.fs.state-store.retry-policy-spec":"2000, 500","dfs.blockreport.intervalMsec":"21600000","yarn.sharedcache.app-checker.class":"org.apache.hadoop.yarn.server.sharedcachemanager.RemoteAppChecker","yarn.nodemanager.linux-container-executor.nonsecure-mode.limit-users":"true","mapreduce.cluster.acls.enabled":"false","mapreduce.job.speculative.retry-after-no-speculate":"1000","dfs.namenode.path.based.cache.refresh.interval.ms":"30000","yarn.resourcemanager.fs.state-store.retry-interval-ms":"1000","file.stream-buffer-size":"4096","mapreduce.map.output.compress.codec":"org.apache.hadoop.io.compress.DefaultCodec","mapreduce.map.speculative":"true","dfs.datanode.use.datanode.hostname":"false","mapreduce.job.speculative.retry-after-speculate":"15000","dfs.namenode.fs-limits.min-block-size":"1048576","yarn.nodemanager.linux-container-executor.cgroups.mount":"false","yarn.app.mapreduce.am.container.log.backups":"0","mapreduce.job.reduce.slowstart.completedmaps":"0.05","dfs.client.read.shortcircuit":"false","yarn.timeline-service.http-authentication.type":"simple","hadoop.security.group.mapping.ldap.search.attr.group.name":"cn","dfs.client.cached.conn.retry":"3","dfs.namenode.invalidate.work.pct.per.iteration":"0.32f","yarn.sharedcache.client-server.address":"0.0.0.0:8045","dfs.replication.max":"512","dfs.namenode.inotify.max.events.per.rpc":"1000","yarn.resourcemanager.hostname":"0.0.0.0","mapreduce.reduce.shuffle.fetch.retry.enabled":"${yarn.nodemanager.recovery.enabled}","mapreduce.map.memory.mb":"1024","mapreduce.task.skip.start.attempts":"2","fs.AbstractFileSystem.hdfs.impl":"org.apache.hadoop.fs.Hdfs","dfs.namenode.lock.detailed-metrics.enabled":"false","ipc.client.rpc-timeout.ms":"0","fs.s3.maxRetries":"4","dfs.default.chunk.view.size":"32768","mapreduce.input.lineinputformat.linespermap":"1","ipc.client.connect.max.retries.on.timeouts":"45","yarn.timeline-service.leveldb-timeline-store.read-cache-size":"104857600","fs.AbstractFileSystem.har.impl":"org.apache.hadoop.fs.HarFs","mapreduce.job.split.metainfo.maxsize":"10000000","yarn.am.liveness-monitor.expiry-interval-ms":"600000","dfs.client.mmap.retry.timeout.ms":"300000","yarn.resourcemanager.container-tokens.master-key-rolling-interval-secs":"*********(redacted)","dfs.namenode.list.cache.directives.num.responses":"100","dfs.image.compress":"false","dfs.namenode.kerberos.principal.pattern":"*","fs.s3n.multipart.uploads.block.size":"67108864","mapreduce.tasktracker.http.address":"0.0.0.0:50060","yarn.resourcemanager.resource-tracker.address":"${yarn.resourcemanager.hostname}:8031","hadoop.fuse.timer.period":"5","yarn.resourcemanager.leveldb-state-store.compaction-interval-secs":"3600","dfs.datanode.hdfs-blocks-metadata.enabled":"false","dfs.namenode.checkpoint.dir":"file://${hadoop.tmp.dir}/dfs/namesecondary","dfs.datanode.max.transfer.threads":"4096","nfs.allow.insecure.ports":"true","mapreduce.client.output.filter":"FAILED","hadoop.http.filter.initializers":"org.apache.hadoop.http.lib.StaticUserWebFilter","mapreduce.reduce.memory.mb":"1024","s3native.client-write-packet-size":"65536","yarn.timeline-service.hostname":"0.0.0.0","file.replication":"1","yarn.nodemanager.container-metrics.unregister-delay-ms":"10000","yarn.nodemanager.log.retain-seconds":"10800","yarn.resourcemanager.keytab":"/etc/krb5.keytab","mapreduce.reduce.merge.inmem.threshold":"1000","dfs.client.https.need-auth":"false","yarn.timeline-service.recovery.enabled":"false","yarn.sharedcache.nm.uploader.thread-count":"20","dfs.blockreport.split.threshold":"1000000","dfs.client.block.write.replace-datanode-on-failure.policy":"DEFAULT","mapreduce.shuffle.ssl.enabled":"false","dfs.namenode.write-lock-reporting-threshold-ms":"5000","dfs.block.access.token.enable":"*********(redacted)","yarn.resourcemanager.state-store.max-completed-applications":"${yarn.resourcemanager.max-completed-applications}","dfs.client.file-block-storage-locations.timeout.millis":"1000","dfs.namenode.block-placement-policy.default.prefer-local-node":"true","mapreduce.job.speculative.minimum-allowed-tasks":"10","yarn.log-aggregation.retain-seconds":"-1","dfs.namenode.replication.considerLoad":"true","yarn.nodemanager.disk-health-checker.min-free-space-per-disk-mb":"0","mapreduce.jobhistory.max-age-ms":"604800000","dfs.namenode.retrycache.heap.percent":"0.03f","hadoop.http.cross-origin.allowed-methods":"GET,POST,HEAD","dfs.datanode.cache.revocation.polling.ms":"500","mapreduce.jobhistory.webapp.address":"0.0.0.0:19888","dfs.namenode.path.based.cache.block.map.allocation.percent":"0.25","mapreduce.jobtracker.system.dir":"${hadoop.tmp.dir}/mapred/system","mapreduce.tasktracker.taskmemorymanager.monitoringinterval":"5000","dfs.journalnode.rpc-address":"0.0.0.0:8485","yarn.client.nodemanager-connect.max-wait-ms":"180000","yarn.resourcemanager.webapp.address":"${yarn.resourcemanager.hostname}:8088","mapreduce.jobhistory.recovery.enable":"false","dfs.client.short.circuit.replica.stale.threshold.ms":"1800000","mapreduce.reduce.shuffle.parallelcopies":"5","fs.trash.interval":"0","dfs.namenode.replication.interval":"3","yarn.app.mapreduce.client.max-retries":"3","hadoop.security.authentication":"simple","dfs.namenode.top.enabled":"true","mapreduce.task.profile.reduce.params":"${mapreduce.task.profile.params}","dfs.datanode.du.reserved":"0","yarn.app.mapreduce.am.resource.mb":"1536","mapreduce.input.fileinputformat.list-status.num-threads":"1","dfs.namenode.lazypersist.file.scrub.interval.sec":"300","yarn.nodemanager.container-executor.class":"org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor","io.mapfile.bloom.size":"1048576","yarn.timeline-service.ttl-ms":"604800000","yarn.nodemanager.resource.cpu-vcores":"8","mapreduce.job.reduces":"1","fs.s3a.multipart.size":"104857600","yarn.scheduler.minimum-allocation-vcores":"1","mapreduce.job.speculative.speculative-cap-total-tasks":"0.01","dfs.datanode.http.address":"0.0.0.0:50075","hadoop.ssl.client.conf":"ssl-client.xml","mapreduce.job.queuename":"default","ha.health-monitor.sleep-after-disconnect.ms":"1000","s3.bytes-per-checksum":"512","yarn.app.mapreduce.shuffle.log.limit.kb":"0","dfs.namenode.list.cache.pools.num.responses":"100","hadoop.security.group.mapping":"org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback","yarn.resourcemanager.ha.enabled":"false","dfs.encrypt.data.transfer":"false","hadoop.http.staticuser.user":"dr.who","yarn.nodemanager.linux-container-executor.resources-handler.class":"org.apache.hadoop.yarn.server.nodemanager.util.DefaultLCEResourcesHandler","mapreduce.reduce.shuffle.memory.limit.percent":"0.25","dfs.namenode.top.windows.minutes":"1,5,25","s3.client-write-packet-size":"65536","mapreduce.map.output.compress":"false","ha.zookeeper.acl":"world:anyone:rwcda","ipc.server.max.connections":"0","mapreduce.reduce.skip.proc.count.autoincr":"true","yarn.scheduler.maximum-allocation-mb":"8192","yarn.resourcemanager.scheduler.monitor.policies":"org.apache.hadoop.yarn.server.resourcemanager.monitor.capacity.ProportionalCapacityPreemptionPolicy","yarn.sharedcache.cleaner.period-mins":"1440","yarn.app.mapreduce.am.container.log.limit.kb":"0","s3native.blocksize":"67108864","ipc.client.connect.retry.interval":"1000","yarn.resourcemanager.zk-state-store.parent-path":"/rmstore","dfs.namenode.edit.log.autoroll.check.interval.ms":"300000","mapreduce.jobhistory.cleaner.enable":"true","hadoop.security.kms.client.encrypted.key.cache.expiry":"43200000","dfs.client.use.datanode.hostname":"false","dfs.stream-buffer-size":"4096","yarn.client.nodemanager-client-async.thread-pool-max-size":"500","mapreduce.map.maxattempts":"4","dfs.datanode.drop.cache.behind.writes":"false","mapreduce.tasktracker.dns.nameserver":"default","yarn.nodemanager.sleep-delay-before-sigkill.ms":"250","mapreduce.job.end-notification.retry.attempts":"0","yarn.resourcemanager.zk-num-retries":"1000","dfs.client.failover.max.attempts":"15","mapreduce.tasktracker.indexcache.mb":"10","hadoop.registry.zk.root":"/registry","mapreduce.job.reduce.shuffle.consumer.plugin.class":"org.apache.hadoop.mapreduce.task.reduce.Shuffle","yarn.resourcemanager.delayed.delegation-token.removal-interval-ms":"*********(redacted)","yarn.nodemanager.localizer.cache.target-size-mb":"10240","ftp.client-write-packet-size":"65536","mapreduce.jobtracker.maxtasks.perjob":"-1","dfs.block.access.token.lifetime":"*********(redacted)","dfs.namenode.max.extra.edits.segments.retained":"10000","yarn.client.failover-retries":"0","fs.s3a.multipart.purge.age":"86400","dfs.image.transfer.bandwidthPerSec":"0","io.native.lib.available":"true","net.topology.node.switch.mapping.impl":"org.apache.hadoop.net.ScriptBasedMapping","ipc.server.listen.queue.size":"128","map.sort.class":"org.apache.hadoop.util.QuickSort","dfs.namenode.acls.enabled":"false","hadoop.security.kms.client.authentication.retry-count":"1","fs.permissions.umask-mode":"022","dfs.datanode.ipc.address":"0.0.0.0:50020","yarn.nodemanager.vmem-check-enabled":"true","yarn.nodemanager.recovery.compaction-interval-secs":"3600","yarn.app.mapreduce.client-am.ipc.max-retries":"3","dfs.lock.suppress.warning.interval":"10s","dfs.client.block.write.retries":"3","mapreduce.job.ubertask.maxreduces":"1","hadoop.security.kms.client.encrypted.key.cache.size":"500","hadoop.security.java.secure.random.algorithm":"SHA1PRNG","ha.failover-controller.cli-check.rpc-timeout.ms":"20000","yarn.client.nodemanager-connect.retry-interval-ms":"10000","yarn.timeline-service.state-store-class":"org.apache.hadoop.yarn.server.timeline.recovery.LeveldbTimelineStateStore","dfs.client-write-packet-size":"65536","yarn.nodemanager.env-whitelist":"JAVA_HOME,HADOOP_COMMON_HOME,HADOOP_HDFS_HOME,HADOOP_CONF_DIR,HADOOP_YARN_HOME","yarn.sharedcache.nested-level":"3","dfs.datanode.dns.nameserver":"default","yarn.nodemanager.webapp.address":"${yarn.nodemanager.hostname}:8042","rpc.metrics.quantile.enable":"false","mapreduce.jobhistory.admin.acl":"*","yarn.resourcemanager.system-metrics-publisher.dispatcher.pool-size":"10","hadoop.http.authentication.kerberos.keytab":"${user.home}/hadoop.keytab","dfs.image.transfer.timeout":"60000","yarn.resourcemanager.recovery.enabled":"false","dfs.datanode.available-space-volume-choosing-policy.balanced-space-threshold":"10737418240","dfs.client.failover.connection.retries.on.timeouts":"0"},"System Properties":{"java.io.tmpdir":"/var/folders/tm/7v5m6cg144g467bsj7zgsxgc0000gn/T/","line.separator":"\n","path.separator":":","sun.management.compiler":"HotSpot 64-Bit Tiered Compilers","SPARK_SUBMIT":"true","sun.cpu.endian":"little","java.specification.version":"1.8","java.vm.specification.name":"Java Virtual Machine Specification","java.vendor":"AdoptOpenJDK","java.vm.specification.version":"1.8","user.home":"/Users/kinsho","file.encoding.pkg":"sun.io","sun.nio.ch.bugLevel":"","sun.arch.data.model":"64","sun.boot.library.path":"/Library/Java/JavaVirtualMachines/adoptopenjdk-8.jdk/Contents/Home/jre/lib","user.dir":"/Users/kinsho/workspace/spark-3.0.1","java.library.path":"/Users/kinsho/Library/Java/Extensions:/Library/Java/Extensions:/Network/Library/Java/Extensions:/System/Library/Java/Extensions:/usr/lib/java:.","sun.cpu.isalist":"","os.arch":"x86_64","java.vm.version":"25.232-b09","jetty.git.hash":"e1bc35120a6617ee3df052294e433f3a25ce7097","java.endorsed.dirs":"/Library/Java/JavaVirtualMachines/adoptopenjdk-8.jdk/Contents/Home/jre/lib/endorsed","java.runtime.version":"1.8.0_232-b09","java.vm.info":"mixed mode","java.ext.dirs":"/Users/kinsho/Library/Java/Extensions:/Library/Java/JavaVirtualMachines/adoptopenjdk-8.jdk/Contents/Home/jre/lib/ext:/Library/Java/Extensions:/Network/Library/Java/Extensions:/System/Library/Java/Extensions:/usr/lib/java","java.runtime.name":"OpenJDK Runtime Environment","file.separator":"/","java.class.version":"52.0","java.specification.name":"Java Platform API Specification","sun.boot.class.path":"/Library/Java/JavaVirtualMachines/adoptopenjdk-8.jdk/Contents/Home/jre/lib/resources.jar:/Library/Java/JavaVirtualMachines/adoptopenjdk-8.jdk/Contents/Home/jre/lib/rt.jar:/Library/Java/JavaVirtualMachines/adoptopenjdk-8.jdk/Contents/Home/jre/lib/sunrsasign.jar:/Library/Java/JavaVirtualMachines/adoptopenjdk-8.jdk/Contents/Home/jre/lib/jsse.jar:/Library/Java/JavaVirtualMachines/adoptopenjdk-8.jdk/Contents/Home/jre/lib/jce.jar:/Library/Java/JavaVirtualMachines/adoptopenjdk-8.jdk/Contents/Home/jre/lib/charsets.jar:/Library/Java/JavaVirtualMachines/adoptopenjdk-8.jdk/Contents/Home/jre/lib/jfr.jar:/Library/Java/JavaVirtualMachines/adoptopenjdk-8.jdk/Contents/Home/jre/classes","file.encoding":"UTF-8","user.timezone":"Asia/Tokyo","java.specification.vendor":"Oracle Corporation","sun.java.launcher":"SUN_STANDARD","os.version":"10.15.6","sun.os.patch.level":"unknown","gopherProxySet":"false","java.vm.specification.vendor":"Oracle Corporation","user.country":"JP","sun.jnu.encoding":"UTF-8","user.language":"ja","java.vendor.url":"http://java.oracle.com/","java.awt.printerjob":"sun.lwawt.macosx.CPrinterJob","java.awt.graphicsenv":"sun.awt.CGraphicsEnvironment","awt.toolkit":"sun.lwawt.macosx.LWCToolkit","os.name":"Mac OS X","java.vm.vendor":"AdoptOpenJDK","java.vendor.url.bug":"http://bugreport.sun.com/bugreport/","user.name":"kinsho","java.vm.name":"OpenJDK 64-Bit Server VM","sun.java.command":"org.apache.spark.deploy.SparkSubmit --master spark://ST000000035:7077 --class LogTransform workspace/sample-spark-scala/target/scala-2.12/simple-project_2.12-1.0.jar","java.home":"/Library/Java/JavaVirtualMachines/adoptopenjdk-8.jdk/Contents/Home/jre","java.version":"1.8.0_232","sun.io.unicode.encoding":"UnicodeBig"},"Classpath Entries":{"/Users/kinsho/workspace/spark-3.0.1/assembly/target/scala-2.12/jars/hadoop-yarn-server-common-2.7.4.jar":"System Classpath","/Users/kinsho/workspace/spark-3.0.1/assembly/target/scala-2.12/jars/hadoop-annotations-2.7.4.jar":"System Classpath","/Users/kinsho/workspace/spark-3.0.1/assembly/target/scala-2.12/jars/spark-tags_2.12-3.0.1.jar":"System Classpath","/Users/kinsho/workspace/spark-3.0.1/assembly/target/scala-2.12/jars/api-util-1.0.0-M20.jar":"System Classpath","/Users/kinsho/workspace/spark-3.0.1/assembly/target/scala-2.12/jars/hk2-api-2.6.1.jar":"System Classpath","/Users/kinsho/workspace/spark-3.0.1/assembly/target/scala-2.12/jars/commons-crypto-1.0.0.jar":"System Classpath","/Users/kinsho/workspace/spark-3.0.1/assembly/target/scala-2.12/jars/commons-configuration-1.6.jar":"System Classpath","/Users/kinsho/workspace/spark-3.0.1/assembly/target/scala-2.12/jars/protobuf-java-2.5.0.jar":"System Classpath","/Users/kinsho/workspace/spark-3.0.1/assembly/target/scala-2.12/jars/xmlenc-0.52.jar":"System Classpath","/Users/kinsho/workspace/spark-3.0.1/assembly/target/scala-2.12/jars/commons-math3-3.4.1.jar":"System Classpath","/Users/kinsho/workspace/spark-3.0.1/assembly/target/scala-2.12/jars/opencsv-2.3.jar":"System Classpath","/Users/kinsho/workspace/spark-3.0.1/conf/":"System Classpath","/Users/kinsho/workspace/spark-3.0.1/assembly/target/scala-2.12/jars/metrics-core-4.1.1.jar":"System Classpath","/Users/kinsho/workspace/spark-3.0.1/assembly/target/scala-2.12/jars/hadoop-mapreduce-client-jobclient-2.7.4.jar":"System Classpath","/Users/kinsho/workspace/spark-3.0.1/assembly/target/scala-2.12/jars/scala-compiler-2.12.10.jar":"System Classpath","/Users/kinsho/workspace/spark-3.0.1/assembly/target/scala-2.12/jars/scala-reflect-2.12.10.jar":"System Classpath","/Users/kinsho/workspace/spark-3.0.1/assembly/target/scala-2.12/jars/parquet-jackson-1.10.1.jar":"System Classpath","/Users/kinsho/workspace/spark-3.0.1/assembly/target/scala-2.12/jars/activation-1.1.1.jar":"System Classpath","/Users/kinsho/workspace/spark-3.0.1/assembly/target/scala-2.12/jars/metrics-json-4.1.1.jar":"System Classpath","/Users/kinsho/workspace/spark-3.0.1/assembly/target/scala-2.12/jars/commons-codec-1.10.jar":"System Classpath","/Users/kinsho/workspace/spark-3.0.1/assembly/target/scala-2.12/jars/javassist-3.25.0-GA.jar":"System Classpath","/Users/kinsho/workspace/spark-3.0.1/assembly/target/scala-2.12/jars/hive-storage-api-2.7.1.jar":"System Classpath","/Users/kinsho/workspace/spark-3.0.1/assembly/target/scala-2.12/jars/jetty-util-6.1.26.jar":"System Classpath","/Users/kinsho/workspace/spark-3.0.1/assembly/target/scala-2.12/jars/commons-beanutils-1.9.4.jar":"System Classpath","/Users/kinsho/workspace/spark-3.0.1/assembly/target/scala-2.12/jars/jackson-core-asl-1.9.13.jar":"System Classpath","/Users/kinsho/workspace/spark-3.0.1/assembly/target/scala-2.12/jars/orc-mapreduce-1.5.10.jar":"System Classpath","/Users/kinsho/workspace/spark-3.0.1/assembly/target/scala-2.12/jars/hadoop-mapreduce-client-app-2.7.4.jar":"System Classpath","/Users/kinsho/workspace/spark-3.0.1/assembly/target/scala-2.12/jars/aopalliance-repackaged-2.6.1.jar":"System Classpath","/Users/kinsho/workspace/spark-3.0.1/assembly/target/scala-2.12/jars/commons-lang-2.6.jar":"System Classpath","/Users/kinsho/workspace/spark-3.0.1/assembly/target/scala-2.12/jars/apacheds-i18n-2.0.0-M15.jar":"System Classpath","/Users/kinsho/workspace/spark-3.0.1/assembly/target/scala-2.12/jars/arrow-memory-0.15.1.jar":"System Classpath","/Users/kinsho/workspace/spark-3.0.1/assembly/target/scala-2.12/jars/antlr4-runtime-4.7.1.jar":"System Classpath","/Users/kinsho/workspace/spark-3.0.1/assembly/target/scala-2.12/jars/spark-launcher_2.12-3.0.1.jar":"System Classpath","/Users/kinsho/workspace/spark-3.0.1/assembly/target/scala-2.12/jars/jackson-module-paranamer-2.10.0.jar":"System Classpath","/Users/kinsho/workspace/spark-3.0.1/assembly/target/scala-2.12/jars/spark-unsafe_2.12-3.0.1.jar":"System Classpath","/Users/kinsho/workspace/spark-3.0.1/assembly/target/scala-2.12/jars/avro-mapred-1.8.2-hadoop2.jar":"System Classpath","/Users/kinsho/workspace/spark-3.0.1/assembly/target/scala-2.12/jars/spark-repl_2.12-3.0.1.jar":"System Classpath","spark://192.168.11.7:55052/jars/simple-project_2.12-1.0.jar":"Added By User","/Users/kinsho/workspace/spark-3.0.1/assembly/target/scala-2.12/jars/audience-annotations-0.5.0.jar":"System Classpath","/Users/kinsho/workspace/spark-3.0.1/assembly/target/scala-2.12/jars/hadoop-auth-2.7.4.jar":"System Classpath","/Users/kinsho/workspace/spark-3.0.1/assembly/target/scala-2.12/jars/spire-platform_2.12-0.17.0-M1.jar":"System Classpath","/Users/kinsho/workspace/spark-3.0.1/assembly/target/scala-2.12/jars/py4j-0.10.9.jar":"System Classpath","/Users/kinsho/workspace/spark-3.0.1/assembly/target/scala-2.12/jars/spark-streaming_2.12-3.0.1.jar":"System Classpath","/Users/kinsho/workspace/spark-3.0.1/assembly/target/scala-2.12/jars/commons-collections-3.2.2.jar":"System Classpath","/Users/kinsho/workspace/spark-3.0.1/assembly/target/scala-2.12/jars/hadoop-mapreduce-client-common-2.7.4.jar":"System Classpath","/Users/kinsho/workspace/spark-3.0.1/assembly/target/scala-2.12/jars/json4s-ast_2.12-3.6.6.jar":"System Classpath","/Users/kinsho/workspace/spark-3.0.1/assembly/target/scala-2.12/jars/spire-util_2.12-0.17.0-M1.jar":"System Classpath","/Users/kinsho/workspace/spark-3.0.1/assembly/target/scala-2.12/jars/javax.servlet-api-3.1.0.jar":"System Classpath","/Users/kinsho/workspace/spark-3.0.1/assembly/target/scala-2.12/jars/algebra_2.12-2.0.0-M2.jar":"System Classpath","/Users/kinsho/workspace/spark-3.0.1/assembly/target/scala-2.12/jars/shims-0.7.45.jar":"System Classpath","/Users/kinsho/workspace/spark-3.0.1/assembly/target/scala-2.12/jars/commons-cli-1.2.jar":"System Classpath","/Users/kinsho/workspace/spark-3.0.1/assembly/target/scala-2.12/jars/stream-2.9.6.jar":"System Classpath","/Users/kinsho/workspace/spark-3.0.1/assembly/target/scala-2.12/jars/flatbuffers-java-1.9.0.jar":"System Classpath","/Users/kinsho/workspace/spark-3.0.1/assembly/target/scala-2.12/jars/snappy-java-1.1.7.5.jar":"System Classpath","/Users/kinsho/workspace/spark-3.0.1/assembly/target/scala-2.12/jars/jackson-databind-2.10.0.jar":"System Classpath","/Users/kinsho/workspace/spark-3.0.1/assembly/target/scala-2.12/jars/jakarta.validation-api-2.0.2.jar":"System Classpath","/Users/kinsho/workspace/spark-3.0.1/assembly/target/scala-2.12/jars/commons-net-3.1.jar":"System Classpath","/Users/kinsho/workspace/spark-3.0.1/assembly/target/scala-2.12/jars/parquet-format-2.4.0.jar":"System Classpath","/Users/kinsho/workspace/spark-3.0.1/assembly/target/scala-2.12/jars/api-asn1-api-1.0.0-M20.jar":"System Classpath","/Users/kinsho/workspace/spark-3.0.1/assembly/target/scala-2.12/jars/hadoop-mapreduce-client-shuffle-2.7.4.jar":"System Classpath","/Users/kinsho/workspace/spark-3.0.1/assembly/target/scala-2.12/jars/scala-parser-combinators_2.12-1.1.2.jar":"System Classpath","/Users/kinsho/workspace/spark-3.0.1/assembly/target/scala-2.12/jars/gson-2.2.4.jar":"System Classpath","/Users/kinsho/workspace/spark-3.0.1/assembly/target/scala-2.12/jars/avro-ipc-1.8.2.jar":"System Classpath","/Users/kinsho/workspace/spark-3.0.1/assembly/target/scala-2.12/jars/pyrolite-4.30.jar":"System Classpath","/Users/kinsho/workspace/spark-3.0.1/assembly/target/scala-2.12/jars/arpack_combined_all-0.1.jar":"System Classpath","/Users/kinsho/workspace/spark-3.0.1/assembly/target/scala-2.12/jars/metrics-graphite-4.1.1.jar":"System Classpath","/Users/kinsho/workspace/spark-3.0.1/assembly/target/scala-2.12/jars/spark-core_2.12-3.0.1.jar":"System Classpath","/Users/kinsho/workspace/spark-3.0.1/assembly/target/scala-2.12/jars/spire-macros_2.12-0.17.0-M1.jar":"System Classpath","/Users/kinsho/workspace/spark-3.0.1/assembly/target/scala-2.12/jars/JTransforms-3.1.jar":"System Classpath","/Users/kinsho/workspace/spark-3.0.1/assembly/target/scala-2.12/jars/hadoop-yarn-client-2.7.4.jar":"System Classpath","/Users/kinsho/workspace/spark-3.0.1/assembly/target/scala-2.12/jars/spark-sketch_2.12-3.0.1.jar":"System Classpath","/Users/kinsho/workspace/spark-3.0.1/assembly/target/scala-2.12/jars/json4s-core_2.12-3.6.6.jar":"System Classpath","/Users/kinsho/workspace/spark-3.0.1/assembly/target/scala-2.12/jars/parquet-hadoop-1.10.1.jar":"System Classpath","/Users/kinsho/workspace/spark-3.0.1/assembly/target/scala-2.12/jars/orc-shims-1.5.10.jar":"System Classpath","/Users/kinsho/workspace/spark-3.0.1/assembly/target/scala-2.12/jars/cats-kernel_2.12-2.0.0-M4.jar":"System Classpath","/Users/kinsho/workspace/spark-3.0.1/assembly/target/scala-2.12/jars/orc-core-1.5.10.jar":"System Classpath","/Users/kinsho/workspace/spark-3.0.1/assembly/target/scala-2.12/jars/spark-network-common_2.12-3.0.1.jar":"System Classpath","/Users/kinsho/workspace/spark-3.0.1/assembly/target/scala-2.12/jars/curator-recipes-2.7.1.jar":"System Classpath","/Users/kinsho/workspace/spark-3.0.1/assembly/target/scala-2.12/jars/jersey-container-servlet-2.30.jar":"System Classpath","/Users/kinsho/workspace/spark-3.0.1/assembly/target/scala-2.12/jars/breeze-macros_2.12-1.0.jar":"System Classpath","/Users/kinsho/workspace/spark-3.0.1/assembly/target/scala-2.12/jars/curator-client-2.7.1.jar":"System Classpath","/Users/kinsho/workspace/spark-3.0.1/assembly/target/scala-2.12/jars/scala-xml_2.12-1.2.0.jar":"System Classpath","/Users/kinsho/workspace/spark-3.0.1/assembly/target/scala-2.12/jars/arrow-format-0.15.1.jar":"System Classpath","/Users/kinsho/workspace/spark-3.0.1/assembly/target/scala-2.12/jars/hadoop-common-2.7.4.jar":"System Classpath","/Users/kinsho/workspace/spark-3.0.1/assembly/target/scala-2.12/jars/jackson-jaxrs-1.9.13.jar":"System Classpath","/Users/kinsho/workspace/spark-3.0.1/assembly/target/scala-2.12/jars/commons-io-2.4.jar":"System Classpath","/Users/kinsho/workspace/spark-3.0.1/assembly/target/scala-2.12/jars/oro-2.0.8.jar":"System Classpath","/Users/kinsho/workspace/spark-3.0.1/assembly/target/scala-2.12/jars/json4s-jackson_2.12-3.6.6.jar":"System Classpath","/Users/kinsho/workspace/spark-3.0.1/assembly/target/scala-2.12/jars/ivy-2.4.0.jar":"System Classpath","/Users/kinsho/workspace/spark-3.0.1/assembly/target/scala-2.12/jars/compress-lzf-1.0.3.jar":"System Classpath","/Users/kinsho/workspace/spark-3.0.1/assembly/target/scala-2.12/jars/commons-digester-1.8.jar":"System Classpath","/Users/kinsho/workspace/spark-3.0.1/assembly/target/scala-2.12/jars/slf4j-log4j12-1.7.30.jar":"System Classpath","/Users/kinsho/workspace/spark-3.0.1/assembly/target/scala-2.12/jars/hadoop-hdfs-2.7.4.jar":"System Classpath","/Users/kinsho/workspace/spark-3.0.1/assembly/target/scala-2.12/jars/lz4-java-1.7.1.jar":"System Classpath","/Users/kinsho/workspace/spark-3.0.1/assembly/target/scala-2.12/jars/commons-lang3-3.9.jar":"System Classpath","/Users/kinsho/workspace/spark-3.0.1/assembly/target/scala-2.12/jars/httpclient-4.5.6.jar":"System Classpath","/Users/kinsho/workspace/spark-3.0.1/assembly/target/scala-2.12/jars/macro-compat_2.12-1.1.1.jar":"System Classpath","/Users/kinsho/workspace/spark-3.0.1/assembly/target/scala-2.12/jars/arrow-vector-0.15.1.jar":"System Classpath","/Users/kinsho/workspace/spark-3.0.1/assembly/target/scala-2.12/jars/slf4j-api-1.7.30.jar":"System Classpath","/Users/kinsho/workspace/spark-3.0.1/assembly/target/scala-2.12/jars/scala-collection-compat_2.12-2.1.1.jar":"System Classpath","/Users/kinsho/workspace/spark-3.0.1/assembly/target/scala-2.12/jars/commons-compress-1.8.1.jar":"System Classpath","/Users/kinsho/workspace/spark-3.0.1/assembly/target/scala-2.12/jars/jackson-annotations-2.10.0.jar":"System Classpath","/Users/kinsho/workspace/spark-3.0.1/assembly/target/scala-2.12/jars/json4s-scalap_2.12-3.6.6.jar":"System Classpath","/Users/kinsho/workspace/spark-3.0.1/assembly/target/scala-2.12/jars/jackson-module-scala_2.12-2.10.0.jar":"System Classpath","/Users/kinsho/workspace/spark-3.0.1/assembly/target/scala-2.12/jars/httpcore-4.4.12.jar":"System Classpath","/Users/kinsho/workspace/spark-3.0.1/assembly/target/scala-2.12/jars/aircompressor-0.10.jar":"System Classpath","/Users/kinsho/workspace/spark-3.0.1/assembly/target/scala-2.12/jars/spark-mllib-local_2.12-3.0.1.jar":"System Classpath","/Users/kinsho/workspace/spark-3.0.1/assembly/target/scala-2.12/jars/jakarta.inject-2.6.1.jar":"System Classpath","/Users/kinsho/workspace/spark-3.0.1/assembly/target/scala-2.12/jars/spark-mllib_2.12-3.0.1.jar":"System Classpath","/Users/kinsho/workspace/spark-3.0.1/assembly/target/scala-2.12/jars/jersey-media-jaxb-2.30.jar":"System Classpath","/Users/kinsho/workspace/spark-3.0.1/assembly/target/scala-2.12/jars/metrics-jmx-4.1.1.jar":"System Classpath","/Users/kinsho/workspace/spark-3.0.1/assembly/target/scala-2.12/jars/jsp-api-2.1.jar":"System Classpath","/Users/kinsho/workspace/spark-3.0.1/assembly/target/scala-2.12/jars/paranamer-2.8.jar":"System Classpath","/Users/kinsho/workspace/spark-3.0.1/assembly/target/scala-2.12/jars/chill-java-0.9.5.jar":"System Classpath","/Users/kinsho/workspace/spark-3.0.1/assembly/target/scala-2.12/jars/xbean-asm7-shaded-4.15.jar":"System Classpath","/Users/kinsho/workspace/spark-3.0.1/assembly/target/scala-2.12/jars/zookeeper-3.4.14.jar":"System Classpath","/Users/kinsho/workspace/spark-3.0.1/assembly/target/scala-2.12/jars/log4j-1.2.17.jar":"System Classpath","/Users/kinsho/workspace/spark-3.0.1/assembly/target/scala-2.12/jars/jcl-over-slf4j-1.7.30.jar":"System Classpath","/Users/kinsho/workspace/spark-3.0.1/assembly/target/scala-2.12/jars/parquet-encoding-1.10.1.jar":"System Classpath","/Users/kinsho/workspace/spark-3.0.1/assembly/target/scala-2.12/jars/apacheds-kerberos-codec-2.0.0-M15.jar":"System Classpath","/Users/kinsho/workspace/spark-3.0.1/assembly/target/scala-2.12/jars/machinist_2.12-0.6.8.jar":"System Classpath","/Users/kinsho/workspace/spark-3.0.1/assembly/target/scala-2.12/jars/spark-network-shuffle_2.12-3.0.1.jar":"System Classpath","/Users/kinsho/workspace/spark-3.0.1/assembly/target/scala-2.12/jars/jsr305-3.0.0.jar":"System Classpath","/Users/kinsho/workspace/spark-3.0.1/assembly/target/scala-2.12/jars/metrics-jvm-4.1.1.jar":"System Classpath","/Users/kinsho/workspace/spark-3.0.1/assembly/target/scala-2.12/jars/commons-text-1.6.jar":"System Classpath","/Users/kinsho/workspace/spark-3.0.1/assembly/target/scala-2.12/jars/jersey-common-2.30.jar":"System Classpath","/Users/kinsho/workspace/spark-3.0.1/assembly/target/scala-2.12/jars/xz-1.5.jar":"System Classpath","/Users/kinsho/workspace/spark-3.0.1/assembly/target/scala-2.12/jars/jersey-container-servlet-core-2.30.jar":"System Classpath","/Users/kinsho/workspace/spark-3.0.1/assembly/target/scala-2.12/jars/guava-14.0.1.jar":"System Classpath","/Users/kinsho/workspace/spark-3.0.1/assembly/target/scala-2.12/jars/hadoop-yarn-common-2.7.4.jar":"System Classpath","/Users/kinsho/workspace/spark-3.0.1/assembly/target/scala-2.12/jars/jaxb-runtime-2.3.2.jar":"System Classpath","/Users/kinsho/workspace/spark-3.0.1/assembly/target/scala-2.12/jars/xml-apis-1.4.01.jar":"System Classpath","/Users/kinsho/workspace/spark-3.0.1/assembly/target/scala-2.12/jars/htrace-core-3.1.0-incubating.jar":"System Classpath","/Users/kinsho/workspace/spark-3.0.1/assembly/target/scala-2.12/jars/commons-httpclient-3.1.jar":"System Classpath","/Users/kinsho/workspace/spark-3.0.1/assembly/target/scala-2.12/jars/shapeless_2.12-2.3.3.jar":"System Classpath","/Users/kinsho/workspace/spark-3.0.1/assembly/target/scala-2.12/jars/univocity-parsers-2.9.0.jar":"System Classpath","/Users/kinsho/workspace/spark-3.0.1/assembly/target/scala-2.12/jars/objenesis-2.5.1.jar":"System Classpath","/Users/kinsho/workspace/spark-3.0.1/assembly/target/scala-2.12/jars/hadoop-client-2.7.4.jar":"System Classpath","/Users/kinsho/workspace/spark-3.0.1/assembly/target/scala-2.12/jars/hadoop-yarn-api-2.7.4.jar":"System Classpath","/Users/kinsho/workspace/spark-3.0.1/assembly/target/scala-2.12/jars/spire_2.12-0.17.0-M1.jar":"System Classpath","/Users/kinsho/workspace/spark-3.0.1/assembly/target/scala-2.12/jars/curator-framework-2.7.1.jar":"System Classpath","/Users/kinsho/workspace/spark-3.0.1/assembly/target/scala-2.12/jars/jetty-sslengine-6.1.26.jar":"System Classpath","/Users/kinsho/workspace/spark-3.0.1/assembly/target/scala-2.12/jars/core-1.1.2.jar":"System Classpath","/Users/kinsho/workspace/spark-3.0.1/assembly/target/scala-2.12/jars/minlog-1.3.0.jar":"System Classpath","/Users/kinsho/workspace/spark-3.0.1/assembly/target/scala-2.12/jars/hk2-utils-2.6.1.jar":"System Classpath","/Users/kinsho/workspace/spark-3.0.1/assembly/target/scala-2.12/jars/commons-compiler-3.0.16.jar":"System Classpath","/Users/kinsho/workspace/spark-3.0.1/assembly/target/scala-2.12/jars/RoaringBitmap-0.7.45.jar":"System Classpath","/Users/kinsho/workspace/spark-3.0.1/assembly/target/scala-2.12/jars/breeze_2.12-1.0.jar":"System Classpath","/Users/kinsho/workspace/spark-3.0.1/assembly/target/scala-2.12/jars/hk2-locator-2.6.1.jar":"System Classpath","/Users/kinsho/workspace/spark-3.0.1/assembly/target/scala-2.12/jars/zstd-jni-1.4.4-3.jar":"System Classpath","/Users/kinsho/workspace/spark-3.0.1/assembly/target/scala-2.12/jars/istack-commons-runtime-3.0.8.jar":"System Classpath","/Users/kinsho/workspace/spark-3.0.1/assembly/target/scala-2.12/jars/jackson-core-2.10.0.jar":"System Classpath","/Users/kinsho/workspace/spark-3.0.1/assembly/target/scala-2.12/jars/spark-kvstore_2.12-3.0.1.jar":"System Classpath","/Users/kinsho/workspace/spark-3.0.1/assembly/target/scala-2.12/jars/JLargeArrays-1.5.jar":"System Classpath","/Users/kinsho/workspace/spark-3.0.1/assembly/target/scala-2.12/jars/threeten-extra-1.5.0.jar":"System Classpath","/Users/kinsho/workspace/spark-3.0.1/assembly/target/scala-2.12/jars/scala-library-2.12.10.jar":"System Classpath","/Users/kinsho/workspace/spark-3.0.1/assembly/target/scala-2.12/jars/kryo-shaded-4.0.2.jar":"System Classpath","/Users/kinsho/workspace/spark-3.0.1/assembly/target/scala-2.12/jars/jackson-mapper-asl-1.9.13.jar":"System Classpath","/Users/kinsho/workspace/spark-3.0.1/assembly/target/scala-2.12/jars/spark-graphx_2.12-3.0.1.jar":"System Classpath","/Users/kinsho/workspace/spark-3.0.1/assembly/target/scala-2.12/jars/parquet-common-1.10.1.jar":"System Classpath","/Users/kinsho/workspace/spark-3.0.1/assembly/target/scala-2.12/jars/avro-1.8.2.jar":"System Classpath","/Users/kinsho/workspace/spark-3.0.1/assembly/target/scala-2.12/jars/janino-3.0.16.jar":"System Classpath","/Users/kinsho/workspace/spark-3.0.1/assembly/target/scala-2.12/jars/jakarta.xml.bind-api-2.3.2.jar":"System Classpath","/Users/kinsho/workspace/spark-3.0.1/assembly/target/scala-2.12/jars/jersey-hk2-2.30.jar":"System Classpath","/Users/kinsho/workspace/spark-3.0.1/assembly/target/scala-2.12/jars/parquet-column-1.10.1.jar":"System Classpath","/Users/kinsho/workspace/spark-3.0.1/assembly/target/scala-2.12/jars/stax-api-1.0-2.jar":"System Classpath","/Users/kinsho/workspace/spark-3.0.1/assembly/target/scala-2.12/jars/spark-sql_2.12-3.0.1.jar":"System Classpath","/Users/kinsho/workspace/spark-3.0.1/assembly/target/scala-2.12/jars/jul-to-slf4j-1.7.30.jar":"System Classpath","/Users/kinsho/workspace/spark-3.0.1/assembly/target/scala-2.12/jars/jakarta.annotation-api-1.3.5.jar":"System Classpath","/Users/kinsho/workspace/spark-3.0.1/assembly/target/scala-2.12/jars/chill_2.12-0.9.5.jar":"System Classpath","/Users/kinsho/workspace/spark-3.0.1/assembly/target/scala-2.12/jars/spark-catalyst_2.12-3.0.1.jar":"System Classpath","/Users/kinsho/workspace/spark-3.0.1/assembly/target/scala-2.12/jars/hadoop-mapreduce-client-core-2.7.4.jar":"System Classpath","/Users/kinsho/workspace/spark-3.0.1/assembly/target/scala-2.12/jars/jaxb-api-2.2.2.jar":"System Classpath","/Users/kinsho/workspace/spark-3.0.1/assembly/target/scala-2.12/jars/leveldbjni-all-1.8.jar":"System Classpath","/Users/kinsho/workspace/spark-3.0.1/assembly/target/scala-2.12/jars/jackson-xc-1.9.13.jar":"System Classpath","/Users/kinsho/workspace/spark-3.0.1/assembly/target/scala-2.12/jars/xercesImpl-2.12.0.jar":"System Classpath","/Users/kinsho/workspace/spark-3.0.1/assembly/target/scala-2.12/jars/netty-all-4.1.47.Final.jar":"System Classpath","/Users/kinsho/workspace/spark-3.0.1/assembly/target/scala-2.12/jars/jersey-client-2.30.jar":"System Classpath","/Users/kinsho/workspace/spark-3.0.1/assembly/target/scala-2.12/jars/jersey-server-2.30.jar":"System Classpath","/Users/kinsho/workspace/spark-3.0.1/assembly/target/scala-2.12/jars/osgi-resource-locator-1.0.3.jar":"System Classpath","/Users/kinsho/workspace/spark-3.0.1/assembly/target/scala-2.12/jars/jakarta.ws.rs-api-2.1.6.jar":"System Classpath"}}
{"Event":"SparkListenerApplicationStart","App Name":"logTransform","App ID":"app-20210130163235-0014","Timestamp":1611991954567,"User":"kinsho"}
{"Event":"SparkListenerExecutorAdded","Timestamp":1611991960405,"Executor ID":"8","Executor Info":{"Host":"192.168.11.7","Total Cores":2,"Log Urls":{"stdout":"http://192.168.11.7:8082/logPage/?appId=app-20210130163235-0014&executorId=8&logType=stdout","stderr":"http://192.168.11.7:8082/logPage/?appId=app-20210130163235-0014&executorId=8&logType=stderr"},"Attributes":{},"Resources":{}}}
{"Event":"SparkListenerExecutorAdded","Timestamp":1611991960414,"Executor ID":"1","Executor Info":{"Host":"192.168.11.7","Total Cores":2,"Log Urls":{"stdout":"http://192.168.11.7:8089/logPage/?appId=app-20210130163235-0014&executorId=1&logType=stdout","stderr":"http://192.168.11.7:8089/logPage/?appId=app-20210130163235-0014&executorId=1&logType=stderr"},"Attributes":{},"Resources":{}}}
{"Event":"SparkListenerExecutorAdded","Timestamp":1611991960447,"Executor ID":"2","Executor Info":{"Host":"192.168.11.7","Total Cores":2,"Log Urls":{"stdout":"http://192.168.11.7:8083/logPage/?appId=app-20210130163235-0014&executorId=2&logType=stdout","stderr":"http://192.168.11.7:8083/logPage/?appId=app-20210130163235-0014&executorId=2&logType=stderr"},"Attributes":{},"Resources":{}}}
{"Event":"SparkListenerExecutorAdded","Timestamp":1611991960449,"Executor ID":"6","Executor Info":{"Host":"192.168.11.7","Total Cores":2,"Log Urls":{"stdout":"http://192.168.11.7:8085/logPage/?appId=app-20210130163235-0014&executorId=6&logType=stdout","stderr":"http://192.168.11.7:8085/logPage/?appId=app-20210130163235-0014&executorId=6&logType=stderr"},"Attributes":{},"Resources":{}}}
{"Event":"SparkListenerExecutorAdded","Timestamp":1611991960462,"Executor ID":"0","Executor Info":{"Host":"192.168.11.7","Total Cores":2,"Log Urls":{"stdout":"http://192.168.11.7:8090/logPage/?appId=app-20210130163235-0014&executorId=0&logType=stdout","stderr":"http://192.168.11.7:8090/logPage/?appId=app-20210130163235-0014&executorId=0&logType=stderr"},"Attributes":{},"Resources":{}}}
{"Event":"SparkListenerExecutorAdded","Timestamp":1611991960546,"Executor ID":"4","Executor Info":{"Host":"192.168.11.7","Total Cores":2,"Log Urls":{"stdout":"http://192.168.11.7:8084/logPage/?appId=app-20210130163235-0014&executorId=4&logType=stdout","stderr":"http://192.168.11.7:8084/logPage/?appId=app-20210130163235-0014&executorId=4&logType=stderr"},"Attributes":{},"Resources":{}}}
{"Event":"SparkListenerExecutorAdded","Timestamp":1611991960578,"Executor ID":"7","Executor Info":{"Host":"192.168.11.7","Total Cores":2,"Log Urls":{"stdout":"http://192.168.11.7:8081/logPage/?appId=app-20210130163235-0014&executorId=7&logType=stdout","stderr":"http://192.168.11.7:8081/logPage/?appId=app-20210130163235-0014&executorId=7&logType=stderr"},"Attributes":{},"Resources":{}}}
{"Event":"SparkListenerBlockManagerAdded","Block Manager ID":{"Executor ID":"1","Host":"192.168.11.7","Port":55107},"Maximum Memory":384093388,"Timestamp":1611991960633,"Maximum Onheap Memory":384093388,"Maximum Offheap Memory":0}
{"Event":"SparkListenerBlockManagerAdded","Block Manager ID":{"Executor ID":"8","Host":"192.168.11.7","Port":55106},"Maximum Memory":384093388,"Timestamp":1611991960644,"Maximum Onheap Memory":384093388,"Maximum Offheap Memory":0}
{"Event":"SparkListenerBlockManagerAdded","Block Manager ID":{"Executor ID":"6","Host":"192.168.11.7","Port":55109},"Maximum Memory":384093388,"Timestamp":1611991960655,"Maximum Onheap Memory":384093388,"Maximum Offheap Memory":0}
{"Event":"SparkListenerBlockManagerAdded","Block Manager ID":{"Executor ID":"2","Host":"192.168.11.7","Port":55110},"Maximum Memory":384093388,"Timestamp":1611991960665,"Maximum Onheap Memory":384093388,"Maximum Offheap Memory":0}
{"Event":"SparkListenerBlockManagerAdded","Block Manager ID":{"Executor ID":"0","Host":"192.168.11.7","Port":55111},"Maximum Memory":384093388,"Timestamp":1611991960686,"Maximum Onheap Memory":384093388,"Maximum Offheap Memory":0}
{"Event":"SparkListenerBlockManagerAdded","Block Manager ID":{"Executor ID":"4","Host":"192.168.11.7","Port":55112},"Maximum Memory":384093388,"Timestamp":1611991960769,"Maximum Onheap Memory":384093388,"Maximum Offheap Memory":0}
{"Event":"SparkListenerExecutorAdded","Timestamp":1611991960771,"Executor ID":"9","Executor Info":{"Host":"192.168.11.7","Total Cores":2,"Log Urls":{"stdout":"http://192.168.11.7:8086/logPage/?appId=app-20210130163235-0014&executorId=9&logType=stdout","stderr":"http://192.168.11.7:8086/logPage/?appId=app-20210130163235-0014&executorId=9&logType=stderr"},"Attributes":{},"Resources":{}}}
{"Event":"SparkListenerBlockManagerAdded","Block Manager ID":{"Executor ID":"7","Host":"192.168.11.7","Port":55114},"Maximum Memory":384093388,"Timestamp":1611991960827,"Maximum Onheap Memory":384093388,"Maximum Offheap Memory":0}
{"Event":"SparkListenerExecutorAdded","Timestamp":1611991960837,"Executor ID":"3","Executor Info":{"Host":"192.168.11.7","Total Cores":2,"Log Urls":{"stdout":"http://192.168.11.7:8088/logPage/?appId=app-20210130163235-0014&executorId=3&logType=stdout","stderr":"http://192.168.11.7:8088/logPage/?appId=app-20210130163235-0014&executorId=3&logType=stderr"},"Attributes":{},"Resources":{}}}
{"Event":"SparkListenerExecutorAdded","Timestamp":1611991960873,"Executor ID":"5","Executor Info":{"Host":"192.168.11.7","Total Cores":2,"Log Urls":{"stdout":"http://192.168.11.7:8087/logPage/?appId=app-20210130163235-0014&executorId=5&logType=stdout","stderr":"http://192.168.11.7:8087/logPage/?appId=app-20210130163235-0014&executorId=5&logType=stderr"},"Attributes":{},"Resources":{}}}
{"Event":"SparkListenerBlockManagerAdded","Block Manager ID":{"Executor ID":"9","Host":"192.168.11.7","Port":55117},"Maximum Memory":384093388,"Timestamp":1611991960952,"Maximum Onheap Memory":384093388,"Maximum Offheap Memory":0}
{"Event":"SparkListenerBlockManagerAdded","Block Manager ID":{"Executor ID":"3","Host":"192.168.11.7","Port":55118},"Maximum Memory":384093388,"Timestamp":1611991960992,"Maximum Onheap Memory":384093388,"Maximum Offheap Memory":0}
{"Event":"SparkListenerBlockManagerAdded","Block Manager ID":{"Executor ID":"5","Host":"192.168.11.7","Port":55119},"Maximum Memory":384093388,"Timestamp":1611991961010,"Maximum Onheap Memory":384093388,"Maximum Offheap Memory":0}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":0,"description":"csv at LogTransform.scala:17","details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:553)\nLogTransform$.main(LogTransform.scala:17)\nLogTransform.main(LogTransform.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\norg.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52)\norg.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:928)\norg.apache.spark.deploy.SparkSubmit.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit.submit(SparkSubmit.scala:203)\norg.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:90)\norg.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:1007)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:1016)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","physicalPlanDescription":"== Parsed Logical Plan ==\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#6, None)) > 0)\n      +- Project [value#0 AS value#6]\n         +- Project [value#0]\n            +- Relation[value#0] text\n\n== Analyzed Logical Plan ==\nvalue: string\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#6, None)) > 0)\n      +- Project [value#0 AS value#6]\n         +- Project [value#0]\n            +- Relation[value#0] text\n\n== Optimized Logical Plan ==\nGlobalLimit 1\n+- LocalLimit 1\n   +- Filter (length(trim(value#0, None)) > 0)\n      +- Relation[value#0] text\n\n== Physical Plan ==\nCollectLimit 1\n+- *(1) Filter (length(trim(value#0, None)) > 0)\n   +- FileScan text [value#0] Batched: false, DataFilters: [(length(trim(value#0, None)) > 0)], Format: Text, Location: InMemoryFileIndex[file:/Users/kinsho/Desktop/impressionLog.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>\n","sparkPlanInfo":{"nodeName":"CollectLimit","simpleString":"CollectLimit 1","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Filter","simpleString":"Filter (length(trim(value#0, None)) > 0)","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"Scan text ","simpleString":"FileScan text [value#0] Batched: false, DataFilters: [(length(trim(value#0, None)) > 0)], Format: Text, Location: InMemoryFileIndex[file:/Users/kinsho/Desktop/impressionLog.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>","children":[],"metadata":{"Location":"InMemoryFileIndex[file:/Users/kinsho/Desktop/impressionLog.csv]","ReadSchema":"struct<value:string>","Format":"Text","Batched":"false","PartitionFilters":"[]","PushedFilters":"[]","DataFilters":"[(length(trim(value#0, None)) > 0)]"},"metrics":[{"name":"number of files read","accumulatorId":13,"metricType":"sum"},{"name":"dynamic partition pruning time","accumulatorId":16,"metricType":"timing"},{"name":"metadata time","accumulatorId":14,"metricType":"timing"},{"name":"size of files read","accumulatorId":15,"metricType":"size"},{"name":"number of output rows","accumulatorId":12,"metricType":"sum"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"number of output rows","accumulatorId":11,"metricType":"sum"}]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":10,"metricType":"timing"}]}],"metadata":{},"metrics":[{"name":"shuffle records written","accumulatorId":8,"metricType":"sum"},{"name":"shuffle write time","accumulatorId":9,"metricType":"nsTiming"},{"name":"records read","accumulatorId":6,"metricType":"sum"},{"name":"local bytes read","accumulatorId":4,"metricType":"size"},{"name":"fetch wait time","accumulatorId":5,"metricType":"timing"},{"name":"remote bytes read","accumulatorId":2,"metricType":"size"},{"name":"local blocks read","accumulatorId":1,"metricType":"sum"},{"name":"remote blocks read","accumulatorId":0,"metricType":"sum"},{"name":"remote bytes read to disk","accumulatorId":3,"metricType":"size"},{"name":"shuffle bytes written","accumulatorId":7,"metricType":"size"}]},"time":1611991962006}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerDriverAccumUpdates","executionId":0,"accumUpdates":[[13,1],[14,2],[15,23517392614]]}
{"Event":"SparkListenerJobStart","Job ID":0,"Submission Time":1611991962648,"Stage Infos":[{"Stage ID":0,"Stage Attempt ID":0,"Stage Name":"csv at LogTransform.scala:17","Number of Tasks":1,"RDD Info":[{"RDD ID":3,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"4\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at LogTransform.scala:17","Parent IDs":[2],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":176,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":1,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"3\",\"name\":\"Scan text \"}","Callsite":"csv at LogTransform.scala:17","Parent IDs":[0],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":176,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":0,"Name":"FileScanRDD","Scope":"{\"id\":\"3\",\"name\":\"Scan text \"}","Callsite":"csv at LogTransform.scala:17","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":176,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":2,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"0\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"csv at LogTransform.scala:17","Parent IDs":[1],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":176,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:553)\nLogTransform$.main(LogTransform.scala:17)\nLogTransform.main(LogTransform.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\norg.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52)\norg.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:928)\norg.apache.spark.deploy.SparkSubmit.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit.submit(SparkSubmit.scala:203)\norg.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:90)\norg.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:1007)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:1016)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","Accumulables":[]}],"Stage IDs":[0],"Properties":{"spark.driver.host":"192.168.11.7","spark.history.fs.logDirectory":"./spark-events","spark.eventLog.enabled":"true","spark.driver.port":"55052","spark.jars":"file:/Users/kinsho/workspace/spark-3.0.1/workspace/sample-spark-scala/target/scala-2.12/simple-project_2.12-1.0.jar","spark.app.name":"logTransform","spark.submit.pyFiles":"","spark.executor.id":"driver","spark.submit.deployMode":"client","spark.master":"spark://ST000000035:7077","spark.eventLog.dir":"./spark-events","spark.sql.execution.id":"0","spark.executor.cores":"2","spark.app.id":"app-20210130163235-0014"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":0,"Stage Attempt ID":0,"Stage Name":"csv at LogTransform.scala:17","Number of Tasks":1,"RDD Info":[{"RDD ID":3,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"4\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at LogTransform.scala:17","Parent IDs":[2],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":176,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":1,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"3\",\"name\":\"Scan text \"}","Callsite":"csv at LogTransform.scala:17","Parent IDs":[0],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":176,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":0,"Name":"FileScanRDD","Scope":"{\"id\":\"3\",\"name\":\"Scan text \"}","Callsite":"csv at LogTransform.scala:17","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":176,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":2,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"0\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"csv at LogTransform.scala:17","Parent IDs":[1],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":176,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:553)\nLogTransform$.main(LogTransform.scala:17)\nLogTransform.main(LogTransform.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\norg.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52)\norg.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:928)\norg.apache.spark.deploy.SparkSubmit.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit.submit(SparkSubmit.scala:203)\norg.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:90)\norg.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:1007)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:1016)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","Submission Time":1611991962670,"Accumulables":[]},"Properties":{"spark.driver.host":"192.168.11.7","spark.history.fs.logDirectory":"./spark-events","spark.eventLog.enabled":"true","spark.driver.port":"55052","spark.jars":"file:/Users/kinsho/workspace/spark-3.0.1/workspace/sample-spark-scala/target/scala-2.12/simple-project_2.12-1.0.jar","spark.app.name":"logTransform","spark.submit.pyFiles":"","spark.executor.id":"driver","spark.submit.deployMode":"client","spark.master":"spark://ST000000035:7077","spark.eventLog.dir":"./spark-events","spark.sql.execution.id":"0","spark.executor.cores":"2","spark.app.id":"app-20210130163235-0014"}}
{"Event":"SparkListenerTaskStart","Stage ID":0,"Stage Attempt ID":0,"Task Info":{"Task ID":0,"Index":0,"Attempt":0,"Launch Time":1611991962742,"Executor ID":"7","Host":"192.168.11.7","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":0,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":0,"Index":0,"Attempt":0,"Launch Time":1611991962742,"Executor ID":"7","Host":"192.168.11.7","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1611991963946,"Failed":false,"Killed":false,"Accumulables":[{"ID":11,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":12,"Name":"number of output rows","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":39,"Name":"internal.metrics.input.recordsRead","Update":1,"Value":1,"Internal":true,"Count Failed Values":true},{"ID":38,"Name":"internal.metrics.input.bytesRead","Update":65536,"Value":65536,"Internal":true,"Count Failed Values":true},{"ID":22,"Name":"internal.metrics.jvmGCTime","Update":25,"Value":25,"Internal":true,"Count Failed Values":true},{"ID":21,"Name":"internal.metrics.resultSize","Update":1897,"Value":1897,"Internal":true,"Count Failed Values":true},{"ID":20,"Name":"internal.metrics.executorCpuTime","Update":539224000,"Value":539224000,"Internal":true,"Count Failed Values":true},{"ID":19,"Name":"internal.metrics.executorRunTime","Update":555,"Value":555,"Internal":true,"Count Failed Values":true},{"ID":18,"Name":"internal.metrics.executorDeserializeCpuTime","Update":487733000,"Value":487733000,"Internal":true,"Count Failed Values":true},{"ID":17,"Name":"internal.metrics.executorDeserializeTime","Update":609,"Value":609,"Internal":true,"Count Failed Values":true}]},"Task Executor Metrics":{"JVMHeapMemory":0,"JVMOffHeapMemory":0,"OnHeapExecutionMemory":0,"OffHeapExecutionMemory":0,"OnHeapStorageMemory":0,"OffHeapStorageMemory":0,"OnHeapUnifiedMemory":0,"OffHeapUnifiedMemory":0,"DirectPoolMemory":0,"MappedPoolMemory":0,"ProcessTreeJVMVMemory":0,"ProcessTreeJVMRSSMemory":0,"ProcessTreePythonVMemory":0,"ProcessTreePythonRSSMemory":0,"ProcessTreeOtherVMemory":0,"ProcessTreeOtherRSSMemory":0,"MinorGCCount":0,"MinorGCTime":0,"MajorGCCount":0,"MajorGCTime":0},"Task Metrics":{"Executor Deserialize Time":609,"Executor Deserialize CPU Time":487733000,"Executor Run Time":555,"Executor CPU Time":539224000,"Peak Execution Memory":0,"Result Size":1897,"JVM GC Time":25,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":65536,"Records Read":1},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":0,"Stage Attempt ID":0,"Stage Name":"csv at LogTransform.scala:17","Number of Tasks":1,"RDD Info":[{"RDD ID":3,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"4\",\"name\":\"mapPartitionsInternal\"}","Callsite":"csv at LogTransform.scala:17","Parent IDs":[2],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":176,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":1,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"3\",\"name\":\"Scan text \"}","Callsite":"csv at LogTransform.scala:17","Parent IDs":[0],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":176,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":0,"Name":"FileScanRDD","Scope":"{\"id\":\"3\",\"name\":\"Scan text \"}","Callsite":"csv at LogTransform.scala:17","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":176,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":2,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"0\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"csv at LogTransform.scala:17","Parent IDs":[1],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":176,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:553)\nLogTransform$.main(LogTransform.scala:17)\nLogTransform.main(LogTransform.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\norg.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52)\norg.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:928)\norg.apache.spark.deploy.SparkSubmit.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit.submit(SparkSubmit.scala:203)\norg.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:90)\norg.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:1007)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:1016)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","Submission Time":1611991962670,"Completion Time":1611991963952,"Accumulables":[{"ID":17,"Name":"internal.metrics.executorDeserializeTime","Value":609,"Internal":true,"Count Failed Values":true},{"ID":11,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":38,"Name":"internal.metrics.input.bytesRead","Value":65536,"Internal":true,"Count Failed Values":true},{"ID":20,"Name":"internal.metrics.executorCpuTime","Value":539224000,"Internal":true,"Count Failed Values":true},{"ID":22,"Name":"internal.metrics.jvmGCTime","Value":25,"Internal":true,"Count Failed Values":true},{"ID":19,"Name":"internal.metrics.executorRunTime","Value":555,"Internal":true,"Count Failed Values":true},{"ID":18,"Name":"internal.metrics.executorDeserializeCpuTime","Value":487733000,"Internal":true,"Count Failed Values":true},{"ID":12,"Name":"number of output rows","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":39,"Name":"internal.metrics.input.recordsRead","Value":1,"Internal":true,"Count Failed Values":true},{"ID":21,"Name":"internal.metrics.resultSize","Value":1897,"Internal":true,"Count Failed Values":true}]}}
{"Event":"SparkListenerJobEnd","Job ID":0,"Completion Time":1611991963955,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":0,"time":1611991963991}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionStart","executionId":1,"description":"show at LogTransform.scala:42","details":"org.apache.spark.sql.Dataset.show(Dataset.scala:792)\nLogTransform$.main(LogTransform.scala:42)\nLogTransform.main(LogTransform.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\norg.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52)\norg.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:928)\norg.apache.spark.deploy.SparkSubmit.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit.submit(SparkSubmit.scala:203)\norg.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:90)\norg.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:1007)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:1016)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","physicalPlanDescription":"== Parsed Logical Plan ==\nGlobalLimit 21\n+- LocalLimit 21\n   +- Project [cast(distributionid#16 as string) AS distributionid#246, cast(advertiserid#17 as string) AS advertiserid#247, cast(distributionhourjst#18 as string) AS distributionhourjst#248, cast(distributiondatetime#19 as string) AS distributiondatetime#249, cast(requestid#20 as string) AS requestid#250, cast(uid#21 as string) AS uid#251, cast(uavalue#23 as string) AS uavalue#252, cast(uacategory#24 as string) AS uacategory#253, cast(documentid#28 as string) AS documentid#254, cast(documenturl#29 as string) AS documenturl#255, cast(sitecode#30 as string) AS sitecode#256, cast(documenttitle#31 as string) AS documenttitle#257, cast(campaignid#33 as string) AS campaignid#258, cast(campaigntype#34 as string) AS campaigntype#259, cast(publisherid#35 as string) AS publisherid#260, cast(publisherchannelid#36 as string) AS publisherchannelid#261, cast(maxcpc#38 as string) AS maxcpc#262, cast(bidcpc#39 as string) AS bidcpc#263, cast(contractcpc#40 as string) AS contractcpc#264, cast(finalscore#41 as string) AS finalscore#265, cast(originalscore#42 as string) AS originalscore#266, cast(distributionorder#43 as string) AS distributionorder#267, cast(israndom#44 as string) AS israndom#268, cast(jobchanneltype#45 as string) AS jobchanneltype#269, ... 4 more fields]\n      +- Project [distributionid#16, advertiserid#17, distributionhourjst#18, distributiondatetime#19, requestid#20, uid#21, uavalue#23, uacategory#24, documentid#28, documenturl#29, sitecode#30, documenttitle#31, campaignid#33, campaigntype#34, publisherid#35, publisherchannelid#36, maxcpc#38, bidcpc#39, contractcpc#40, finalscore#41, originalscore#42, distributionorder#43, israndom#44, jobchanneltype#45, ... 4 more fields]\n         +- Project [distributionid#16, advertiserid#17, distributionhourjst#18, distributiondatetime#19, requestid#20, uid#21, uavalue#23, uacategory#24, documentid#28, documenturl#29, sitecode#30, documenttitle#31, campaignid#33, campaigntype#34, publisherid#35, publisherchannelid#36, maxcpc#38, bidcpc#39, contractcpc#40, finalscore#41, originalscore#42, distributionorder#43, israndom#44, jobchanneltype#45, ... 3 more fields]\n            +- Relation[distributionid#16,advertiserid#17,distributionhourjst#18,distributiondatetime#19,requestid#20,uid#21,visitid#22,uavalue#23,uacategory#24,ip#25,referer#26,devicetype#27,documentid#28,documenturl#29,sitecode#30,documenttitle#31,documentcontent#32,campaignid#33,campaigntype#34,publisherid#35,publisherchannelid#36,publisherchanneltype#37,maxcpc#38,bidcpc#39,... 12 more fields] csv\n\n== Analyzed Logical Plan ==\ndistributionid: string, advertiserid: string, distributionhourjst: string, distributiondatetime: string, requestid: string, uid: string, uavalue: string, uacategory: string, documentid: string, documenturl: string, sitecode: string, documenttitle: string, campaignid: string, campaigntype: string, publisherid: string, publisherchannelid: string, maxcpc: string, bidcpc: string, contractcpc: string, finalscore: string, originalscore: string, distributionorder: string, israndom: string, jobchanneltype: string, ... 4 more fields\nGlobalLimit 21\n+- LocalLimit 21\n   +- Project [cast(distributionid#16 as string) AS distributionid#246, cast(advertiserid#17 as string) AS advertiserid#247, cast(distributionhourjst#18 as string) AS distributionhourjst#248, cast(distributiondatetime#19 as string) AS distributiondatetime#249, cast(requestid#20 as string) AS requestid#250, cast(uid#21 as string) AS uid#251, cast(uavalue#23 as string) AS uavalue#252, cast(uacategory#24 as string) AS uacategory#253, cast(documentid#28 as string) AS documentid#254, cast(documenturl#29 as string) AS documenturl#255, cast(sitecode#30 as string) AS sitecode#256, cast(documenttitle#31 as string) AS documenttitle#257, cast(campaignid#33 as string) AS campaignid#258, cast(campaigntype#34 as string) AS campaigntype#259, cast(publisherid#35 as string) AS publisherid#260, cast(publisherchannelid#36 as string) AS publisherchannelid#261, cast(maxcpc#38 as string) AS maxcpc#262, cast(bidcpc#39 as string) AS bidcpc#263, cast(contractcpc#40 as string) AS contractcpc#264, cast(finalscore#41 as string) AS finalscore#265, cast(originalscore#42 as string) AS originalscore#266, cast(distributionorder#43 as string) AS distributionorder#267, cast(israndom#44 as string) AS israndom#268, cast(jobchanneltype#45 as string) AS jobchanneltype#269, ... 4 more fields]\n      +- Project [distributionid#16, advertiserid#17, distributionhourjst#18, distributiondatetime#19, requestid#20, uid#21, uavalue#23, uacategory#24, documentid#28, documenturl#29, sitecode#30, documenttitle#31, campaignid#33, campaigntype#34, publisherid#35, publisherchannelid#36, maxcpc#38, bidcpc#39, contractcpc#40, finalscore#41, originalscore#42, distributionorder#43, israndom#44, jobchanneltype#45, ... 4 more fields]\n         +- Project [distributionid#16, advertiserid#17, distributionhourjst#18, distributiondatetime#19, requestid#20, uid#21, uavalue#23, uacategory#24, documentid#28, documenturl#29, sitecode#30, documenttitle#31, campaignid#33, campaigntype#34, publisherid#35, publisherchannelid#36, maxcpc#38, bidcpc#39, contractcpc#40, finalscore#41, originalscore#42, distributionorder#43, israndom#44, jobchanneltype#45, ... 3 more fields]\n            +- Relation[distributionid#16,advertiserid#17,distributionhourjst#18,distributiondatetime#19,requestid#20,uid#21,visitid#22,uavalue#23,uacategory#24,ip#25,referer#26,devicetype#27,documentid#28,documenturl#29,sitecode#30,documenttitle#31,documentcontent#32,campaignid#33,campaigntype#34,publisherid#35,publisherchannelid#36,publisherchanneltype#37,maxcpc#38,bidcpc#39,... 12 more fields] csv\n\n== Optimized Logical Plan ==\nGlobalLimit 21\n+- LocalLimit 21\n   +- Project [distributionid#16, advertiserid#17, distributionhourjst#18, distributiondatetime#19, requestid#20, uid#21, uavalue#23, uacategory#24, documentid#28, documenturl#29, sitecode#30, documenttitle#31, campaignid#33, campaigntype#34, publisherid#35, publisherchannelid#36, maxcpc#38, bidcpc#39, contractcpc#40, finalscore#41, originalscore#42, distributionorder#43, israndom#44, jobchanneltype#45, ... 4 more fields]\n      +- Relation[distributionid#16,advertiserid#17,distributionhourjst#18,distributiondatetime#19,requestid#20,uid#21,visitid#22,uavalue#23,uacategory#24,ip#25,referer#26,devicetype#27,documentid#28,documenturl#29,sitecode#30,documenttitle#31,documentcontent#32,campaignid#33,campaigntype#34,publisherid#35,publisherchannelid#36,publisherchanneltype#37,maxcpc#38,bidcpc#39,... 12 more fields] csv\n\n== Physical Plan ==\nCollectLimit 21\n+- *(1) Project [distributionid#16, advertiserid#17, distributionhourjst#18, distributiondatetime#19, requestid#20, uid#21, uavalue#23, uacategory#24, documentid#28, documenturl#29, sitecode#30, documenttitle#31, campaignid#33, campaigntype#34, publisherid#35, publisherchannelid#36, maxcpc#38, bidcpc#39, contractcpc#40, finalscore#41, originalscore#42, distributionorder#43, israndom#44, jobchanneltype#45, ... 4 more fields]\n   +- FileScan csv [distributionid#16,advertiserid#17,distributionhourjst#18,distributiondatetime#19,requestid#20,uid#21,uavalue#23,uacategory#24,documentid#28,documenturl#29,sitecode#30,documenttitle#31,campaignid#33,campaigntype#34,publisherid#35,publisherchannelid#36,maxcpc#38,bidcpc#39,contractcpc#40,finalscore#41,originalscore#42,distributionorder#43,israndom#44,jobchanneltype#45,... 3 more fields] Batched: false, DataFilters: [], Format: CSV, Location: InMemoryFileIndex[file:/Users/kinsho/Desktop/impressionLog.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<distributionid:string,advertiserid:string,distributionhourjst:string,distributiondatetime:...\n","sparkPlanInfo":{"nodeName":"CollectLimit","simpleString":"CollectLimit 21","children":[{"nodeName":"WholeStageCodegen (1)","simpleString":"WholeStageCodegen (1)","children":[{"nodeName":"Project","simpleString":"Project [distributionid#16, advertiserid#17, distributionhourjst#18, distributiondatetime#19, requestid#20, uid#21, uavalue#23, uacategory#24, documentid#28, documenturl#29, sitecode#30, documenttitle#31, campaignid#33, campaigntype#34, publisherid#35, publisherchannelid#36, maxcpc#38, bidcpc#39, contractcpc#40, finalscore#41, originalscore#42, distributionorder#43, israndom#44, jobchanneltype#45, ... 4 more fields]","children":[{"nodeName":"InputAdapter","simpleString":"InputAdapter","children":[{"nodeName":"Scan csv ","simpleString":"FileScan csv [distributionid#16,advertiserid#17,distributionhourjst#18,distributiondatetime#19,requestid#20,uid#21,uavalue#23,uacategory#24,documentid#28,documenturl#29,sitecode#30,documenttitle#31,campaignid#33,campaigntype#34,publisherid#35,publisherchannelid#36,maxcpc#38,bidcpc#39,contractcpc#40,finalscore#41,originalscore#42,distributionorder#43,israndom#44,jobchanneltype#45,... 3 more fields] Batched: false, DataFilters: [], Format: CSV, Location: InMemoryFileIndex[file:/Users/kinsho/Desktop/impressionLog.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<distributionid:string,advertiserid:string,distributionhourjst:string,distributiondatetime:...","children":[],"metadata":{"Location":"InMemoryFileIndex[file:/Users/kinsho/Desktop/impressionLog.csv]","ReadSchema":"struct<distributionid:string,advertiserid:string,distributionhourjst:string,distributiondatetime:string,requestid:string,uid:string,uavalue:string,uacategory:string,documentid:string,documenturl:string,sitecode:string,documenttitle:string,campaignid:string,campaigntype:string,publisherid:string,publisherchannelid:string,maxcpc:string,bidcpc:string,contractcpc:string,finalscore:string,originalscore:string,distributionorder:string,israndom:string,jobchanneltype:string,buckettype:string,predictctr:string,dt:string>","Format":"CSV","Batched":"false","PartitionFilters":"[]","PushedFilters":"[]","DataFilters":"[]"},"metrics":[{"name":"number of files read","accumulatorId":59,"metricType":"sum"},{"name":"dynamic partition pruning time","accumulatorId":62,"metricType":"timing"},{"name":"metadata time","accumulatorId":60,"metricType":"timing"},{"name":"size of files read","accumulatorId":61,"metricType":"size"},{"name":"number of output rows","accumulatorId":58,"metricType":"sum"}]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[]}],"metadata":{},"metrics":[{"name":"duration","accumulatorId":57,"metricType":"timing"}]}],"metadata":{},"metrics":[{"name":"shuffle records written","accumulatorId":55,"metricType":"sum"},{"name":"shuffle write time","accumulatorId":56,"metricType":"nsTiming"},{"name":"records read","accumulatorId":53,"metricType":"sum"},{"name":"local bytes read","accumulatorId":51,"metricType":"size"},{"name":"fetch wait time","accumulatorId":52,"metricType":"timing"},{"name":"remote bytes read","accumulatorId":49,"metricType":"size"},{"name":"local blocks read","accumulatorId":48,"metricType":"sum"},{"name":"remote blocks read","accumulatorId":47,"metricType":"sum"},{"name":"remote bytes read to disk","accumulatorId":50,"metricType":"size"},{"name":"shuffle bytes written","accumulatorId":54,"metricType":"size"}]},"time":1611991964530}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerDriverAccumUpdates","executionId":1,"accumUpdates":[[59,1],[60,0],[61,23517392614]]}
{"Event":"SparkListenerJobStart","Job ID":1,"Submission Time":1611991964641,"Stage Infos":[{"Stage ID":1,"Stage Attempt ID":0,"Stage Name":"show at LogTransform.scala:42","Number of Tasks":1,"RDD Info":[{"RDD ID":13,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"17\",\"name\":\"mapPartitionsInternal\"}","Callsite":"show at LogTransform.scala:42","Parent IDs":[12],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":176,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":12,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"13\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"show at LogTransform.scala:42","Parent IDs":[11],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":176,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":10,"Name":"FileScanRDD","Scope":"{\"id\":\"16\",\"name\":\"Scan csv \"}","Callsite":"show at LogTransform.scala:42","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":176,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":11,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"16\",\"name\":\"Scan csv \"}","Callsite":"show at LogTransform.scala:42","Parent IDs":[10],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":176,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.Dataset.show(Dataset.scala:792)\nLogTransform$.main(LogTransform.scala:42)\nLogTransform.main(LogTransform.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\norg.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52)\norg.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:928)\norg.apache.spark.deploy.SparkSubmit.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit.submit(SparkSubmit.scala:203)\norg.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:90)\norg.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:1007)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:1016)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","Accumulables":[]}],"Stage IDs":[1],"Properties":{"spark.driver.host":"192.168.11.7","spark.history.fs.logDirectory":"./spark-events","spark.eventLog.enabled":"true","spark.driver.port":"55052","spark.jars":"file:/Users/kinsho/workspace/spark-3.0.1/workspace/sample-spark-scala/target/scala-2.12/simple-project_2.12-1.0.jar","spark.app.name":"logTransform","spark.submit.pyFiles":"","spark.executor.id":"driver","spark.submit.deployMode":"client","spark.master":"spark://ST000000035:7077","spark.eventLog.dir":"./spark-events","spark.sql.execution.id":"1","spark.executor.cores":"2","spark.app.id":"app-20210130163235-0014"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":1,"Stage Attempt ID":0,"Stage Name":"show at LogTransform.scala:42","Number of Tasks":1,"RDD Info":[{"RDD ID":13,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"17\",\"name\":\"mapPartitionsInternal\"}","Callsite":"show at LogTransform.scala:42","Parent IDs":[12],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":176,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":12,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"13\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"show at LogTransform.scala:42","Parent IDs":[11],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":176,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":10,"Name":"FileScanRDD","Scope":"{\"id\":\"16\",\"name\":\"Scan csv \"}","Callsite":"show at LogTransform.scala:42","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":176,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":11,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"16\",\"name\":\"Scan csv \"}","Callsite":"show at LogTransform.scala:42","Parent IDs":[10],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":176,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.Dataset.show(Dataset.scala:792)\nLogTransform$.main(LogTransform.scala:42)\nLogTransform.main(LogTransform.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\norg.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52)\norg.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:928)\norg.apache.spark.deploy.SparkSubmit.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit.submit(SparkSubmit.scala:203)\norg.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:90)\norg.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:1007)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:1016)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","Submission Time":1611991964642,"Accumulables":[]},"Properties":{"spark.driver.host":"192.168.11.7","spark.history.fs.logDirectory":"./spark-events","spark.eventLog.enabled":"true","spark.driver.port":"55052","spark.jars":"file:/Users/kinsho/workspace/spark-3.0.1/workspace/sample-spark-scala/target/scala-2.12/simple-project_2.12-1.0.jar","spark.app.name":"logTransform","spark.submit.pyFiles":"","spark.executor.id":"driver","spark.submit.deployMode":"client","spark.master":"spark://ST000000035:7077","spark.eventLog.dir":"./spark-events","spark.sql.execution.id":"1","spark.executor.cores":"2","spark.app.id":"app-20210130163235-0014"}}
{"Event":"SparkListenerTaskStart","Stage ID":1,"Stage Attempt ID":0,"Task Info":{"Task ID":1,"Index":0,"Attempt":0,"Launch Time":1611991964659,"Executor ID":"7","Host":"192.168.11.7","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":1,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"ExceptionFailure","Class Name":"org.apache.spark.SparkException","Description":"Failed to execute user defined function(LogTransform$$$Lambda$2463/1768069354: (string) => boolean)","Stack Trace":[{"Declaring Class":"org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1","Method Name":"processNext","File Name":null,"Line Number":-1},{"Declaring Class":"org.apache.spark.sql.execution.BufferedRowIterator","Method Name":"hasNext","File Name":"BufferedRowIterator.java","Line Number":43},{"Declaring Class":"org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1","Method Name":"hasNext","File Name":"WholeStageCodegenExec.scala","Line Number":729},{"Declaring Class":"org.apache.spark.sql.execution.SparkPlan","Method Name":"$anonfun$getByteArrayRdd$1","File Name":"SparkPlan.scala","Line Number":340},{"Declaring Class":"org.apache.spark.rdd.RDD","Method Name":"$anonfun$mapPartitionsInternal$2","File Name":"RDD.scala","Line Number":872},{"Declaring Class":"org.apache.spark.rdd.RDD","Method Name":"$anonfun$mapPartitionsInternal$2$adapted","File Name":"RDD.scala","Line Number":872},{"Declaring Class":"org.apache.spark.rdd.MapPartitionsRDD","Method Name":"compute","File Name":"MapPartitionsRDD.scala","Line Number":52},{"Declaring Class":"org.apache.spark.rdd.RDD","Method Name":"computeOrReadCheckpoint","File Name":"RDD.scala","Line Number":349},{"Declaring Class":"org.apache.spark.rdd.RDD","Method Name":"iterator","File Name":"RDD.scala","Line Number":313},{"Declaring Class":"org.apache.spark.scheduler.ResultTask","Method Name":"runTask","File Name":"ResultTask.scala","Line Number":90},{"Declaring Class":"org.apache.spark.scheduler.Task","Method Name":"run","File Name":"Task.scala","Line Number":127},{"Declaring Class":"org.apache.spark.executor.Executor$TaskRunner","Method Name":"$anonfun$run$3","File Name":"Executor.scala","Line Number":446},{"Declaring Class":"org.apache.spark.util.Utils$","Method Name":"tryWithSafeFinally","File Name":"Utils.scala","Line Number":1377},{"Declaring Class":"org.apache.spark.executor.Executor$TaskRunner","Method Name":"run","File Name":"Executor.scala","Line Number":449},{"Declaring Class":"java.util.concurrent.ThreadPoolExecutor","Method Name":"runWorker","File Name":"ThreadPoolExecutor.java","Line Number":1149},{"Declaring Class":"java.util.concurrent.ThreadPoolExecutor$Worker","Method Name":"run","File Name":"ThreadPoolExecutor.java","Line Number":624},{"Declaring Class":"java.lang.Thread","Method Name":"run","File Name":"Thread.java","Line Number":748}],"Full Stack Trace":"org.apache.spark.SparkException: Failed to execute user defined function(LogTransform$$$Lambda$2463/1768069354: (string) => boolean)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:729)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:340)\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:872)\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:872)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:313)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:127)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:446)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:449)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: java.lang.NullPointerException\n\tat LogTransform$.$anonfun$main$1(LogTransform.scala:39)\n\tat LogTransform$.$anonfun$main$1$adapted(LogTransform.scala:39)\n\t... 17 more\n","Accumulator Updates":[{"ID":65,"Update":"240","Internal":false,"Count Failed Values":true},{"ID":67,"Update":"0","Internal":false,"Count Failed Values":true},{"ID":84,"Update":"65536","Internal":false,"Count Failed Values":true},{"ID":85,"Update":"1","Internal":false,"Count Failed Values":true}]},"Task Info":{"Task ID":1,"Index":0,"Attempt":0,"Launch Time":1611991964659,"Executor ID":"7","Host":"192.168.11.7","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1611991964930,"Failed":true,"Killed":false,"Accumulables":[{"ID":85,"Name":"internal.metrics.input.recordsRead","Update":1,"Value":1,"Internal":true,"Count Failed Values":true},{"ID":84,"Name":"internal.metrics.input.bytesRead","Update":65536,"Value":65536,"Internal":true,"Count Failed Values":true},{"ID":65,"Name":"internal.metrics.executorRunTime","Update":240,"Value":240,"Internal":true,"Count Failed Values":true}]},"Task Executor Metrics":{"JVMHeapMemory":0,"JVMOffHeapMemory":0,"OnHeapExecutionMemory":0,"OffHeapExecutionMemory":0,"OnHeapStorageMemory":0,"OffHeapStorageMemory":0,"OnHeapUnifiedMemory":0,"OffHeapUnifiedMemory":0,"DirectPoolMemory":0,"MappedPoolMemory":0,"ProcessTreeJVMVMemory":0,"ProcessTreeJVMRSSMemory":0,"ProcessTreePythonVMemory":0,"ProcessTreePythonRSSMemory":0,"ProcessTreeOtherVMemory":0,"ProcessTreeOtherRSSMemory":0,"MinorGCCount":0,"MinorGCTime":0,"MajorGCCount":0,"MajorGCTime":0},"Task Metrics":{"Executor Deserialize Time":0,"Executor Deserialize CPU Time":0,"Executor Run Time":240,"Executor CPU Time":0,"Peak Execution Memory":0,"Result Size":0,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":65536,"Records Read":1},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerTaskStart","Stage ID":1,"Stage Attempt ID":0,"Task Info":{"Task ID":2,"Index":0,"Attempt":1,"Launch Time":1611991964932,"Executor ID":"5","Host":"192.168.11.7","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":1,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"ExceptionFailure","Class Name":"org.apache.spark.SparkException","Description":"Failed to execute user defined function(LogTransform$$$Lambda$2463/1768069354: (string) => boolean)","Stack Trace":[{"Declaring Class":"org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1","Method Name":"processNext","File Name":null,"Line Number":-1},{"Declaring Class":"org.apache.spark.sql.execution.BufferedRowIterator","Method Name":"hasNext","File Name":"BufferedRowIterator.java","Line Number":43},{"Declaring Class":"org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1","Method Name":"hasNext","File Name":"WholeStageCodegenExec.scala","Line Number":729},{"Declaring Class":"org.apache.spark.sql.execution.SparkPlan","Method Name":"$anonfun$getByteArrayRdd$1","File Name":"SparkPlan.scala","Line Number":340},{"Declaring Class":"org.apache.spark.rdd.RDD","Method Name":"$anonfun$mapPartitionsInternal$2","File Name":"RDD.scala","Line Number":872},{"Declaring Class":"org.apache.spark.rdd.RDD","Method Name":"$anonfun$mapPartitionsInternal$2$adapted","File Name":"RDD.scala","Line Number":872},{"Declaring Class":"org.apache.spark.rdd.MapPartitionsRDD","Method Name":"compute","File Name":"MapPartitionsRDD.scala","Line Number":52},{"Declaring Class":"org.apache.spark.rdd.RDD","Method Name":"computeOrReadCheckpoint","File Name":"RDD.scala","Line Number":349},{"Declaring Class":"org.apache.spark.rdd.RDD","Method Name":"iterator","File Name":"RDD.scala","Line Number":313},{"Declaring Class":"org.apache.spark.scheduler.ResultTask","Method Name":"runTask","File Name":"ResultTask.scala","Line Number":90},{"Declaring Class":"org.apache.spark.scheduler.Task","Method Name":"run","File Name":"Task.scala","Line Number":127},{"Declaring Class":"org.apache.spark.executor.Executor$TaskRunner","Method Name":"$anonfun$run$3","File Name":"Executor.scala","Line Number":446},{"Declaring Class":"org.apache.spark.util.Utils$","Method Name":"tryWithSafeFinally","File Name":"Utils.scala","Line Number":1377},{"Declaring Class":"org.apache.spark.executor.Executor$TaskRunner","Method Name":"run","File Name":"Executor.scala","Line Number":449},{"Declaring Class":"java.util.concurrent.ThreadPoolExecutor","Method Name":"runWorker","File Name":"ThreadPoolExecutor.java","Line Number":1149},{"Declaring Class":"java.util.concurrent.ThreadPoolExecutor$Worker","Method Name":"run","File Name":"ThreadPoolExecutor.java","Line Number":624},{"Declaring Class":"java.lang.Thread","Method Name":"run","File Name":"Thread.java","Line Number":748}],"Full Stack Trace":"org.apache.spark.SparkException: Failed to execute user defined function(LogTransform$$$Lambda$2463/1768069354: (string) => boolean)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:729)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:340)\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:872)\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:872)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:313)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:127)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:446)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:449)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: java.lang.NullPointerException\n\tat LogTransform$.$anonfun$main$1(LogTransform.scala:39)\n\tat LogTransform$.$anonfun$main$1$adapted(LogTransform.scala:39)\n\t... 17 more\n","Accumulator Updates":[{"ID":65,"Update":"1173","Internal":false,"Count Failed Values":true},{"ID":67,"Update":"0","Internal":false,"Count Failed Values":true},{"ID":68,"Update":"25","Internal":false,"Count Failed Values":true},{"ID":84,"Update":"65536","Internal":false,"Count Failed Values":true},{"ID":85,"Update":"1","Internal":false,"Count Failed Values":true}]},"Task Info":{"Task ID":2,"Index":0,"Attempt":1,"Launch Time":1611991964932,"Executor ID":"5","Host":"192.168.11.7","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1611991966238,"Failed":true,"Killed":false,"Accumulables":[{"ID":85,"Name":"internal.metrics.input.recordsRead","Update":1,"Value":2,"Internal":true,"Count Failed Values":true},{"ID":84,"Name":"internal.metrics.input.bytesRead","Update":65536,"Value":131072,"Internal":true,"Count Failed Values":true},{"ID":68,"Name":"internal.metrics.jvmGCTime","Update":25,"Value":25,"Internal":true,"Count Failed Values":true},{"ID":65,"Name":"internal.metrics.executorRunTime","Update":1173,"Value":1413,"Internal":true,"Count Failed Values":true}]},"Task Executor Metrics":{"JVMHeapMemory":0,"JVMOffHeapMemory":0,"OnHeapExecutionMemory":0,"OffHeapExecutionMemory":0,"OnHeapStorageMemory":0,"OffHeapStorageMemory":0,"OnHeapUnifiedMemory":0,"OffHeapUnifiedMemory":0,"DirectPoolMemory":0,"MappedPoolMemory":0,"ProcessTreeJVMVMemory":0,"ProcessTreeJVMRSSMemory":0,"ProcessTreePythonVMemory":0,"ProcessTreePythonRSSMemory":0,"ProcessTreeOtherVMemory":0,"ProcessTreeOtherRSSMemory":0,"MinorGCCount":0,"MinorGCTime":0,"MajorGCCount":0,"MajorGCTime":0},"Task Metrics":{"Executor Deserialize Time":0,"Executor Deserialize CPU Time":0,"Executor Run Time":1173,"Executor CPU Time":0,"Peak Execution Memory":0,"Result Size":0,"JVM GC Time":25,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":65536,"Records Read":1},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerTaskStart","Stage ID":1,"Stage Attempt ID":0,"Task Info":{"Task ID":3,"Index":0,"Attempt":2,"Launch Time":1611991966240,"Executor ID":"8","Host":"192.168.11.7","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":1,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"ExceptionFailure","Class Name":"org.apache.spark.SparkException","Description":"Failed to execute user defined function(LogTransform$$$Lambda$2463/1768069354: (string) => boolean)","Stack Trace":[{"Declaring Class":"org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1","Method Name":"processNext","File Name":null,"Line Number":-1},{"Declaring Class":"org.apache.spark.sql.execution.BufferedRowIterator","Method Name":"hasNext","File Name":"BufferedRowIterator.java","Line Number":43},{"Declaring Class":"org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1","Method Name":"hasNext","File Name":"WholeStageCodegenExec.scala","Line Number":729},{"Declaring Class":"org.apache.spark.sql.execution.SparkPlan","Method Name":"$anonfun$getByteArrayRdd$1","File Name":"SparkPlan.scala","Line Number":340},{"Declaring Class":"org.apache.spark.rdd.RDD","Method Name":"$anonfun$mapPartitionsInternal$2","File Name":"RDD.scala","Line Number":872},{"Declaring Class":"org.apache.spark.rdd.RDD","Method Name":"$anonfun$mapPartitionsInternal$2$adapted","File Name":"RDD.scala","Line Number":872},{"Declaring Class":"org.apache.spark.rdd.MapPartitionsRDD","Method Name":"compute","File Name":"MapPartitionsRDD.scala","Line Number":52},{"Declaring Class":"org.apache.spark.rdd.RDD","Method Name":"computeOrReadCheckpoint","File Name":"RDD.scala","Line Number":349},{"Declaring Class":"org.apache.spark.rdd.RDD","Method Name":"iterator","File Name":"RDD.scala","Line Number":313},{"Declaring Class":"org.apache.spark.scheduler.ResultTask","Method Name":"runTask","File Name":"ResultTask.scala","Line Number":90},{"Declaring Class":"org.apache.spark.scheduler.Task","Method Name":"run","File Name":"Task.scala","Line Number":127},{"Declaring Class":"org.apache.spark.executor.Executor$TaskRunner","Method Name":"$anonfun$run$3","File Name":"Executor.scala","Line Number":446},{"Declaring Class":"org.apache.spark.util.Utils$","Method Name":"tryWithSafeFinally","File Name":"Utils.scala","Line Number":1377},{"Declaring Class":"org.apache.spark.executor.Executor$TaskRunner","Method Name":"run","File Name":"Executor.scala","Line Number":449},{"Declaring Class":"java.util.concurrent.ThreadPoolExecutor","Method Name":"runWorker","File Name":"ThreadPoolExecutor.java","Line Number":1149},{"Declaring Class":"java.util.concurrent.ThreadPoolExecutor$Worker","Method Name":"run","File Name":"ThreadPoolExecutor.java","Line Number":624},{"Declaring Class":"java.lang.Thread","Method Name":"run","File Name":"Thread.java","Line Number":748}],"Full Stack Trace":"org.apache.spark.SparkException: Failed to execute user defined function(LogTransform$$$Lambda$2463/1768069354: (string) => boolean)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:729)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:340)\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:872)\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:872)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:313)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:127)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:446)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:449)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: java.lang.NullPointerException\n\tat LogTransform$.$anonfun$main$1(LogTransform.scala:39)\n\tat LogTransform$.$anonfun$main$1$adapted(LogTransform.scala:39)\n\t... 17 more\n","Accumulator Updates":[{"ID":65,"Update":"1182","Internal":false,"Count Failed Values":true},{"ID":67,"Update":"0","Internal":false,"Count Failed Values":true},{"ID":68,"Update":"25","Internal":false,"Count Failed Values":true},{"ID":84,"Update":"65536","Internal":false,"Count Failed Values":true},{"ID":85,"Update":"1","Internal":false,"Count Failed Values":true}]},"Task Info":{"Task ID":3,"Index":0,"Attempt":2,"Launch Time":1611991966240,"Executor ID":"8","Host":"192.168.11.7","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1611991967569,"Failed":true,"Killed":false,"Accumulables":[{"ID":85,"Name":"internal.metrics.input.recordsRead","Update":1,"Value":3,"Internal":true,"Count Failed Values":true},{"ID":84,"Name":"internal.metrics.input.bytesRead","Update":65536,"Value":196608,"Internal":true,"Count Failed Values":true},{"ID":68,"Name":"internal.metrics.jvmGCTime","Update":25,"Value":50,"Internal":true,"Count Failed Values":true},{"ID":65,"Name":"internal.metrics.executorRunTime","Update":1182,"Value":2595,"Internal":true,"Count Failed Values":true}]},"Task Executor Metrics":{"JVMHeapMemory":0,"JVMOffHeapMemory":0,"OnHeapExecutionMemory":0,"OffHeapExecutionMemory":0,"OnHeapStorageMemory":0,"OffHeapStorageMemory":0,"OnHeapUnifiedMemory":0,"OffHeapUnifiedMemory":0,"DirectPoolMemory":0,"MappedPoolMemory":0,"ProcessTreeJVMVMemory":0,"ProcessTreeJVMRSSMemory":0,"ProcessTreePythonVMemory":0,"ProcessTreePythonRSSMemory":0,"ProcessTreeOtherVMemory":0,"ProcessTreeOtherRSSMemory":0,"MinorGCCount":0,"MinorGCTime":0,"MajorGCCount":0,"MajorGCTime":0},"Task Metrics":{"Executor Deserialize Time":0,"Executor Deserialize CPU Time":0,"Executor Run Time":1182,"Executor CPU Time":0,"Peak Execution Memory":0,"Result Size":0,"JVM GC Time":25,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":65536,"Records Read":1},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerTaskStart","Stage ID":1,"Stage Attempt ID":0,"Task Info":{"Task ID":4,"Index":0,"Attempt":3,"Launch Time":1611991967569,"Executor ID":"7","Host":"192.168.11.7","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":1,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"ExceptionFailure","Class Name":"org.apache.spark.SparkException","Description":"Failed to execute user defined function(LogTransform$$$Lambda$2463/1768069354: (string) => boolean)","Stack Trace":[{"Declaring Class":"org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1","Method Name":"processNext","File Name":null,"Line Number":-1},{"Declaring Class":"org.apache.spark.sql.execution.BufferedRowIterator","Method Name":"hasNext","File Name":"BufferedRowIterator.java","Line Number":43},{"Declaring Class":"org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1","Method Name":"hasNext","File Name":"WholeStageCodegenExec.scala","Line Number":729},{"Declaring Class":"org.apache.spark.sql.execution.SparkPlan","Method Name":"$anonfun$getByteArrayRdd$1","File Name":"SparkPlan.scala","Line Number":340},{"Declaring Class":"org.apache.spark.rdd.RDD","Method Name":"$anonfun$mapPartitionsInternal$2","File Name":"RDD.scala","Line Number":872},{"Declaring Class":"org.apache.spark.rdd.RDD","Method Name":"$anonfun$mapPartitionsInternal$2$adapted","File Name":"RDD.scala","Line Number":872},{"Declaring Class":"org.apache.spark.rdd.MapPartitionsRDD","Method Name":"compute","File Name":"MapPartitionsRDD.scala","Line Number":52},{"Declaring Class":"org.apache.spark.rdd.RDD","Method Name":"computeOrReadCheckpoint","File Name":"RDD.scala","Line Number":349},{"Declaring Class":"org.apache.spark.rdd.RDD","Method Name":"iterator","File Name":"RDD.scala","Line Number":313},{"Declaring Class":"org.apache.spark.scheduler.ResultTask","Method Name":"runTask","File Name":"ResultTask.scala","Line Number":90},{"Declaring Class":"org.apache.spark.scheduler.Task","Method Name":"run","File Name":"Task.scala","Line Number":127},{"Declaring Class":"org.apache.spark.executor.Executor$TaskRunner","Method Name":"$anonfun$run$3","File Name":"Executor.scala","Line Number":446},{"Declaring Class":"org.apache.spark.util.Utils$","Method Name":"tryWithSafeFinally","File Name":"Utils.scala","Line Number":1377},{"Declaring Class":"org.apache.spark.executor.Executor$TaskRunner","Method Name":"run","File Name":"Executor.scala","Line Number":449},{"Declaring Class":"java.util.concurrent.ThreadPoolExecutor","Method Name":"runWorker","File Name":"ThreadPoolExecutor.java","Line Number":1149},{"Declaring Class":"java.util.concurrent.ThreadPoolExecutor$Worker","Method Name":"run","File Name":"ThreadPoolExecutor.java","Line Number":624},{"Declaring Class":"java.lang.Thread","Method Name":"run","File Name":"Thread.java","Line Number":748}],"Full Stack Trace":"org.apache.spark.SparkException: Failed to execute user defined function(LogTransform$$$Lambda$2463/1768069354: (string) => boolean)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:729)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:340)\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:872)\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:872)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:313)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:127)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:446)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:449)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: java.lang.NullPointerException\n\tat LogTransform$.$anonfun$main$1(LogTransform.scala:39)\n\tat LogTransform$.$anonfun$main$1$adapted(LogTransform.scala:39)\n\t... 17 more\n","Accumulator Updates":[{"ID":65,"Update":"21","Internal":false,"Count Failed Values":true},{"ID":67,"Update":"0","Internal":false,"Count Failed Values":true},{"ID":84,"Update":"65536","Internal":false,"Count Failed Values":true},{"ID":85,"Update":"1","Internal":false,"Count Failed Values":true}]},"Task Info":{"Task ID":4,"Index":0,"Attempt":3,"Launch Time":1611991967569,"Executor ID":"7","Host":"192.168.11.7","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1611991967597,"Failed":true,"Killed":false,"Accumulables":[{"ID":85,"Name":"internal.metrics.input.recordsRead","Update":1,"Value":4,"Internal":true,"Count Failed Values":true},{"ID":84,"Name":"internal.metrics.input.bytesRead","Update":65536,"Value":262144,"Internal":true,"Count Failed Values":true},{"ID":65,"Name":"internal.metrics.executorRunTime","Update":21,"Value":2616,"Internal":true,"Count Failed Values":true}]},"Task Executor Metrics":{"JVMHeapMemory":0,"JVMOffHeapMemory":0,"OnHeapExecutionMemory":0,"OffHeapExecutionMemory":0,"OnHeapStorageMemory":0,"OffHeapStorageMemory":0,"OnHeapUnifiedMemory":0,"OffHeapUnifiedMemory":0,"DirectPoolMemory":0,"MappedPoolMemory":0,"ProcessTreeJVMVMemory":0,"ProcessTreeJVMRSSMemory":0,"ProcessTreePythonVMemory":0,"ProcessTreePythonRSSMemory":0,"ProcessTreeOtherVMemory":0,"ProcessTreeOtherRSSMemory":0,"MinorGCCount":0,"MinorGCTime":0,"MajorGCCount":0,"MajorGCTime":0},"Task Metrics":{"Executor Deserialize Time":0,"Executor Deserialize CPU Time":0,"Executor Run Time":21,"Executor CPU Time":0,"Peak Execution Memory":0,"Result Size":0,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":65536,"Records Read":1},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":1,"Stage Attempt ID":0,"Stage Name":"show at LogTransform.scala:42","Number of Tasks":1,"RDD Info":[{"RDD ID":13,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"17\",\"name\":\"mapPartitionsInternal\"}","Callsite":"show at LogTransform.scala:42","Parent IDs":[12],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":176,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":12,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"13\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"show at LogTransform.scala:42","Parent IDs":[11],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":176,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":10,"Name":"FileScanRDD","Scope":"{\"id\":\"16\",\"name\":\"Scan csv \"}","Callsite":"show at LogTransform.scala:42","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":176,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":11,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"16\",\"name\":\"Scan csv \"}","Callsite":"show at LogTransform.scala:42","Parent IDs":[10],"Storage Level":{"Use Disk":false,"Use Memory":false,"Deserialized":false,"Replication":1},"Barrier":false,"Number of Partitions":176,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.Dataset.show(Dataset.scala:792)\nLogTransform$.main(LogTransform.scala:42)\nLogTransform.main(LogTransform.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\norg.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52)\norg.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:928)\norg.apache.spark.deploy.SparkSubmit.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit.submit(SparkSubmit.scala:203)\norg.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:90)\norg.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:1007)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:1016)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","Submission Time":1611991964642,"Completion Time":1611991967601,"Failure Reason":"Job aborted due to stage failure: Task 0 in stage 1.0 failed 4 times, most recent failure: Lost task 0.3 in stage 1.0 (TID 4, 192.168.11.7, executor 7): org.apache.spark.SparkException: Failed to execute user defined function(LogTransform$$$Lambda$2463/1768069354: (string) => boolean)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:729)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:340)\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:872)\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:872)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:313)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:127)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:446)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:449)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: java.lang.NullPointerException\n\tat LogTransform$.$anonfun$main$1(LogTransform.scala:39)\n\tat LogTransform$.$anonfun$main$1$adapted(LogTransform.scala:39)\n\t... 17 more\n\nDriver stacktrace:","Accumulables":[{"ID":68,"Name":"internal.metrics.jvmGCTime","Value":50,"Internal":true,"Count Failed Values":true},{"ID":65,"Name":"internal.metrics.executorRunTime","Value":2616,"Internal":true,"Count Failed Values":true},{"ID":85,"Name":"internal.metrics.input.recordsRead","Value":4,"Internal":true,"Count Failed Values":true},{"ID":84,"Name":"internal.metrics.input.bytesRead","Value":262144,"Internal":true,"Count Failed Values":true}]}}
{"Event":"org.apache.spark.sql.execution.ui.SparkListenerSQLExecutionEnd","executionId":1,"time":1611991967602}
{"Event":"SparkListenerJobEnd","Job ID":1,"Completion Time":1611991967601,"Job Result":{"Result":"JobFailed","Exception":{"Message":"Job aborted due to stage failure: Task 0 in stage 1.0 failed 4 times, most recent failure: Lost task 0.3 in stage 1.0 (TID 4, 192.168.11.7, executor 7): org.apache.spark.SparkException: Failed to execute user defined function(LogTransform$$$Lambda$2463/1768069354: (string) => boolean)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:729)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:340)\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:872)\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:872)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:313)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:127)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:446)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:449)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: java.lang.NullPointerException\n\tat LogTransform$.$anonfun$main$1(LogTransform.scala:39)\n\tat LogTransform$.$anonfun$main$1$adapted(LogTransform.scala:39)\n\t... 17 more\n\nDriver stacktrace:","Stack Trace":[{"Declaring Class":"org.apache.spark.scheduler.DAGScheduler","Method Name":"failJobAndIndependentStages","File Name":"DAGScheduler.scala","Line Number":2059},{"Declaring Class":"org.apache.spark.scheduler.DAGScheduler","Method Name":"$anonfun$abortStage$2","File Name":"DAGScheduler.scala","Line Number":2008},{"Declaring Class":"org.apache.spark.scheduler.DAGScheduler","Method Name":"$anonfun$abortStage$2$adapted","File Name":"DAGScheduler.scala","Line Number":2007},{"Declaring Class":"scala.collection.mutable.ResizableArray","Method Name":"foreach","File Name":"ResizableArray.scala","Line Number":62},{"Declaring Class":"scala.collection.mutable.ResizableArray","Method Name":"foreach$","File Name":"ResizableArray.scala","Line Number":55},{"Declaring Class":"scala.collection.mutable.ArrayBuffer","Method Name":"foreach","File Name":"ArrayBuffer.scala","Line Number":49},{"Declaring Class":"org.apache.spark.scheduler.DAGScheduler","Method Name":"abortStage","File Name":"DAGScheduler.scala","Line Number":2007},{"Declaring Class":"org.apache.spark.scheduler.DAGScheduler","Method Name":"$anonfun$handleTaskSetFailed$1","File Name":"DAGScheduler.scala","Line Number":973},{"Declaring Class":"org.apache.spark.scheduler.DAGScheduler","Method Name":"$anonfun$handleTaskSetFailed$1$adapted","File Name":"DAGScheduler.scala","Line Number":973},{"Declaring Class":"scala.Option","Method Name":"foreach","File Name":"Option.scala","Line Number":407},{"Declaring Class":"org.apache.spark.scheduler.DAGScheduler","Method Name":"handleTaskSetFailed","File Name":"DAGScheduler.scala","Line Number":973},{"Declaring Class":"org.apache.spark.scheduler.DAGSchedulerEventProcessLoop","Method Name":"doOnReceive","File Name":"DAGScheduler.scala","Line Number":2239},{"Declaring Class":"org.apache.spark.scheduler.DAGSchedulerEventProcessLoop","Method Name":"onReceive","File Name":"DAGScheduler.scala","Line Number":2188},{"Declaring Class":"org.apache.spark.scheduler.DAGSchedulerEventProcessLoop","Method Name":"onReceive","File Name":"DAGScheduler.scala","Line Number":2177},{"Declaring Class":"org.apache.spark.util.EventLoop$$anon$1","Method Name":"run","File Name":"EventLoop.scala","Line Number":49},{"Declaring Class":"org.apache.spark.scheduler.DAGScheduler","Method Name":"runJob","File Name":"DAGScheduler.scala","Line Number":775},{"Declaring Class":"org.apache.spark.SparkContext","Method Name":"runJob","File Name":"SparkContext.scala","Line Number":2099},{"Declaring Class":"org.apache.spark.SparkContext","Method Name":"runJob","File Name":"SparkContext.scala","Line Number":2120},{"Declaring Class":"org.apache.spark.SparkContext","Method Name":"runJob","File Name":"SparkContext.scala","Line Number":2139},{"Declaring Class":"org.apache.spark.sql.execution.SparkPlan","Method Name":"executeTake","File Name":"SparkPlan.scala","Line Number":467},{"Declaring Class":"org.apache.spark.sql.execution.SparkPlan","Method Name":"executeTake","File Name":"SparkPlan.scala","Line Number":420},{"Declaring Class":"org.apache.spark.sql.execution.CollectLimitExec","Method Name":"executeCollect","File Name":"limit.scala","Line Number":47},{"Declaring Class":"org.apache.spark.sql.Dataset","Method Name":"collectFromPlan","File Name":"Dataset.scala","Line Number":3627},{"Declaring Class":"org.apache.spark.sql.Dataset","Method Name":"$anonfun$head$1","File Name":"Dataset.scala","Line Number":2697},{"Declaring Class":"org.apache.spark.sql.Dataset","Method Name":"$anonfun$withAction$1","File Name":"Dataset.scala","Line Number":3618},{"Declaring Class":"org.apache.spark.sql.execution.SQLExecution$","Method Name":"$anonfun$withNewExecutionId$5","File Name":"SQLExecution.scala","Line Number":100},{"Declaring Class":"org.apache.spark.sql.execution.SQLExecution$","Method Name":"withSQLConfPropagated","File Name":"SQLExecution.scala","Line Number":160},{"Declaring Class":"org.apache.spark.sql.execution.SQLExecution$","Method Name":"$anonfun$withNewExecutionId$1","File Name":"SQLExecution.scala","Line Number":87},{"Declaring Class":"org.apache.spark.sql.SparkSession","Method Name":"withActive","File Name":"SparkSession.scala","Line Number":764},{"Declaring Class":"org.apache.spark.sql.execution.SQLExecution$","Method Name":"withNewExecutionId","File Name":"SQLExecution.scala","Line Number":64},{"Declaring Class":"org.apache.spark.sql.Dataset","Method Name":"withAction","File Name":"Dataset.scala","Line Number":3616},{"Declaring Class":"org.apache.spark.sql.Dataset","Method Name":"head","File Name":"Dataset.scala","Line Number":2697},{"Declaring Class":"org.apache.spark.sql.Dataset","Method Name":"take","File Name":"Dataset.scala","Line Number":2904},{"Declaring Class":"org.apache.spark.sql.Dataset","Method Name":"getRows","File Name":"Dataset.scala","Line Number":300},{"Declaring Class":"org.apache.spark.sql.Dataset","Method Name":"showString","File Name":"Dataset.scala","Line Number":337},{"Declaring Class":"org.apache.spark.sql.Dataset","Method Name":"show","File Name":"Dataset.scala","Line Number":824},{"Declaring Class":"org.apache.spark.sql.Dataset","Method Name":"show","File Name":"Dataset.scala","Line Number":783},{"Declaring Class":"org.apache.spark.sql.Dataset","Method Name":"show","File Name":"Dataset.scala","Line Number":792},{"Declaring Class":"LogTransform$","Method Name":"main","File Name":"LogTransform.scala","Line Number":42},{"Declaring Class":"LogTransform","Method Name":"main","File Name":"LogTransform.scala","Line Number":-1},{"Declaring Class":"sun.reflect.NativeMethodAccessorImpl","Method Name":"invoke0","File Name":"NativeMethodAccessorImpl.java","Line Number":-2},{"Declaring Class":"sun.reflect.NativeMethodAccessorImpl","Method Name":"invoke","File Name":"NativeMethodAccessorImpl.java","Line Number":62},{"Declaring Class":"sun.reflect.DelegatingMethodAccessorImpl","Method Name":"invoke","File Name":"DelegatingMethodAccessorImpl.java","Line Number":43},{"Declaring Class":"java.lang.reflect.Method","Method Name":"invoke","File Name":"Method.java","Line Number":498},{"Declaring Class":"org.apache.spark.deploy.JavaMainApplication","Method Name":"start","File Name":"SparkApplication.scala","Line Number":52},{"Declaring Class":"org.apache.spark.deploy.SparkSubmit","Method Name":"org$apache$spark$deploy$SparkSubmit$$runMain","File Name":"SparkSubmit.scala","Line Number":928},{"Declaring Class":"org.apache.spark.deploy.SparkSubmit","Method Name":"doRunMain$1","File Name":"SparkSubmit.scala","Line Number":180},{"Declaring Class":"org.apache.spark.deploy.SparkSubmit","Method Name":"submit","File Name":"SparkSubmit.scala","Line Number":203},{"Declaring Class":"org.apache.spark.deploy.SparkSubmit","Method Name":"doSubmit","File Name":"SparkSubmit.scala","Line Number":90},{"Declaring Class":"org.apache.spark.deploy.SparkSubmit$$anon$2","Method Name":"doSubmit","File Name":"SparkSubmit.scala","Line Number":1007},{"Declaring Class":"org.apache.spark.deploy.SparkSubmit$","Method Name":"main","File Name":"SparkSubmit.scala","Line Number":1016},{"Declaring Class":"org.apache.spark.deploy.SparkSubmit","Method Name":"main","File Name":"SparkSubmit.scala","Line Number":-1}]}}}
{"Event":"SparkListenerApplicationEnd","Timestamp":1611991967605}
