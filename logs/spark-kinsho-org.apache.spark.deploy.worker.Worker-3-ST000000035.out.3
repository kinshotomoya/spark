Spark Command: /Library/Java/JavaVirtualMachines/adoptopenjdk-8.jdk/Contents/Home/jre/bin/java -cp /Users/kinsho/workspace/spark-3.0.1/conf/:/Users/kinsho/workspace/spark-3.0.1/assembly/target/scala-2.12/jars/* -Xmx1g org.apache.spark.deploy.worker.Worker --webui-port 8083 spark://ST000000035:7077
========================================
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
21/01/27 01:01:06 INFO Worker: Started daemon with process name: 51449@ST000000035
21/01/27 01:01:06 INFO SignalUtils: Registered signal handler for TERM
21/01/27 01:01:06 INFO SignalUtils: Registered signal handler for HUP
21/01/27 01:01:06 INFO SignalUtils: Registered signal handler for INT
21/01/27 01:01:06 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
21/01/27 01:01:06 INFO SecurityManager: Changing view acls to: kinsho
21/01/27 01:01:06 INFO SecurityManager: Changing modify acls to: kinsho
21/01/27 01:01:06 INFO SecurityManager: Changing view acls groups to: 
21/01/27 01:01:06 INFO SecurityManager: Changing modify acls groups to: 
21/01/27 01:01:06 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(kinsho); groups with view permissions: Set(); users  with modify permissions: Set(kinsho); groups with modify permissions: Set()
21/01/27 01:01:07 INFO Utils: Successfully started service 'sparkWorker' on port 58444.
21/01/27 01:01:07 INFO Worker: Starting Spark worker 192.168.11.7:58444 with 2 cores, 1024.0 MiB RAM
21/01/27 01:01:07 INFO Worker: Running Spark version 3.0.1
21/01/27 01:01:07 INFO Worker: Spark home: /Users/kinsho/workspace/spark-3.0.1
21/01/27 01:01:07 INFO ResourceUtils: ==============================================================
21/01/27 01:01:07 INFO ResourceUtils: Resources for spark.worker:

21/01/27 01:01:07 INFO ResourceUtils: ==============================================================
21/01/27 01:01:07 INFO Utils: Successfully started service 'WorkerUI' on port 8083.
21/01/27 01:01:07 INFO WorkerWebUI: Bound WorkerWebUI to 0.0.0.0, and started at http://192.168.11.7:8083
21/01/27 01:01:07 INFO Worker: Connecting to master ST000000035:7077...
21/01/27 01:01:07 INFO TransportClientFactory: Successfully created connection to ST000000035/192.168.11.7:7077 after 25 ms (0 ms spent in bootstraps)
21/01/27 01:01:07 INFO Worker: Successfully registered with master spark://ST000000035:7077
21/01/27 01:19:08 INFO Worker: Asked to launch executor app-20210127011908-0000/9 for SimpleApp
21/01/27 01:19:08 INFO SecurityManager: Changing view acls to: kinsho
21/01/27 01:19:08 INFO SecurityManager: Changing modify acls to: kinsho
21/01/27 01:19:08 INFO SecurityManager: Changing view acls groups to: 
21/01/27 01:19:08 INFO SecurityManager: Changing modify acls groups to: 
21/01/27 01:19:08 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(kinsho); groups with view permissions: Set(); users  with modify permissions: Set(kinsho); groups with modify permissions: Set()
21/01/27 01:19:08 INFO ExecutorRunner: Launch command: "/Library/Java/JavaVirtualMachines/adoptopenjdk-8.jdk/Contents/Home/jre/bin/java" "-cp" "/Users/kinsho/workspace/spark-3.0.1/conf/:/Users/kinsho/workspace/spark-3.0.1/assembly/target/scala-2.12/jars/*" "-Xmx1024M" "-Dspark.driver.port=58613" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@192.168.11.7:58613" "--executor-id" "9" "--hostname" "192.168.11.7" "--cores" "2" "--app-id" "app-20210127011908-0000" "--worker-url" "spark://Worker@192.168.11.7:58444"
21/01/27 01:19:20 INFO Worker: Asked to kill executor app-20210127011908-0000/9
21/01/27 01:19:20 INFO ExecutorRunner: Runner thread for executor app-20210127011908-0000/9 interrupted
21/01/27 01:19:20 INFO ExecutorRunner: Killing process!
21/01/27 01:19:21 INFO Worker: Executor app-20210127011908-0000/9 finished with state KILLED exitStatus 143
21/01/27 01:19:21 INFO ExternalShuffleBlockResolver: Clean up non-shuffle and non-RDD files associated with the finished executor 9
21/01/27 01:19:21 INFO ExternalShuffleBlockResolver: Executor is not registered (appId=app-20210127011908-0000, execId=9)
21/01/27 01:19:21 INFO Worker: Cleaning up local directories for application app-20210127011908-0000
21/01/27 01:19:21 INFO ExternalShuffleBlockResolver: Application app-20210127011908-0000 removed, cleanupLocalDirs = true
21/01/27 01:25:39 INFO Worker: Asked to launch executor app-20210127012539-0001/9 for SimpleApp
21/01/27 01:25:39 INFO SecurityManager: Changing view acls to: kinsho
21/01/27 01:25:39 INFO SecurityManager: Changing modify acls to: kinsho
21/01/27 01:25:39 INFO SecurityManager: Changing view acls groups to: 
21/01/27 01:25:39 INFO SecurityManager: Changing modify acls groups to: 
21/01/27 01:25:39 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(kinsho); groups with view permissions: Set(); users  with modify permissions: Set(kinsho); groups with modify permissions: Set()
21/01/27 01:25:39 INFO ExecutorRunner: Launch command: "/Library/Java/JavaVirtualMachines/adoptopenjdk-8.jdk/Contents/Home/jre/bin/java" "-cp" "/Users/kinsho/workspace/spark-3.0.1/conf/:/Users/kinsho/workspace/spark-3.0.1/assembly/target/scala-2.12/jars/*" "-Xmx1024M" "-Dspark.driver.port=58858" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@192.168.11.7:58858" "--executor-id" "9" "--hostname" "192.168.11.7" "--cores" "2" "--app-id" "app-20210127012539-0001" "--worker-url" "spark://Worker@192.168.11.7:58444"
21/01/27 01:25:50 INFO Worker: Asked to kill executor app-20210127012539-0001/9
21/01/27 01:25:50 INFO ExecutorRunner: Runner thread for executor app-20210127012539-0001/9 interrupted
21/01/27 01:25:50 INFO ExecutorRunner: Killing process!
21/01/27 01:25:51 INFO Worker: Executor app-20210127012539-0001/9 finished with state KILLED exitStatus 143
21/01/27 01:25:51 INFO ExternalShuffleBlockResolver: Clean up non-shuffle and non-RDD files associated with the finished executor 9
21/01/27 01:25:51 INFO ExternalShuffleBlockResolver: Executor is not registered (appId=app-20210127012539-0001, execId=9)
21/01/27 01:25:51 INFO ExternalShuffleBlockResolver: Application app-20210127012539-0001 removed, cleanupLocalDirs = true
21/01/27 01:25:51 INFO Worker: Cleaning up local directories for application app-20210127012539-0001
21/01/27 01:27:42 INFO Worker: Asked to launch executor app-20210127012742-0002/9 for SimpleApp
21/01/27 01:27:42 INFO SecurityManager: Changing view acls to: kinsho
21/01/27 01:27:42 INFO SecurityManager: Changing modify acls to: kinsho
21/01/27 01:27:42 INFO SecurityManager: Changing view acls groups to: 
21/01/27 01:27:42 INFO SecurityManager: Changing modify acls groups to: 
21/01/27 01:27:42 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(kinsho); groups with view permissions: Set(); users  with modify permissions: Set(kinsho); groups with modify permissions: Set()
21/01/27 01:27:42 INFO ExecutorRunner: Launch command: "/Library/Java/JavaVirtualMachines/adoptopenjdk-8.jdk/Contents/Home/jre/bin/java" "-cp" "/Users/kinsho/workspace/spark-3.0.1/conf/:/Users/kinsho/workspace/spark-3.0.1/assembly/target/scala-2.12/jars/*" "-Xmx1024M" "-Dspark.driver.port=59018" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@192.168.11.7:59018" "--executor-id" "9" "--hostname" "192.168.11.7" "--cores" "2" "--app-id" "app-20210127012742-0002" "--worker-url" "spark://Worker@192.168.11.7:58444"
21/01/27 01:27:54 INFO Worker: Asked to kill executor app-20210127012742-0002/9
21/01/27 01:27:54 INFO ExecutorRunner: Runner thread for executor app-20210127012742-0002/9 interrupted
21/01/27 01:27:54 INFO ExecutorRunner: Killing process!
21/01/27 01:27:54 INFO Worker: Executor app-20210127012742-0002/9 finished with state KILLED exitStatus 143
21/01/27 01:27:54 INFO ExternalShuffleBlockResolver: Clean up non-shuffle and non-RDD files associated with the finished executor 9
21/01/27 01:27:54 INFO ExternalShuffleBlockResolver: Executor is not registered (appId=app-20210127012742-0002, execId=9)
21/01/27 01:27:54 INFO ExternalShuffleBlockResolver: Application app-20210127012742-0002 removed, cleanupLocalDirs = true
21/01/27 01:27:54 INFO Worker: Cleaning up local directories for application app-20210127012742-0002
21/01/27 01:32:58 INFO Worker: Asked to launch executor app-20210127013258-0003/9 for SimpleApp
21/01/27 01:32:58 INFO SecurityManager: Changing view acls to: kinsho
21/01/27 01:32:58 INFO SecurityManager: Changing modify acls to: kinsho
21/01/27 01:32:58 INFO SecurityManager: Changing view acls groups to: 
21/01/27 01:32:58 INFO SecurityManager: Changing modify acls groups to: 
21/01/27 01:32:58 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(kinsho); groups with view permissions: Set(); users  with modify permissions: Set(kinsho); groups with modify permissions: Set()
21/01/27 01:32:58 INFO ExecutorRunner: Launch command: "/Library/Java/JavaVirtualMachines/adoptopenjdk-8.jdk/Contents/Home/jre/bin/java" "-cp" "/Users/kinsho/workspace/spark-3.0.1/conf/:/Users/kinsho/workspace/spark-3.0.1/assembly/target/scala-2.12/jars/*" "-Xmx1024M" "-Dspark.driver.port=59174" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@192.168.11.7:59174" "--executor-id" "9" "--hostname" "192.168.11.7" "--cores" "2" "--app-id" "app-20210127013258-0003" "--worker-url" "spark://Worker@192.168.11.7:58444"
21/01/27 01:33:11 INFO Worker: Asked to kill executor app-20210127013258-0003/9
21/01/27 01:33:11 INFO ExecutorRunner: Runner thread for executor app-20210127013258-0003/9 interrupted
21/01/27 01:33:11 INFO ExecutorRunner: Killing process!
21/01/27 01:33:12 INFO Worker: Executor app-20210127013258-0003/9 finished with state KILLED exitStatus 143
21/01/27 01:33:12 INFO ExternalShuffleBlockResolver: Clean up non-shuffle and non-RDD files associated with the finished executor 9
21/01/27 01:33:12 INFO ExternalShuffleBlockResolver: Executor is not registered (appId=app-20210127013258-0003, execId=9)
21/01/27 01:33:12 INFO Worker: Cleaning up local directories for application app-20210127013258-0003
21/01/27 01:33:12 INFO ExternalShuffleBlockResolver: Application app-20210127013258-0003 removed, cleanupLocalDirs = true
21/01/27 02:44:50 INFO Worker: Master with url spark://ST000000035:7077 requested this worker to reconnect.
21/01/27 02:44:50 INFO Worker: Master with url spark://ST000000035:7077 requested this worker to reconnect.
21/01/27 02:44:50 INFO Worker: Connecting to master ST000000035:7077...
21/01/27 02:44:50 INFO Worker: Not spawning another attempt to register with the master, since there is an attempt scheduled already.
21/01/27 02:44:50 INFO Worker: Master with url spark://ST000000035:7077 requested this worker to reconnect.
21/01/27 02:44:50 INFO Worker: Not spawning another attempt to register with the master, since there is an attempt scheduled already.
21/01/27 02:44:50 INFO Worker: Master with url spark://ST000000035:7077 requested this worker to reconnect.
21/01/27 02:44:50 INFO Worker: Not spawning another attempt to register with the master, since there is an attempt scheduled already.
21/01/27 02:44:50 INFO Worker: Master with url spark://ST000000035:7077 requested this worker to reconnect.
21/01/27 02:44:50 INFO Worker: Not spawning another attempt to register with the master, since there is an attempt scheduled already.
21/01/27 02:44:50 INFO Worker: Master with url spark://ST000000035:7077 requested this worker to reconnect.
21/01/27 02:44:50 INFO Worker: Not spawning another attempt to register with the master, since there is an attempt scheduled already.
21/01/27 02:44:50 INFO Worker: Master with url spark://ST000000035:7077 requested this worker to reconnect.
21/01/27 02:44:50 INFO Worker: Not spawning another attempt to register with the master, since there is an attempt scheduled already.
21/01/27 02:44:50 INFO Worker: Master with url spark://ST000000035:7077 requested this worker to reconnect.
21/01/27 02:44:50 INFO Worker: Not spawning another attempt to register with the master, since there is an attempt scheduled already.
21/01/27 02:44:50 INFO Worker: Master with url spark://ST000000035:7077 requested this worker to reconnect.
21/01/27 02:44:50 INFO Worker: Not spawning another attempt to register with the master, since there is an attempt scheduled already.
21/01/27 02:44:50 INFO Worker: Successfully registered with master spark://ST000000035:7077
21/01/27 09:24:51 WARN TransportChannelHandler: Exception in connection from ST000000035/192.168.11.7:7077
java.io.IOException: Operation timed out
	at sun.nio.ch.FileDispatcherImpl.read0(Native Method)
	at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)
	at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:223)
	at sun.nio.ch.IOUtil.read(IOUtil.java:192)
	at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:380)
	at io.netty.buffer.PooledByteBuf.setBytes(PooledByteBuf.java:253)
	at io.netty.buffer.AbstractByteBuf.writeBytes(AbstractByteBuf.java:1133)
	at io.netty.channel.socket.nio.NioSocketChannel.doReadBytes(NioSocketChannel.java:350)
	at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:148)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:714)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:650)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:576)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493)
	at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)
	at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.lang.Thread.run(Thread.java:748)
21/01/27 09:24:51 INFO Worker: ST000000035:7077 Disassociated !
21/01/27 09:24:51 ERROR Worker: Connection to master failed! Waiting for master to reconnect...
21/01/27 09:24:51 INFO Worker: ST000000035:7077 Disassociated !
21/01/27 09:24:51 INFO Worker: Connecting to master ST000000035:7077...
21/01/27 09:24:51 ERROR Worker: Connection to master failed! Waiting for master to reconnect...
21/01/27 09:24:51 INFO Worker: Not spawning another attempt to register with the master, since there is an attempt scheduled already.
21/01/27 09:24:51 INFO TransportClientFactory: Found inactive connection to ST000000035/fe80:0:0:0:aede:48ff:fe00:1122%4:7077, creating a new one.
21/01/27 09:24:51 WARN Worker: Failed to connect to master ST000000035:7077
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:302)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:101)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:109)
	at org.apache.spark.deploy.worker.Worker$$anon$1.run(Worker.scala:277)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Failed to connect to ST000000035/fe80:0:0:0:aede:48ff:fe00:1122%4:7077
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:253)
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:195)
	at org.apache.spark.rpc.netty.NettyRpcEnv.createClient(NettyRpcEnv.scala:204)
	at org.apache.spark.rpc.netty.Outbox$$anon$1.call(Outbox.scala:202)
	at org.apache.spark.rpc.netty.Outbox$$anon$1.call(Outbox.scala:198)
	... 4 more
Caused by: io.netty.channel.AbstractChannel$AnnotatedNoRouteToHostException: No route to host: ST000000035/fe80:0:0:0:aede:48ff:fe00:1122%4:7077
Caused by: java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:454)
	at sun.nio.ch.Net.connect(Net.java:446)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:648)
	at io.netty.util.internal.SocketUtils$3.run(SocketUtils.java:91)
	at io.netty.util.internal.SocketUtils$3.run(SocketUtils.java:88)
	at java.security.AccessController.doPrivileged(Native Method)
	at io.netty.util.internal.SocketUtils.connect(SocketUtils.java:88)
	at io.netty.channel.socket.nio.NioSocketChannel.doConnect(NioSocketChannel.java:315)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.connect(AbstractNioChannel.java:248)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.connect(DefaultChannelPipeline.java:1342)
	at io.netty.channel.AbstractChannelHandlerContext.invokeConnect(AbstractChannelHandlerContext.java:548)
	at io.netty.channel.AbstractChannelHandlerContext.connect(AbstractChannelHandlerContext.java:533)
	at io.netty.channel.AbstractChannelHandlerContext.connect(AbstractChannelHandlerContext.java:517)
	at io.netty.channel.DefaultChannelPipeline.connect(DefaultChannelPipeline.java:978)
	at io.netty.channel.AbstractChannel.connect(AbstractChannel.java:253)
	at io.netty.bootstrap.Bootstrap$3.run(Bootstrap.java:244)
	at io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:164)
	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:472)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:500)
	at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)
	at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.lang.Thread.run(Thread.java:748)
21/01/27 09:24:58 INFO Worker: Retrying connection to master (attempt # 1)
21/01/27 09:24:58 INFO Worker: Connecting to master ST000000035:7077...
21/01/27 09:24:58 INFO TransportClientFactory: Found inactive connection to ST000000035/fe80:0:0:0:aede:48ff:fe00:1122%4:7077, creating a new one.
21/01/27 09:24:58 WARN Worker: Failed to connect to master ST000000035:7077
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:302)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:101)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:109)
	at org.apache.spark.deploy.worker.Worker$$anon$2.run(Worker.scala:334)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Failed to connect to ST000000035/fe80:0:0:0:aede:48ff:fe00:1122%4:7077
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:253)
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:195)
	at org.apache.spark.rpc.netty.NettyRpcEnv.createClient(NettyRpcEnv.scala:204)
	at org.apache.spark.rpc.netty.Outbox$$anon$1.call(Outbox.scala:202)
	at org.apache.spark.rpc.netty.Outbox$$anon$1.call(Outbox.scala:198)
	... 4 more
Caused by: io.netty.channel.AbstractChannel$AnnotatedNoRouteToHostException: No route to host: ST000000035/fe80:0:0:0:aede:48ff:fe00:1122%4:7077
Caused by: java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:454)
	at sun.nio.ch.Net.connect(Net.java:446)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:648)
	at io.netty.util.internal.SocketUtils$3.run(SocketUtils.java:91)
	at io.netty.util.internal.SocketUtils$3.run(SocketUtils.java:88)
	at java.security.AccessController.doPrivileged(Native Method)
	at io.netty.util.internal.SocketUtils.connect(SocketUtils.java:88)
	at io.netty.channel.socket.nio.NioSocketChannel.doConnect(NioSocketChannel.java:315)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.connect(AbstractNioChannel.java:248)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.connect(DefaultChannelPipeline.java:1342)
	at io.netty.channel.AbstractChannelHandlerContext.invokeConnect(AbstractChannelHandlerContext.java:548)
	at io.netty.channel.AbstractChannelHandlerContext.connect(AbstractChannelHandlerContext.java:533)
	at io.netty.channel.AbstractChannelHandlerContext.connect(AbstractChannelHandlerContext.java:517)
	at io.netty.channel.DefaultChannelPipeline.connect(DefaultChannelPipeline.java:978)
	at io.netty.channel.AbstractChannel.connect(AbstractChannel.java:253)
	at io.netty.bootstrap.Bootstrap$3.run(Bootstrap.java:244)
	at io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:164)
	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:472)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:500)
	at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)
	at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.lang.Thread.run(Thread.java:748)
21/01/27 09:25:05 INFO Worker: Retrying connection to master (attempt # 2)
21/01/27 09:25:05 INFO Worker: Connecting to master ST000000035:7077...
21/01/27 09:25:05 INFO TransportClientFactory: Found inactive connection to ST000000035/fe80:0:0:0:aede:48ff:fe00:1122%4:7077, creating a new one.
21/01/27 09:25:05 WARN Worker: Failed to connect to master ST000000035:7077
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:302)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:101)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:109)
	at org.apache.spark.deploy.worker.Worker$$anon$2.run(Worker.scala:334)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Failed to connect to ST000000035/fe80:0:0:0:aede:48ff:fe00:1122%4:7077
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:253)
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:195)
	at org.apache.spark.rpc.netty.NettyRpcEnv.createClient(NettyRpcEnv.scala:204)
	at org.apache.spark.rpc.netty.Outbox$$anon$1.call(Outbox.scala:202)
	at org.apache.spark.rpc.netty.Outbox$$anon$1.call(Outbox.scala:198)
	... 4 more
Caused by: io.netty.channel.AbstractChannel$AnnotatedNoRouteToHostException: No route to host: ST000000035/fe80:0:0:0:aede:48ff:fe00:1122%4:7077
Caused by: java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:454)
	at sun.nio.ch.Net.connect(Net.java:446)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:648)
	at io.netty.util.internal.SocketUtils$3.run(SocketUtils.java:91)
	at io.netty.util.internal.SocketUtils$3.run(SocketUtils.java:88)
	at java.security.AccessController.doPrivileged(Native Method)
	at io.netty.util.internal.SocketUtils.connect(SocketUtils.java:88)
	at io.netty.channel.socket.nio.NioSocketChannel.doConnect(NioSocketChannel.java:315)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.connect(AbstractNioChannel.java:248)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.connect(DefaultChannelPipeline.java:1342)
	at io.netty.channel.AbstractChannelHandlerContext.invokeConnect(AbstractChannelHandlerContext.java:548)
	at io.netty.channel.AbstractChannelHandlerContext.connect(AbstractChannelHandlerContext.java:533)
	at io.netty.channel.AbstractChannelHandlerContext.connect(AbstractChannelHandlerContext.java:517)
	at io.netty.channel.DefaultChannelPipeline.connect(DefaultChannelPipeline.java:978)
	at io.netty.channel.AbstractChannel.connect(AbstractChannel.java:253)
	at io.netty.bootstrap.Bootstrap$3.run(Bootstrap.java:244)
	at io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:164)
	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:472)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:500)
	at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)
	at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.lang.Thread.run(Thread.java:748)
21/01/27 09:25:12 INFO Worker: Retrying connection to master (attempt # 3)
21/01/27 09:25:12 INFO Worker: Connecting to master ST000000035:7077...
21/01/27 09:25:12 INFO TransportClientFactory: Found inactive connection to ST000000035/fe80:0:0:0:aede:48ff:fe00:1122%4:7077, creating a new one.
21/01/27 09:25:12 WARN Worker: Failed to connect to master ST000000035:7077
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:302)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:101)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:109)
	at org.apache.spark.deploy.worker.Worker$$anon$2.run(Worker.scala:334)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Failed to connect to ST000000035/fe80:0:0:0:aede:48ff:fe00:1122%4:7077
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:253)
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:195)
	at org.apache.spark.rpc.netty.NettyRpcEnv.createClient(NettyRpcEnv.scala:204)
	at org.apache.spark.rpc.netty.Outbox$$anon$1.call(Outbox.scala:202)
	at org.apache.spark.rpc.netty.Outbox$$anon$1.call(Outbox.scala:198)
	... 4 more
Caused by: io.netty.channel.AbstractChannel$AnnotatedNoRouteToHostException: No route to host: ST000000035/fe80:0:0:0:aede:48ff:fe00:1122%4:7077
Caused by: java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:454)
	at sun.nio.ch.Net.connect(Net.java:446)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:648)
	at io.netty.util.internal.SocketUtils$3.run(SocketUtils.java:91)
	at io.netty.util.internal.SocketUtils$3.run(SocketUtils.java:88)
	at java.security.AccessController.doPrivileged(Native Method)
	at io.netty.util.internal.SocketUtils.connect(SocketUtils.java:88)
	at io.netty.channel.socket.nio.NioSocketChannel.doConnect(NioSocketChannel.java:315)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.connect(AbstractNioChannel.java:248)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.connect(DefaultChannelPipeline.java:1342)
	at io.netty.channel.AbstractChannelHandlerContext.invokeConnect(AbstractChannelHandlerContext.java:548)
	at io.netty.channel.AbstractChannelHandlerContext.connect(AbstractChannelHandlerContext.java:533)
	at io.netty.channel.AbstractChannelHandlerContext.connect(AbstractChannelHandlerContext.java:517)
	at io.netty.channel.DefaultChannelPipeline.connect(DefaultChannelPipeline.java:978)
	at io.netty.channel.AbstractChannel.connect(AbstractChannel.java:253)
	at io.netty.bootstrap.Bootstrap$3.run(Bootstrap.java:244)
	at io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:164)
	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:472)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:500)
	at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)
	at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.lang.Thread.run(Thread.java:748)
21/01/27 09:25:19 INFO Worker: Retrying connection to master (attempt # 4)
21/01/27 09:25:19 INFO Worker: Connecting to master ST000000035:7077...
21/01/27 09:25:19 INFO TransportClientFactory: Found inactive connection to ST000000035/fe80:0:0:0:aede:48ff:fe00:1122%4:7077, creating a new one.
21/01/27 09:25:19 WARN Worker: Failed to connect to master ST000000035:7077
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:302)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:101)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:109)
	at org.apache.spark.deploy.worker.Worker$$anon$2.run(Worker.scala:334)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Failed to connect to ST000000035/fe80:0:0:0:aede:48ff:fe00:1122%4:7077
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:253)
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:195)
	at org.apache.spark.rpc.netty.NettyRpcEnv.createClient(NettyRpcEnv.scala:204)
	at org.apache.spark.rpc.netty.Outbox$$anon$1.call(Outbox.scala:202)
	at org.apache.spark.rpc.netty.Outbox$$anon$1.call(Outbox.scala:198)
	... 4 more
Caused by: io.netty.channel.AbstractChannel$AnnotatedNoRouteToHostException: No route to host: ST000000035/fe80:0:0:0:aede:48ff:fe00:1122%4:7077
Caused by: java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:454)
	at sun.nio.ch.Net.connect(Net.java:446)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:648)
	at io.netty.util.internal.SocketUtils$3.run(SocketUtils.java:91)
	at io.netty.util.internal.SocketUtils$3.run(SocketUtils.java:88)
	at java.security.AccessController.doPrivileged(Native Method)
	at io.netty.util.internal.SocketUtils.connect(SocketUtils.java:88)
	at io.netty.channel.socket.nio.NioSocketChannel.doConnect(NioSocketChannel.java:315)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.connect(AbstractNioChannel.java:248)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.connect(DefaultChannelPipeline.java:1342)
	at io.netty.channel.AbstractChannelHandlerContext.invokeConnect(AbstractChannelHandlerContext.java:548)
	at io.netty.channel.AbstractChannelHandlerContext.connect(AbstractChannelHandlerContext.java:533)
	at io.netty.channel.AbstractChannelHandlerContext.connect(AbstractChannelHandlerContext.java:517)
	at io.netty.channel.DefaultChannelPipeline.connect(DefaultChannelPipeline.java:978)
	at io.netty.channel.AbstractChannel.connect(AbstractChannel.java:253)
	at io.netty.bootstrap.Bootstrap$3.run(Bootstrap.java:244)
	at io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:164)
	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:472)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:500)
	at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)
	at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.lang.Thread.run(Thread.java:748)
21/01/27 09:25:26 INFO Worker: Retrying connection to master (attempt # 5)
21/01/27 09:25:26 INFO Worker: Connecting to master ST000000035:7077...
21/01/27 09:25:26 INFO TransportClientFactory: Found inactive connection to ST000000035/192.168.11.7:7077, creating a new one.
21/01/27 09:25:26 INFO TransportClientFactory: Successfully created connection to ST000000035/192.168.11.7:7077 after 1 ms (0 ms spent in bootstraps)
21/01/27 09:25:26 INFO Worker: Successfully registered with master spark://ST000000035:7077
21/01/27 23:43:15 WARN TransportChannelHandler: Exception in connection from ST000000035/192.168.11.7:7077
java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileDispatcherImpl.read0(Native Method)
	at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)
	at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:223)
	at sun.nio.ch.IOUtil.read(IOUtil.java:192)
	at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:380)
	at io.netty.buffer.PooledByteBuf.setBytes(PooledByteBuf.java:253)
	at io.netty.buffer.AbstractByteBuf.writeBytes(AbstractByteBuf.java:1133)
	at io.netty.channel.socket.nio.NioSocketChannel.doReadBytes(NioSocketChannel.java:350)
	at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:148)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:714)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:650)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:576)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493)
	at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)
	at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.lang.Thread.run(Thread.java:748)
21/01/27 23:43:15 INFO Worker: ST000000035:7077 Disassociated !
21/01/27 23:43:15 ERROR Worker: Connection to master failed! Waiting for master to reconnect...
21/01/27 23:43:15 INFO Worker: ST000000035:7077 Disassociated !
21/01/27 23:43:15 ERROR Worker: Connection to master failed! Waiting for master to reconnect...
21/01/27 23:43:15 INFO Worker: Not spawning another attempt to register with the master, since there is an attempt scheduled already.
21/01/27 23:43:15 INFO Worker: Connecting to master ST000000035:7077...
21/01/27 23:43:15 INFO TransportClientFactory: Found inactive connection to ST000000035/192.168.11.7:7077, creating a new one.
21/01/27 23:43:15 INFO TransportClientFactory: Successfully created connection to ST000000035/192.168.11.7:7077 after 11 ms (0 ms spent in bootstraps)
21/01/27 23:43:15 INFO Worker: Successfully registered with master spark://ST000000035:7077
21/01/28 09:28:07 INFO Worker: Master with url spark://ST000000035:7077 requested this worker to reconnect.
21/01/28 09:28:07 INFO Worker: Master with url spark://ST000000035:7077 requested this worker to reconnect.
21/01/28 09:28:07 INFO Worker: Not spawning another attempt to register with the master, since there is an attempt scheduled already.
21/01/28 09:28:07 INFO Worker: Master with url spark://ST000000035:7077 requested this worker to reconnect.
21/01/28 09:28:07 INFO Worker: Not spawning another attempt to register with the master, since there is an attempt scheduled already.
21/01/28 09:28:07 INFO Worker: Master with url spark://ST000000035:7077 requested this worker to reconnect.
21/01/28 09:28:07 INFO Worker: Not spawning another attempt to register with the master, since there is an attempt scheduled already.
21/01/28 09:28:07 INFO Worker: Master with url spark://ST000000035:7077 requested this worker to reconnect.
21/01/28 09:28:07 INFO Worker: Connecting to master ST000000035:7077...
21/01/28 09:28:08 INFO Worker: Not spawning another attempt to register with the master, since there is an attempt scheduled already.
21/01/28 09:28:08 INFO Worker: Master with url spark://ST000000035:7077 requested this worker to reconnect.
21/01/28 09:28:08 INFO Worker: Not spawning another attempt to register with the master, since there is an attempt scheduled already.
21/01/28 09:28:08 INFO Worker: Master with url spark://ST000000035:7077 requested this worker to reconnect.
21/01/28 09:28:08 INFO Worker: Not spawning another attempt to register with the master, since there is an attempt scheduled already.
21/01/28 09:28:08 INFO Worker: Master with url spark://ST000000035:7077 requested this worker to reconnect.
21/01/28 09:28:08 INFO Worker: Not spawning another attempt to register with the master, since there is an attempt scheduled already.
21/01/28 09:28:08 INFO Worker: Master with url spark://ST000000035:7077 requested this worker to reconnect.
21/01/28 09:28:08 INFO Worker: Not spawning another attempt to register with the master, since there is an attempt scheduled already.
21/01/28 09:28:08 INFO Worker: Master with url spark://ST000000035:7077 requested this worker to reconnect.
21/01/28 09:28:08 INFO Worker: Not spawning another attempt to register with the master, since there is an attempt scheduled already.
21/01/28 09:28:08 INFO Worker: Successfully registered with master spark://ST000000035:7077
21/01/28 21:07:20 INFO Worker: Master with url spark://ST000000035:7077 requested this worker to reconnect.
21/01/28 21:07:20 INFO Worker: Master with url spark://ST000000035:7077 requested this worker to reconnect.
21/01/28 21:07:20 INFO Worker: Connecting to master ST000000035:7077...
21/01/28 21:07:20 INFO Worker: Not spawning another attempt to register with the master, since there is an attempt scheduled already.
21/01/28 21:07:20 INFO Worker: Master with url spark://ST000000035:7077 requested this worker to reconnect.
21/01/28 21:07:20 INFO Worker: Not spawning another attempt to register with the master, since there is an attempt scheduled already.
21/01/28 21:07:20 INFO Worker: Master with url spark://ST000000035:7077 requested this worker to reconnect.
21/01/28 21:07:20 INFO Worker: Not spawning another attempt to register with the master, since there is an attempt scheduled already.
21/01/28 21:07:20 INFO Worker: Master with url spark://ST000000035:7077 requested this worker to reconnect.
21/01/28 21:07:20 INFO Worker: Not spawning another attempt to register with the master, since there is an attempt scheduled already.
21/01/28 21:07:20 INFO Worker: Master with url spark://ST000000035:7077 requested this worker to reconnect.
21/01/28 21:07:20 INFO Worker: Not spawning another attempt to register with the master, since there is an attempt scheduled already.
21/01/28 21:07:20 INFO Worker: Master with url spark://ST000000035:7077 requested this worker to reconnect.
21/01/28 21:07:20 INFO Worker: Not spawning another attempt to register with the master, since there is an attempt scheduled already.
21/01/28 21:07:20 INFO Worker: Master with url spark://ST000000035:7077 requested this worker to reconnect.
21/01/28 21:07:20 INFO Worker: Not spawning another attempt to register with the master, since there is an attempt scheduled already.
21/01/28 21:07:20 INFO Worker: Master with url spark://ST000000035:7077 requested this worker to reconnect.
21/01/28 21:07:20 INFO Worker: Not spawning another attempt to register with the master, since there is an attempt scheduled already.
21/01/28 21:07:20 INFO Worker: Master with url spark://ST000000035:7077 requested this worker to reconnect.
21/01/28 21:07:20 INFO Worker: Not spawning another attempt to register with the master, since there is an attempt scheduled already.
21/01/28 21:07:20 INFO Worker: Master with url spark://ST000000035:7077 requested this worker to reconnect.
21/01/28 21:07:20 INFO Worker: Not spawning another attempt to register with the master, since there is an attempt scheduled already.
21/01/28 21:07:20 INFO Worker: Master with url spark://ST000000035:7077 requested this worker to reconnect.
21/01/28 21:07:20 INFO Worker: Not spawning another attempt to register with the master, since there is an attempt scheduled already.
21/01/28 21:07:20 INFO Worker: Master with url spark://ST000000035:7077 requested this worker to reconnect.
21/01/28 21:07:20 INFO Worker: Not spawning another attempt to register with the master, since there is an attempt scheduled already.
21/01/28 21:07:20 INFO Worker: Master with url spark://ST000000035:7077 requested this worker to reconnect.
21/01/28 21:07:20 INFO Worker: Not spawning another attempt to register with the master, since there is an attempt scheduled already.
21/01/28 21:07:20 INFO Worker: Master with url spark://ST000000035:7077 requested this worker to reconnect.
21/01/28 21:07:20 INFO Worker: Not spawning another attempt to register with the master, since there is an attempt scheduled already.
21/01/28 21:07:20 INFO Worker: Master with url spark://ST000000035:7077 requested this worker to reconnect.
21/01/28 21:07:20 INFO Worker: Not spawning another attempt to register with the master, since there is an attempt scheduled already.
21/01/28 21:07:20 INFO Worker: Master with url spark://ST000000035:7077 requested this worker to reconnect.
21/01/28 21:07:20 INFO Worker: Not spawning another attempt to register with the master, since there is an attempt scheduled already.
21/01/28 21:07:20 INFO Worker: Master with url spark://ST000000035:7077 requested this worker to reconnect.
21/01/28 21:07:20 INFO Worker: Not spawning another attempt to register with the master, since there is an attempt scheduled already.
21/01/28 21:07:20 INFO Worker: Master with url spark://ST000000035:7077 requested this worker to reconnect.
21/01/28 21:07:20 INFO Worker: Not spawning another attempt to register with the master, since there is an attempt scheduled already.
21/01/28 21:07:20 INFO Worker: Master with url spark://ST000000035:7077 requested this worker to reconnect.
21/01/28 21:07:20 INFO Worker: Not spawning another attempt to register with the master, since there is an attempt scheduled already.
21/01/28 21:07:20 INFO Worker: Master with url spark://ST000000035:7077 requested this worker to reconnect.
21/01/28 21:07:20 INFO Worker: Not spawning another attempt to register with the master, since there is an attempt scheduled already.
21/01/28 21:07:20 INFO Worker: Master with url spark://ST000000035:7077 requested this worker to reconnect.
21/01/28 21:07:20 INFO Worker: Not spawning another attempt to register with the master, since there is an attempt scheduled already.
21/01/28 21:07:20 INFO Worker: Master with url spark://ST000000035:7077 requested this worker to reconnect.
21/01/28 21:07:20 INFO Worker: Not spawning another attempt to register with the master, since there is an attempt scheduled already.
21/01/28 21:07:20 INFO Worker: Master with url spark://ST000000035:7077 requested this worker to reconnect.
21/01/28 21:07:20 INFO Worker: Not spawning another attempt to register with the master, since there is an attempt scheduled already.
21/01/28 21:07:20 INFO Worker: Master with url spark://ST000000035:7077 requested this worker to reconnect.
21/01/28 21:07:20 INFO Worker: Not spawning another attempt to register with the master, since there is an attempt scheduled already.
21/01/28 21:07:20 INFO Worker: Master with url spark://ST000000035:7077 requested this worker to reconnect.
21/01/28 21:07:20 INFO Worker: Not spawning another attempt to register with the master, since there is an attempt scheduled already.
21/01/28 21:07:20 INFO Worker: Master with url spark://ST000000035:7077 requested this worker to reconnect.
21/01/28 21:07:20 INFO Worker: Not spawning another attempt to register with the master, since there is an attempt scheduled already.
21/01/28 21:07:20 INFO Worker: Master with url spark://ST000000035:7077 requested this worker to reconnect.
21/01/28 21:07:20 INFO Worker: Not spawning another attempt to register with the master, since there is an attempt scheduled already.
21/01/28 21:07:20 INFO Worker: Master with url spark://ST000000035:7077 requested this worker to reconnect.
21/01/28 21:07:20 INFO Worker: Not spawning another attempt to register with the master, since there is an attempt scheduled already.
21/01/28 21:07:20 INFO Worker: Successfully registered with master spark://ST000000035:7077
21/01/28 21:10:42 INFO Worker: Master with url spark://ST000000035:7077 requested this worker to reconnect.
21/01/28 21:10:42 INFO Worker: Master with url spark://ST000000035:7077 requested this worker to reconnect.
21/01/28 21:10:42 INFO Worker: Not spawning another attempt to register with the master, since there is an attempt scheduled already.
21/01/28 21:10:42 INFO Worker: Connecting to master ST000000035:7077...
21/01/28 21:10:42 INFO Worker: Master with url spark://ST000000035:7077 requested this worker to reconnect.
21/01/28 21:10:42 INFO Worker: Not spawning another attempt to register with the master, since there is an attempt scheduled already.
21/01/28 21:10:42 INFO Worker: Master with url spark://ST000000035:7077 requested this worker to reconnect.
21/01/28 21:10:42 INFO Worker: Not spawning another attempt to register with the master, since there is an attempt scheduled already.
21/01/28 21:10:42 INFO Worker: Master with url spark://ST000000035:7077 requested this worker to reconnect.
21/01/28 21:10:42 INFO Worker: Not spawning another attempt to register with the master, since there is an attempt scheduled already.
21/01/28 21:10:42 INFO Worker: Successfully registered with master spark://ST000000035:7077
21/01/29 01:11:24 INFO Worker: Master with url spark://ST000000035:7077 requested this worker to reconnect.
21/01/29 01:11:24 INFO Worker: Master with url spark://ST000000035:7077 requested this worker to reconnect.
21/01/29 01:11:24 INFO Worker: Not spawning another attempt to register with the master, since there is an attempt scheduled already.
21/01/29 01:11:24 INFO Worker: Master with url spark://ST000000035:7077 requested this worker to reconnect.
21/01/29 01:11:24 INFO Worker: Not spawning another attempt to register with the master, since there is an attempt scheduled already.
21/01/29 01:11:24 INFO Worker: Master with url spark://ST000000035:7077 requested this worker to reconnect.
21/01/29 01:11:24 INFO Worker: Not spawning another attempt to register with the master, since there is an attempt scheduled already.
21/01/29 01:11:24 INFO Worker: Master with url spark://ST000000035:7077 requested this worker to reconnect.
21/01/29 01:11:24 INFO Worker: Not spawning another attempt to register with the master, since there is an attempt scheduled already.
21/01/29 01:11:24 INFO Worker: Master with url spark://ST000000035:7077 requested this worker to reconnect.
21/01/29 01:11:24 INFO Worker: Not spawning another attempt to register with the master, since there is an attempt scheduled already.
21/01/29 01:11:24 INFO Worker: Master with url spark://ST000000035:7077 requested this worker to reconnect.
21/01/29 01:11:24 INFO Worker: Not spawning another attempt to register with the master, since there is an attempt scheduled already.
21/01/29 01:11:24 INFO Worker: Master with url spark://ST000000035:7077 requested this worker to reconnect.
21/01/29 01:11:24 INFO Worker: Connecting to master ST000000035:7077...
21/01/29 01:11:24 INFO Worker: Not spawning another attempt to register with the master, since there is an attempt scheduled already.
21/01/29 01:11:24 INFO Worker: Master with url spark://ST000000035:7077 requested this worker to reconnect.
21/01/29 01:11:24 INFO Worker: Not spawning another attempt to register with the master, since there is an attempt scheduled already.
21/01/29 01:11:24 INFO Worker: Master with url spark://ST000000035:7077 requested this worker to reconnect.
21/01/29 01:11:24 INFO Worker: Not spawning another attempt to register with the master, since there is an attempt scheduled already.
21/01/29 01:11:24 INFO Worker: Master with url spark://ST000000035:7077 requested this worker to reconnect.
21/01/29 01:11:24 INFO Worker: Not spawning another attempt to register with the master, since there is an attempt scheduled already.
21/01/29 01:11:24 INFO Worker: Master with url spark://ST000000035:7077 requested this worker to reconnect.
21/01/29 01:11:24 INFO Worker: Not spawning another attempt to register with the master, since there is an attempt scheduled already.
21/01/29 01:11:24 INFO Worker: Master with url spark://ST000000035:7077 requested this worker to reconnect.
21/01/29 01:11:24 INFO Worker: Not spawning another attempt to register with the master, since there is an attempt scheduled already.
21/01/29 01:11:24 INFO Worker: Master with url spark://ST000000035:7077 requested this worker to reconnect.
21/01/29 01:11:24 INFO Worker: Not spawning another attempt to register with the master, since there is an attempt scheduled already.
21/01/29 01:11:24 INFO Worker: Master with url spark://ST000000035:7077 requested this worker to reconnect.
21/01/29 01:11:24 INFO Worker: Not spawning another attempt to register with the master, since there is an attempt scheduled already.
21/01/29 01:11:24 INFO Worker: Master with url spark://ST000000035:7077 requested this worker to reconnect.
21/01/29 01:11:24 INFO Worker: Not spawning another attempt to register with the master, since there is an attempt scheduled already.
21/01/29 01:11:24 INFO Worker: Master with url spark://ST000000035:7077 requested this worker to reconnect.
21/01/29 01:11:24 INFO Worker: Not spawning another attempt to register with the master, since there is an attempt scheduled already.
21/01/29 01:11:25 INFO Worker: Successfully registered with master spark://ST000000035:7077
21/01/29 01:46:57 INFO Worker: ST000000035:7077 Disassociated !
21/01/29 01:46:57 ERROR Worker: Connection to master failed! Waiting for master to reconnect...
21/01/29 01:46:57 INFO Worker: ST000000035:7077 Disassociated !
21/01/29 01:46:57 ERROR Worker: Connection to master failed! Waiting for master to reconnect...
21/01/29 01:46:57 INFO Worker: Not spawning another attempt to register with the master, since there is an attempt scheduled already.
21/01/29 01:46:57 INFO Worker: Connecting to master ST000000035:7077...
21/01/29 01:46:57 INFO TransportClientFactory: Found inactive connection to ST000000035/192.168.11.7:7077, creating a new one.
21/01/29 01:46:57 WARN Worker: Failed to connect to master ST000000035:7077
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:302)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:101)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:109)
	at org.apache.spark.deploy.worker.Worker$$anon$1.run(Worker.scala:277)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Failed to connect to ST000000035/192.168.11.7:7077
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:253)
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:195)
	at org.apache.spark.rpc.netty.NettyRpcEnv.createClient(NettyRpcEnv.scala:204)
	at org.apache.spark.rpc.netty.Outbox$$anon$1.call(Outbox.scala:202)
	at org.apache.spark.rpc.netty.Outbox$$anon$1.call(Outbox.scala:198)
	... 4 more
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: ST000000035/192.168.11.7:7077
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:330)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:334)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:702)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:650)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:576)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493)
	at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)
	at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.lang.Thread.run(Thread.java:748)
21/01/29 01:47:04 INFO Worker: Retrying connection to master (attempt # 1)
21/01/29 01:47:04 INFO Worker: Connecting to master ST000000035:7077...
21/01/29 01:47:04 INFO TransportClientFactory: Found inactive connection to ST000000035/192.168.11.7:7077, creating a new one.
21/01/29 01:47:04 WARN Worker: Failed to connect to master ST000000035:7077
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:302)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:101)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:109)
	at org.apache.spark.deploy.worker.Worker$$anon$2.run(Worker.scala:334)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Failed to connect to ST000000035/192.168.11.7:7077
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:253)
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:195)
	at org.apache.spark.rpc.netty.NettyRpcEnv.createClient(NettyRpcEnv.scala:204)
	at org.apache.spark.rpc.netty.Outbox$$anon$1.call(Outbox.scala:202)
	at org.apache.spark.rpc.netty.Outbox$$anon$1.call(Outbox.scala:198)
	... 4 more
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: ST000000035/192.168.11.7:7077
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:330)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:334)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:702)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:650)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:576)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493)
	at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)
	at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.lang.Thread.run(Thread.java:748)
21/01/29 01:47:11 INFO Worker: Retrying connection to master (attempt # 2)
21/01/29 01:47:11 INFO Worker: Connecting to master ST000000035:7077...
21/01/29 01:47:11 INFO TransportClientFactory: Found inactive connection to ST000000035/192.168.11.7:7077, creating a new one.
21/01/29 01:47:11 WARN Worker: Failed to connect to master ST000000035:7077
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:302)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:101)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:109)
	at org.apache.spark.deploy.worker.Worker$$anon$2.run(Worker.scala:334)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Failed to connect to ST000000035/192.168.11.7:7077
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:253)
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:195)
	at org.apache.spark.rpc.netty.NettyRpcEnv.createClient(NettyRpcEnv.scala:204)
	at org.apache.spark.rpc.netty.Outbox$$anon$1.call(Outbox.scala:202)
	at org.apache.spark.rpc.netty.Outbox$$anon$1.call(Outbox.scala:198)
	... 4 more
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: ST000000035/192.168.11.7:7077
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:330)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:334)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:702)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:650)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:576)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493)
	at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)
	at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.lang.Thread.run(Thread.java:748)
21/01/29 01:47:16 ERROR Worker: RECEIVED SIGNAL TERM
21/01/29 01:47:16 INFO ShutdownHookManager: Shutdown hook called
21/01/29 01:47:16 INFO ShutdownHookManager: Deleting directory /private/var/folders/tm/7v5m6cg144g467bsj7zgsxgc0000gn/T/spark-3447a774-bc98-4a77-941c-f02715974f6d
