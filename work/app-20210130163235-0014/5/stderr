Spark Executor Command: "/Library/Java/JavaVirtualMachines/adoptopenjdk-8.jdk/Contents/Home/jre/bin/java" "-cp" "/Users/kinsho/workspace/spark-3.0.1/conf/:/Users/kinsho/workspace/spark-3.0.1/assembly/target/scala-2.12/jars/*" "-Xmx1024M" "-Dspark.driver.port=55052" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@192.168.11.7:55052" "--executor-id" "5" "--hostname" "192.168.11.7" "--cores" "2" "--app-id" "app-20210130163235-0014" "--worker-url" "spark://Worker@192.168.11.7:63944"
========================================

Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
21/01/30 16:32:37 INFO CoarseGrainedExecutorBackend: Started daemon with process name: 14878@ST000000035
21/01/30 16:32:37 INFO SignalUtils: Registered signal handler for TERM
21/01/30 16:32:37 INFO SignalUtils: Registered signal handler for HUP
21/01/30 16:32:37 INFO SignalUtils: Registered signal handler for INT
21/01/30 16:32:38 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
21/01/30 16:32:38 INFO SecurityManager: Changing view acls to: kinsho
21/01/30 16:32:38 INFO SecurityManager: Changing modify acls to: kinsho
21/01/30 16:32:38 INFO SecurityManager: Changing view acls groups to: 
21/01/30 16:32:38 INFO SecurityManager: Changing modify acls groups to: 
21/01/30 16:32:38 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(kinsho); groups with view permissions: Set(); users  with modify permissions: Set(kinsho); groups with modify permissions: Set()
21/01/30 16:32:39 INFO TransportClientFactory: Successfully created connection to /192.168.11.7:55052 after 112 ms (0 ms spent in bootstraps)
21/01/30 16:32:39 INFO SecurityManager: Changing view acls to: kinsho
21/01/30 16:32:39 INFO SecurityManager: Changing modify acls to: kinsho
21/01/30 16:32:39 INFO SecurityManager: Changing view acls groups to: 
21/01/30 16:32:39 INFO SecurityManager: Changing modify acls groups to: 
21/01/30 16:32:39 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(kinsho); groups with view permissions: Set(); users  with modify permissions: Set(kinsho); groups with modify permissions: Set()
21/01/30 16:32:40 INFO TransportClientFactory: Successfully created connection to /192.168.11.7:55052 after 2 ms (0 ms spent in bootstraps)
21/01/30 16:32:40 INFO DiskBlockManager: Created local directory at /private/var/folders/tm/7v5m6cg144g467bsj7zgsxgc0000gn/T/spark-b22e2ad3-deb4-457b-874f-8b2b4492df5b/executor-67f36ed2-8f0a-4b30-a4b6-4d6c47c46160/blockmgr-9c20b011-6cec-4cef-aa38-8d850deccb7b
21/01/30 16:32:40 INFO MemoryStore: MemoryStore started with capacity 366.3 MiB
21/01/30 16:32:40 INFO CoarseGrainedExecutorBackend: Connecting to driver: spark://CoarseGrainedScheduler@192.168.11.7:55052
21/01/30 16:32:40 INFO WorkerWatcher: Connecting to worker spark://Worker@192.168.11.7:63944
21/01/30 16:32:40 INFO TransportClientFactory: Successfully created connection to /192.168.11.7:63944 after 7 ms (0 ms spent in bootstraps)
21/01/30 16:32:40 INFO ResourceUtils: ==============================================================
21/01/30 16:32:40 INFO ResourceUtils: Resources for spark.executor:

21/01/30 16:32:40 INFO ResourceUtils: ==============================================================
21/01/30 16:32:40 INFO CoarseGrainedExecutorBackend: Successfully registered with driver
21/01/30 16:32:40 INFO Executor: Starting executor ID 5 on host 192.168.11.7
21/01/30 16:32:40 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 55119.
21/01/30 16:32:40 INFO NettyBlockTransferService: Server created on 192.168.11.7:55119
21/01/30 16:32:40 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
21/01/30 16:32:41 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(5, 192.168.11.7, 55119, None)
21/01/30 16:32:41 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(5, 192.168.11.7, 55119, None)
21/01/30 16:32:41 INFO BlockManager: Initialized BlockManager: BlockManagerId(5, 192.168.11.7, 55119, None)
21/01/30 16:32:44 INFO CoarseGrainedExecutorBackend: Got assigned task 2
21/01/30 16:32:44 INFO Executor: Running task 0.1 in stage 1.0 (TID 2)
21/01/30 16:32:44 INFO Executor: Fetching spark://192.168.11.7:55052/jars/simple-project_2.12-1.0.jar with timestamp 1611991955233
21/01/30 16:32:44 INFO TransportClientFactory: Successfully created connection to /192.168.11.7:55052 after 1 ms (0 ms spent in bootstraps)
21/01/30 16:32:44 INFO Utils: Fetching spark://192.168.11.7:55052/jars/simple-project_2.12-1.0.jar to /private/var/folders/tm/7v5m6cg144g467bsj7zgsxgc0000gn/T/spark-b22e2ad3-deb4-457b-874f-8b2b4492df5b/executor-67f36ed2-8f0a-4b30-a4b6-4d6c47c46160/spark-ba8f7062-ad7d-48b4-9235-49ad38478e44/fetchFileTemp2875104420842112682.tmp
21/01/30 16:32:44 INFO Utils: Copying /private/var/folders/tm/7v5m6cg144g467bsj7zgsxgc0000gn/T/spark-b22e2ad3-deb4-457b-874f-8b2b4492df5b/executor-67f36ed2-8f0a-4b30-a4b6-4d6c47c46160/spark-ba8f7062-ad7d-48b4-9235-49ad38478e44/-850028311611991955233_cache to /Users/kinsho/workspace/spark-3.0.1/work/app-20210130163235-0014/5/./simple-project_2.12-1.0.jar
21/01/30 16:32:45 INFO Executor: Adding file:/Users/kinsho/workspace/spark-3.0.1/work/app-20210130163235-0014/5/./simple-project_2.12-1.0.jar to class loader
21/01/30 16:32:45 INFO TorrentBroadcast: Started reading broadcast variable 4 with 1 pieces (estimated total size 4.0 MiB)
21/01/30 16:32:45 INFO TransportClientFactory: Successfully created connection to /192.168.11.7:55114 after 1 ms (0 ms spent in bootstraps)
21/01/30 16:32:45 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 9.0 KiB, free 366.3 MiB)
21/01/30 16:32:45 INFO TorrentBroadcast: Reading broadcast variable 4 took 89 ms
21/01/30 16:32:45 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 24.6 KiB, free 366.3 MiB)
21/01/30 16:32:45 INFO CodeGenerator: Code generated in 174.727058 ms
21/01/30 16:32:45 INFO FileScanRDD: Reading File path: file:///Users/kinsho/Desktop/impressionLog.csv, range: 0-134217728, partition values: [empty row]
21/01/30 16:32:45 INFO CodeGenerator: Code generated in 29.670541 ms
21/01/30 16:32:45 INFO TorrentBroadcast: Started reading broadcast variable 3 with 1 pieces (estimated total size 4.0 MiB)
21/01/30 16:32:45 INFO TransportClientFactory: Successfully created connection to /192.168.11.7:55058 after 2 ms (0 ms spent in bootstraps)
21/01/30 16:32:45 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 24.0 KiB, free 366.2 MiB)
21/01/30 16:32:45 INFO TorrentBroadcast: Reading broadcast variable 3 took 10 ms
21/01/30 16:32:46 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 336.8 KiB, free 365.9 MiB)
21/01/30 16:32:46 ERROR Executor: Exception in task 0.1 in stage 1.0 (TID 2)
org.apache.spark.SparkException: Failed to execute user defined function(LogTransform$$$Lambda$2463/1768069354: (string) => boolean)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:729)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:340)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:872)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:872)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:127)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:446)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:449)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.NullPointerException
	at LogTransform$.$anonfun$main$1(LogTransform.scala:39)
	at LogTransform$.$anonfun$main$1$adapted(LogTransform.scala:39)
	... 17 more
21/01/30 16:32:47 INFO CoarseGrainedExecutorBackend: Driver commanded a shutdown
