Spark Executor Command: "/Library/Java/JavaVirtualMachines/adoptopenjdk-8.jdk/Contents/Home/jre/bin/java" "-cp" "/Users/kinsho/workspace/spark-3.0.1/conf/:/Users/kinsho/workspace/spark-3.0.1/assembly/target/scala-2.12/jars/*" "-Xmx1024M" "-Dspark.driver.port=55052" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@192.168.11.7:55052" "--executor-id" "8" "--hostname" "192.168.11.7" "--cores" "2" "--app-id" "app-20210130163235-0014" "--worker-url" "spark://Worker@192.168.11.7:63876"
========================================

Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
21/01/30 16:32:37 INFO CoarseGrainedExecutorBackend: Started daemon with process name: 14879@ST000000035
21/01/30 16:32:37 INFO SignalUtils: Registered signal handler for TERM
21/01/30 16:32:37 INFO SignalUtils: Registered signal handler for HUP
21/01/30 16:32:37 INFO SignalUtils: Registered signal handler for INT
21/01/30 16:32:38 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
21/01/30 16:32:38 INFO SecurityManager: Changing view acls to: kinsho
21/01/30 16:32:38 INFO SecurityManager: Changing modify acls to: kinsho
21/01/30 16:32:38 INFO SecurityManager: Changing view acls groups to: 
21/01/30 16:32:38 INFO SecurityManager: Changing modify acls groups to: 
21/01/30 16:32:38 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(kinsho); groups with view permissions: Set(); users  with modify permissions: Set(kinsho); groups with modify permissions: Set()
21/01/30 16:32:39 INFO TransportClientFactory: Successfully created connection to /192.168.11.7:55052 after 127 ms (0 ms spent in bootstraps)
21/01/30 16:32:39 INFO SecurityManager: Changing view acls to: kinsho
21/01/30 16:32:39 INFO SecurityManager: Changing modify acls to: kinsho
21/01/30 16:32:39 INFO SecurityManager: Changing view acls groups to: 
21/01/30 16:32:39 INFO SecurityManager: Changing modify acls groups to: 
21/01/30 16:32:39 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(kinsho); groups with view permissions: Set(); users  with modify permissions: Set(kinsho); groups with modify permissions: Set()
21/01/30 16:32:39 INFO TransportClientFactory: Successfully created connection to /192.168.11.7:55052 after 4 ms (0 ms spent in bootstraps)
21/01/30 16:32:39 INFO DiskBlockManager: Created local directory at /private/var/folders/tm/7v5m6cg144g467bsj7zgsxgc0000gn/T/spark-ed26b2ee-040f-4b9b-80d0-8d360fa07eb5/executor-4e8226fc-9166-460d-87b3-ce6203980cda/blockmgr-49765b70-2388-442e-b4e2-cddd7630a09b
21/01/30 16:32:39 INFO MemoryStore: MemoryStore started with capacity 366.3 MiB
21/01/30 16:32:40 INFO CoarseGrainedExecutorBackend: Connecting to driver: spark://CoarseGrainedScheduler@192.168.11.7:55052
21/01/30 16:32:40 INFO WorkerWatcher: Connecting to worker spark://Worker@192.168.11.7:63876
21/01/30 16:32:40 INFO TransportClientFactory: Successfully created connection to /192.168.11.7:63876 after 3 ms (0 ms spent in bootstraps)
21/01/30 16:32:40 INFO WorkerWatcher: Successfully connected to spark://Worker@192.168.11.7:63876
21/01/30 16:32:40 INFO ResourceUtils: ==============================================================
21/01/30 16:32:40 INFO ResourceUtils: Resources for spark.executor:

21/01/30 16:32:40 INFO ResourceUtils: ==============================================================
21/01/30 16:32:40 INFO CoarseGrainedExecutorBackend: Successfully registered with driver
21/01/30 16:32:40 INFO Executor: Starting executor ID 8 on host 192.168.11.7
21/01/30 16:32:40 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 55106.
21/01/30 16:32:40 INFO NettyBlockTransferService: Server created on 192.168.11.7:55106
21/01/30 16:32:40 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
21/01/30 16:32:40 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(8, 192.168.11.7, 55106, None)
21/01/30 16:32:40 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(8, 192.168.11.7, 55106, None)
21/01/30 16:32:40 INFO BlockManager: Initialized BlockManager: BlockManagerId(8, 192.168.11.7, 55106, None)
21/01/30 16:32:46 INFO CoarseGrainedExecutorBackend: Got assigned task 3
21/01/30 16:32:46 INFO Executor: Running task 0.2 in stage 1.0 (TID 3)
21/01/30 16:32:46 INFO Executor: Fetching spark://192.168.11.7:55052/jars/simple-project_2.12-1.0.jar with timestamp 1611991955233
21/01/30 16:32:46 INFO TransportClientFactory: Successfully created connection to /192.168.11.7:55052 after 1 ms (0 ms spent in bootstraps)
21/01/30 16:32:46 INFO Utils: Fetching spark://192.168.11.7:55052/jars/simple-project_2.12-1.0.jar to /private/var/folders/tm/7v5m6cg144g467bsj7zgsxgc0000gn/T/spark-ed26b2ee-040f-4b9b-80d0-8d360fa07eb5/executor-4e8226fc-9166-460d-87b3-ce6203980cda/spark-f839f692-62a8-45db-a95e-5a5048836391/fetchFileTemp702918033278097325.tmp
21/01/30 16:32:46 INFO Utils: Copying /private/var/folders/tm/7v5m6cg144g467bsj7zgsxgc0000gn/T/spark-ed26b2ee-040f-4b9b-80d0-8d360fa07eb5/executor-4e8226fc-9166-460d-87b3-ce6203980cda/spark-f839f692-62a8-45db-a95e-5a5048836391/-850028311611991955233_cache to /Users/kinsho/workspace/spark-3.0.1/work/app-20210130163235-0014/8/./simple-project_2.12-1.0.jar
21/01/30 16:32:46 INFO Executor: Adding file:/Users/kinsho/workspace/spark-3.0.1/work/app-20210130163235-0014/8/./simple-project_2.12-1.0.jar to class loader
21/01/30 16:32:46 INFO TorrentBroadcast: Started reading broadcast variable 4 with 1 pieces (estimated total size 4.0 MiB)
21/01/30 16:32:46 INFO TransportClientFactory: Successfully created connection to /192.168.11.7:55114 after 1 ms (0 ms spent in bootstraps)
21/01/30 16:32:46 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 9.0 KiB, free 366.3 MiB)
21/01/30 16:32:46 INFO TorrentBroadcast: Reading broadcast variable 4 took 86 ms
21/01/30 16:32:46 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 24.6 KiB, free 366.3 MiB)
21/01/30 16:32:47 INFO CodeGenerator: Code generated in 174.599526 ms
21/01/30 16:32:47 INFO FileScanRDD: Reading File path: file:///Users/kinsho/Desktop/impressionLog.csv, range: 0-134217728, partition values: [empty row]
21/01/30 16:32:47 INFO CodeGenerator: Code generated in 29.210271 ms
21/01/30 16:32:47 INFO TorrentBroadcast: Started reading broadcast variable 3 with 1 pieces (estimated total size 4.0 MiB)
21/01/30 16:32:47 INFO TransportClientFactory: Successfully created connection to /192.168.11.7:55119 after 1 ms (0 ms spent in bootstraps)
21/01/30 16:32:47 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 24.0 KiB, free 366.2 MiB)
21/01/30 16:32:47 INFO TorrentBroadcast: Reading broadcast variable 3 took 23 ms
21/01/30 16:32:47 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 336.8 KiB, free 365.9 MiB)
21/01/30 16:32:47 ERROR Executor: Exception in task 0.2 in stage 1.0 (TID 3)
org.apache.spark.SparkException: Failed to execute user defined function(LogTransform$$$Lambda$2463/1768069354: (string) => boolean)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:729)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:340)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:872)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:872)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:127)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:446)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:449)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.NullPointerException
	at LogTransform$.$anonfun$main$1(LogTransform.scala:39)
	at LogTransform$.$anonfun$main$1$adapted(LogTransform.scala:39)
	... 17 more
21/01/30 16:32:47 INFO CoarseGrainedExecutorBackend: Driver commanded a shutdown
