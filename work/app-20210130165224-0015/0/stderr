Spark Executor Command: "/Library/Java/JavaVirtualMachines/adoptopenjdk-8.jdk/Contents/Home/jre/bin/java" "-cp" "/Users/kinsho/workspace/spark-3.0.1/conf/:/Users/kinsho/workspace/spark-3.0.1/assembly/target/scala-2.12/jars/*" "-Xmx1024M" "-Dspark.driver.port=59986" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@192.168.11.7:59986" "--executor-id" "0" "--hostname" "192.168.11.7" "--cores" "2" "--app-id" "app-20210130165224-0015" "--worker-url" "spark://Worker@192.168.11.7:63978"
========================================

Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
21/01/30 16:52:26 INFO CoarseGrainedExecutorBackend: Started daemon with process name: 15393@ST000000035
21/01/30 16:52:26 INFO SignalUtils: Registered signal handler for TERM
21/01/30 16:52:26 INFO SignalUtils: Registered signal handler for HUP
21/01/30 16:52:26 INFO SignalUtils: Registered signal handler for INT
21/01/30 16:52:27 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
21/01/30 16:52:27 INFO SecurityManager: Changing view acls to: kinsho
21/01/30 16:52:27 INFO SecurityManager: Changing modify acls to: kinsho
21/01/30 16:52:27 INFO SecurityManager: Changing view acls groups to: 
21/01/30 16:52:27 INFO SecurityManager: Changing modify acls groups to: 
21/01/30 16:52:27 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(kinsho); groups with view permissions: Set(); users  with modify permissions: Set(kinsho); groups with modify permissions: Set()
21/01/30 16:52:28 INFO TransportClientFactory: Successfully created connection to /192.168.11.7:59986 after 118 ms (0 ms spent in bootstraps)
21/01/30 16:52:28 INFO SecurityManager: Changing view acls to: kinsho
21/01/30 16:52:28 INFO SecurityManager: Changing modify acls to: kinsho
21/01/30 16:52:28 INFO SecurityManager: Changing view acls groups to: 
21/01/30 16:52:28 INFO SecurityManager: Changing modify acls groups to: 
21/01/30 16:52:28 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(kinsho); groups with view permissions: Set(); users  with modify permissions: Set(kinsho); groups with modify permissions: Set()
21/01/30 16:52:28 INFO TransportClientFactory: Successfully created connection to /192.168.11.7:59986 after 2 ms (0 ms spent in bootstraps)
21/01/30 16:52:28 INFO DiskBlockManager: Created local directory at /private/var/folders/tm/7v5m6cg144g467bsj7zgsxgc0000gn/T/spark-fb50bbc1-385d-42b4-ab16-c5d025f6423b/executor-88761041-fca5-4676-9379-801c829a3d12/blockmgr-9fc896db-5d21-43c6-955d-b40ce2656cd7
21/01/30 16:52:28 INFO MemoryStore: MemoryStore started with capacity 366.3 MiB
21/01/30 16:52:29 INFO CoarseGrainedExecutorBackend: Connecting to driver: spark://CoarseGrainedScheduler@192.168.11.7:59986
21/01/30 16:52:29 INFO WorkerWatcher: Connecting to worker spark://Worker@192.168.11.7:63978
21/01/30 16:52:29 INFO TransportClientFactory: Successfully created connection to /192.168.11.7:63978 after 4 ms (0 ms spent in bootstraps)
21/01/30 16:52:29 INFO ResourceUtils: ==============================================================
21/01/30 16:52:29 INFO ResourceUtils: Resources for spark.executor:

21/01/30 16:52:29 INFO ResourceUtils: ==============================================================
21/01/30 16:52:29 INFO CoarseGrainedExecutorBackend: Successfully registered with driver
21/01/30 16:52:29 INFO Executor: Starting executor ID 0 on host 192.168.11.7
21/01/30 16:52:29 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 60049.
21/01/30 16:52:29 INFO NettyBlockTransferService: Server created on 192.168.11.7:60049
21/01/30 16:52:29 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
21/01/30 16:52:29 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(0, 192.168.11.7, 60049, None)
21/01/30 16:52:29 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(0, 192.168.11.7, 60049, None)
21/01/30 16:52:29 INFO BlockManager: Initialized BlockManager: BlockManagerId(0, 192.168.11.7, 60049, None)
21/01/30 16:52:36 INFO CoarseGrainedExecutorBackend: Got assigned task 3
21/01/30 16:52:36 INFO Executor: Running task 0.2 in stage 1.0 (TID 3)
21/01/30 16:52:36 INFO Executor: Fetching spark://192.168.11.7:59986/jars/simple-project_2.12-1.0.jar with timestamp 1611993144378
21/01/30 16:52:36 INFO TransportClientFactory: Successfully created connection to /192.168.11.7:59986 after 2 ms (0 ms spent in bootstraps)
21/01/30 16:52:36 INFO Utils: Fetching spark://192.168.11.7:59986/jars/simple-project_2.12-1.0.jar to /private/var/folders/tm/7v5m6cg144g467bsj7zgsxgc0000gn/T/spark-fb50bbc1-385d-42b4-ab16-c5d025f6423b/executor-88761041-fca5-4676-9379-801c829a3d12/spark-d99aa1c0-4cbe-4219-89a9-825717fbeb9e/fetchFileTemp4715679931428502570.tmp
21/01/30 16:52:36 INFO Utils: Copying /private/var/folders/tm/7v5m6cg144g467bsj7zgsxgc0000gn/T/spark-fb50bbc1-385d-42b4-ab16-c5d025f6423b/executor-88761041-fca5-4676-9379-801c829a3d12/spark-d99aa1c0-4cbe-4219-89a9-825717fbeb9e/-19995978771611993144378_cache to /Users/kinsho/workspace/spark-3.0.1/work/app-20210130165224-0015/0/./simple-project_2.12-1.0.jar
21/01/30 16:52:36 INFO Executor: Adding file:/Users/kinsho/workspace/spark-3.0.1/work/app-20210130165224-0015/0/./simple-project_2.12-1.0.jar to class loader
21/01/30 16:52:36 INFO TorrentBroadcast: Started reading broadcast variable 4 with 1 pieces (estimated total size 4.0 MiB)
21/01/30 16:52:36 INFO TransportClientFactory: Successfully created connection to /192.168.11.7:60039 after 1 ms (0 ms spent in bootstraps)
21/01/30 16:52:36 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 9.0 KiB, free 366.3 MiB)
21/01/30 16:52:36 INFO TorrentBroadcast: Reading broadcast variable 4 took 89 ms
21/01/30 16:52:36 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 24.5 KiB, free 366.3 MiB)
21/01/30 16:52:37 INFO CodeGenerator: Code generated in 185.805887 ms
21/01/30 16:52:37 INFO FileScanRDD: Reading File path: file:///Users/kinsho/Desktop/impressionLog.csv, range: 0-134217728, partition values: [empty row]
21/01/30 16:52:37 INFO CodeGenerator: Code generated in 25.080281 ms
21/01/30 16:52:37 INFO TorrentBroadcast: Started reading broadcast variable 3 with 1 pieces (estimated total size 4.0 MiB)
21/01/30 16:52:37 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 24.0 KiB, free 366.2 MiB)
21/01/30 16:52:37 INFO TorrentBroadcast: Reading broadcast variable 3 took 8 ms
21/01/30 16:52:37 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 336.8 KiB, free 365.9 MiB)
21/01/30 16:52:37 ERROR Executor: Exception in task 0.2 in stage 1.0 (TID 3)
org.apache.spark.SparkException: Failed to execute user defined function(LogTransform$$$Lambda$2462/331451322: (string) => boolean)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:729)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:340)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:872)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:872)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:127)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:446)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:449)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: scala.MatchError: null
	at LogTransform$.$anonfun$main$1(LogTransform.scala:40)
	at LogTransform$.$anonfun$main$1$adapted(LogTransform.scala:39)
	... 17 more
21/01/30 16:52:37 INFO CoarseGrainedExecutorBackend: Driver commanded a shutdown
