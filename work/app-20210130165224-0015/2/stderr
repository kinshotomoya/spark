Spark Executor Command: "/Library/Java/JavaVirtualMachines/adoptopenjdk-8.jdk/Contents/Home/jre/bin/java" "-cp" "/Users/kinsho/workspace/spark-3.0.1/conf/:/Users/kinsho/workspace/spark-3.0.1/assembly/target/scala-2.12/jars/*" "-Xmx1024M" "-Dspark.driver.port=59986" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@192.168.11.7:59986" "--executor-id" "2" "--hostname" "192.168.11.7" "--cores" "2" "--app-id" "app-20210130165224-0015" "--worker-url" "spark://Worker@192.168.11.7:63887"
========================================

Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
21/01/30 16:52:26 INFO CoarseGrainedExecutorBackend: Started daemon with process name: 15394@ST000000035
21/01/30 16:52:26 INFO SignalUtils: Registered signal handler for TERM
21/01/30 16:52:26 INFO SignalUtils: Registered signal handler for HUP
21/01/30 16:52:26 INFO SignalUtils: Registered signal handler for INT
21/01/30 16:52:27 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
21/01/30 16:52:27 INFO SecurityManager: Changing view acls to: kinsho
21/01/30 16:52:27 INFO SecurityManager: Changing modify acls to: kinsho
21/01/30 16:52:27 INFO SecurityManager: Changing view acls groups to: 
21/01/30 16:52:27 INFO SecurityManager: Changing modify acls groups to: 
21/01/30 16:52:27 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(kinsho); groups with view permissions: Set(); users  with modify permissions: Set(kinsho); groups with modify permissions: Set()
21/01/30 16:52:28 INFO TransportClientFactory: Successfully created connection to /192.168.11.7:59986 after 113 ms (0 ms spent in bootstraps)
21/01/30 16:52:28 INFO SecurityManager: Changing view acls to: kinsho
21/01/30 16:52:28 INFO SecurityManager: Changing modify acls to: kinsho
21/01/30 16:52:28 INFO SecurityManager: Changing view acls groups to: 
21/01/30 16:52:28 INFO SecurityManager: Changing modify acls groups to: 
21/01/30 16:52:28 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(kinsho); groups with view permissions: Set(); users  with modify permissions: Set(kinsho); groups with modify permissions: Set()
21/01/30 16:52:28 INFO TransportClientFactory: Successfully created connection to /192.168.11.7:59986 after 2 ms (0 ms spent in bootstraps)
21/01/30 16:52:28 INFO DiskBlockManager: Created local directory at /private/var/folders/tm/7v5m6cg144g467bsj7zgsxgc0000gn/T/spark-56526756-d62c-425a-9228-330d931c7738/executor-3065d500-675c-4695-bd82-3ea64bb4c5f7/blockmgr-d67595b7-bba1-4c95-8493-3869951c4921
21/01/30 16:52:28 INFO MemoryStore: MemoryStore started with capacity 366.3 MiB
21/01/30 16:52:29 INFO CoarseGrainedExecutorBackend: Connecting to driver: spark://CoarseGrainedScheduler@192.168.11.7:59986
21/01/30 16:52:29 INFO WorkerWatcher: Connecting to worker spark://Worker@192.168.11.7:63887
21/01/30 16:52:29 INFO ResourceUtils: ==============================================================
21/01/30 16:52:29 INFO ResourceUtils: Resources for spark.executor:

21/01/30 16:52:29 INFO ResourceUtils: ==============================================================
21/01/30 16:52:29 INFO TransportClientFactory: Successfully created connection to /192.168.11.7:63887 after 6 ms (0 ms spent in bootstraps)
21/01/30 16:52:29 INFO WorkerWatcher: Successfully connected to spark://Worker@192.168.11.7:63887
21/01/30 16:52:29 INFO CoarseGrainedExecutorBackend: Successfully registered with driver
21/01/30 16:52:29 INFO Executor: Starting executor ID 2 on host 192.168.11.7
21/01/30 16:52:29 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 60051.
21/01/30 16:52:29 INFO NettyBlockTransferService: Server created on 192.168.11.7:60051
21/01/30 16:52:29 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
21/01/30 16:52:29 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(2, 192.168.11.7, 60051, None)
21/01/30 16:52:29 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(2, 192.168.11.7, 60051, None)
21/01/30 16:52:29 INFO BlockManager: Initialized BlockManager: BlockManagerId(2, 192.168.11.7, 60051, None)
21/01/30 16:52:33 INFO CoarseGrainedExecutorBackend: Got assigned task 1
21/01/30 16:52:33 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
21/01/30 16:52:33 INFO Executor: Fetching spark://192.168.11.7:59986/jars/simple-project_2.12-1.0.jar with timestamp 1611993144378
21/01/30 16:52:33 INFO TransportClientFactory: Successfully created connection to /192.168.11.7:59986 after 1 ms (0 ms spent in bootstraps)
21/01/30 16:52:33 INFO Utils: Fetching spark://192.168.11.7:59986/jars/simple-project_2.12-1.0.jar to /private/var/folders/tm/7v5m6cg144g467bsj7zgsxgc0000gn/T/spark-56526756-d62c-425a-9228-330d931c7738/executor-3065d500-675c-4695-bd82-3ea64bb4c5f7/spark-d6678e47-14df-4b80-a556-48b0bd32f1b5/fetchFileTemp5251675956698055063.tmp
21/01/30 16:52:33 INFO Utils: Copying /private/var/folders/tm/7v5m6cg144g467bsj7zgsxgc0000gn/T/spark-56526756-d62c-425a-9228-330d931c7738/executor-3065d500-675c-4695-bd82-3ea64bb4c5f7/spark-d6678e47-14df-4b80-a556-48b0bd32f1b5/-19995978771611993144378_cache to /Users/kinsho/workspace/spark-3.0.1/work/app-20210130165224-0015/2/./simple-project_2.12-1.0.jar
21/01/30 16:52:33 INFO Executor: Adding file:/Users/kinsho/workspace/spark-3.0.1/work/app-20210130165224-0015/2/./simple-project_2.12-1.0.jar to class loader
21/01/30 16:52:33 INFO TorrentBroadcast: Started reading broadcast variable 4 with 1 pieces (estimated total size 4.0 MiB)
21/01/30 16:52:33 INFO TransportClientFactory: Successfully created connection to /192.168.11.7:59992 after 1 ms (0 ms spent in bootstraps)
21/01/30 16:52:33 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 9.0 KiB, free 366.3 MiB)
21/01/30 16:52:33 INFO TorrentBroadcast: Reading broadcast variable 4 took 81 ms
21/01/30 16:52:33 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 24.5 KiB, free 366.3 MiB)
21/01/30 16:52:34 INFO CodeGenerator: Code generated in 180.697345 ms
21/01/30 16:52:34 INFO FileScanRDD: Reading File path: file:///Users/kinsho/Desktop/impressionLog.csv, range: 0-134217728, partition values: [empty row]
21/01/30 16:52:34 INFO CodeGenerator: Code generated in 29.259373 ms
21/01/30 16:52:34 INFO TorrentBroadcast: Started reading broadcast variable 3 with 1 pieces (estimated total size 4.0 MiB)
21/01/30 16:52:34 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 24.0 KiB, free 366.2 MiB)
21/01/30 16:52:34 INFO TorrentBroadcast: Reading broadcast variable 3 took 9 ms
21/01/30 16:52:34 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 336.8 KiB, free 365.9 MiB)
21/01/30 16:52:34 ERROR Executor: Exception in task 0.0 in stage 1.0 (TID 1)
org.apache.spark.SparkException: Failed to execute user defined function(LogTransform$$$Lambda$2462/331451322: (string) => boolean)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:729)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:340)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:872)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:872)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:127)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:446)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:449)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: scala.MatchError: null
	at LogTransform$.$anonfun$main$1(LogTransform.scala:40)
	at LogTransform$.$anonfun$main$1$adapted(LogTransform.scala:39)
	... 17 more
21/01/30 16:52:37 INFO CoarseGrainedExecutorBackend: Driver commanded a shutdown
