Spark Executor Command: "/Library/Java/JavaVirtualMachines/adoptopenjdk-8.jdk/Contents/Home/jre/bin/java" "-cp" "/Users/kinsho/workspace/spark-3.0.1/conf/:/Users/kinsho/workspace/spark-3.0.1/assembly/target/scala-2.12/jars/*" "-Xmx1024M" "-Dspark.driver.port=61200" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@192.168.11.7:61200" "--executor-id" "6" "--hostname" "192.168.11.7" "--cores" "2" "--app-id" "app-20210131124043-0029" "--worker-url" "spark://Worker@192.168.11.7:63887"
========================================

Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
21/01/31 12:40:45 INFO CoarseGrainedExecutorBackend: Started daemon with process name: 26417@ST000000035
21/01/31 12:40:45 INFO SignalUtils: Registered signal handler for TERM
21/01/31 12:40:45 INFO SignalUtils: Registered signal handler for HUP
21/01/31 12:40:45 INFO SignalUtils: Registered signal handler for INT
21/01/31 12:40:45 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
21/01/31 12:40:46 INFO SecurityManager: Changing view acls to: kinsho
21/01/31 12:40:46 INFO SecurityManager: Changing modify acls to: kinsho
21/01/31 12:40:46 INFO SecurityManager: Changing view acls groups to: 
21/01/31 12:40:46 INFO SecurityManager: Changing modify acls groups to: 
21/01/31 12:40:46 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(kinsho); groups with view permissions: Set(); users  with modify permissions: Set(kinsho); groups with modify permissions: Set()
21/01/31 12:40:47 INFO TransportClientFactory: Successfully created connection to /192.168.11.7:61200 after 119 ms (0 ms spent in bootstraps)
21/01/31 12:40:47 INFO SecurityManager: Changing view acls to: kinsho
21/01/31 12:40:47 INFO SecurityManager: Changing modify acls to: kinsho
21/01/31 12:40:47 INFO SecurityManager: Changing view acls groups to: 
21/01/31 12:40:47 INFO SecurityManager: Changing modify acls groups to: 
21/01/31 12:40:47 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(kinsho); groups with view permissions: Set(); users  with modify permissions: Set(kinsho); groups with modify permissions: Set()
21/01/31 12:40:47 INFO TransportClientFactory: Successfully created connection to /192.168.11.7:61200 after 2 ms (0 ms spent in bootstraps)
21/01/31 12:40:47 INFO DiskBlockManager: Created local directory at /private/var/folders/tm/7v5m6cg144g467bsj7zgsxgc0000gn/T/spark-56526756-d62c-425a-9228-330d931c7738/executor-b37d4f66-963d-4777-970a-c0797286c96c/blockmgr-6fa3212a-ba82-4a21-9915-863ea0b3b812
21/01/31 12:40:47 INFO MemoryStore: MemoryStore started with capacity 366.3 MiB
21/01/31 12:40:47 INFO CoarseGrainedExecutorBackend: Connecting to driver: spark://CoarseGrainedScheduler@192.168.11.7:61200
21/01/31 12:40:47 INFO WorkerWatcher: Connecting to worker spark://Worker@192.168.11.7:63887
21/01/31 12:40:47 INFO TransportClientFactory: Successfully created connection to /192.168.11.7:63887 after 4 ms (0 ms spent in bootstraps)
21/01/31 12:40:47 INFO ResourceUtils: ==============================================================
21/01/31 12:40:47 INFO ResourceUtils: Resources for spark.executor:

21/01/31 12:40:47 INFO ResourceUtils: ==============================================================
21/01/31 12:40:48 INFO CoarseGrainedExecutorBackend: Successfully registered with driver
21/01/31 12:40:48 INFO Executor: Starting executor ID 6 on host 192.168.11.7
21/01/31 12:40:48 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 61263.
21/01/31 12:40:48 INFO NettyBlockTransferService: Server created on 192.168.11.7:61263
21/01/31 12:40:48 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
21/01/31 12:40:48 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(6, 192.168.11.7, 61263, None)
21/01/31 12:40:48 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(6, 192.168.11.7, 61263, None)
21/01/31 12:40:48 INFO BlockManager: Initialized BlockManager: BlockManagerId(6, 192.168.11.7, 61263, None)
21/01/31 12:40:52 INFO CoarseGrainedExecutorBackend: Got assigned task 2
21/01/31 12:40:52 INFO CoarseGrainedExecutorBackend: Got assigned task 12
21/01/31 12:40:52 INFO Executor: Running task 1.0 in stage 1.0 (TID 2)
21/01/31 12:40:52 INFO Executor: Running task 11.0 in stage 1.0 (TID 12)
21/01/31 12:40:52 INFO Executor: Fetching spark://192.168.11.7:61200/jars/simple-project_2.12-1.0.jar with timestamp 1612064442939
21/01/31 12:40:52 INFO TransportClientFactory: Successfully created connection to /192.168.11.7:61200 after 2 ms (0 ms spent in bootstraps)
21/01/31 12:40:52 INFO Utils: Fetching spark://192.168.11.7:61200/jars/simple-project_2.12-1.0.jar to /private/var/folders/tm/7v5m6cg144g467bsj7zgsxgc0000gn/T/spark-56526756-d62c-425a-9228-330d931c7738/executor-b37d4f66-963d-4777-970a-c0797286c96c/spark-cf3b471c-924c-4e1c-8bcc-6df0a4e34203/fetchFileTemp134580106718395437.tmp
21/01/31 12:40:52 INFO Utils: Copying /private/var/folders/tm/7v5m6cg144g467bsj7zgsxgc0000gn/T/spark-56526756-d62c-425a-9228-330d931c7738/executor-b37d4f66-963d-4777-970a-c0797286c96c/spark-cf3b471c-924c-4e1c-8bcc-6df0a4e34203/20408847431612064442939_cache to /Users/kinsho/workspace/spark-3.0.1/work/app-20210131124043-0029/6/./simple-project_2.12-1.0.jar
21/01/31 12:40:52 INFO Executor: Adding file:/Users/kinsho/workspace/spark-3.0.1/work/app-20210131124043-0029/6/./simple-project_2.12-1.0.jar to class loader
21/01/31 12:40:53 INFO TorrentBroadcast: Started reading broadcast variable 4 with 1 pieces (estimated total size 4.0 MiB)
21/01/31 12:40:53 INFO TransportClientFactory: Successfully created connection to /192.168.11.7:61206 after 8 ms (0 ms spent in bootstraps)
21/01/31 12:40:53 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 18.1 KiB, free 366.3 MiB)
21/01/31 12:40:53 INFO TorrentBroadcast: Reading broadcast variable 4 took 438 ms
21/01/31 12:40:54 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 43.3 KiB, free 366.2 MiB)
21/01/31 12:40:55 INFO FileScanRDD: Reading File path: file:///Users/kinsho/Desktop/impressionLog.csv, range: 1476395008-1610612736, partition values: [empty row]
21/01/31 12:40:55 INFO FileScanRDD: Reading File path: file:///Users/kinsho/Desktop/impressionLog.csv, range: 134217728-268435456, partition values: [empty row]
21/01/31 12:40:57 INFO CodeGenerator: Code generated in 1140.788864 ms
21/01/31 12:40:57 INFO TorrentBroadcast: Started reading broadcast variable 3 with 1 pieces (estimated total size 4.0 MiB)
21/01/31 12:40:57 INFO TransportClientFactory: Successfully created connection to /192.168.11.7:61266 after 2 ms (0 ms spent in bootstraps)
21/01/31 12:40:57 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 24.0 KiB, free 366.2 MiB)
21/01/31 12:40:57 INFO TorrentBroadcast: Reading broadcast variable 3 took 31 ms
21/01/31 12:40:58 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 336.8 KiB, free 365.9 MiB)
21/01/31 12:41:24 INFO MemoryStore: Will not store rdd_12_11
21/01/31 12:41:24 WARN MemoryStore: Not enough space to cache rdd_12_11 in memory! (computed 135.8 MiB so far)
21/01/31 12:41:24 INFO MemoryStore: Memory use = 422.1 KiB (blocks) + 310.3 MiB (scratch space shared across 2 tasks(s)) = 310.7 MiB. Storage limit = 366.3 MiB.
21/01/31 12:41:24 WARN BlockManager: Persisting block rdd_12_11 to disk instead.
21/01/31 12:41:29 INFO MemoryStore: Block rdd_12_1 stored as values in memory (estimated size 164.0 MiB, free 201.9 MiB)
21/01/31 12:41:29 INFO CodeGenerator: Code generated in 28.033892 ms
21/01/31 12:41:29 INFO CodeGenerator: Code generated in 38.689585 ms
21/01/31 12:41:29 INFO CodeGenerator: Code generated in 30.207052 ms
21/01/31 12:41:29 INFO Executor: Finished task 1.0 in stage 1.0 (TID 2). 2151 bytes result sent to driver
21/01/31 12:41:29 INFO CoarseGrainedExecutorBackend: Got assigned task 22
21/01/31 12:41:29 INFO Executor: Running task 21.0 in stage 1.0 (TID 22)
21/01/31 12:41:30 INFO FileScanRDD: Reading File path: file:///Users/kinsho/Desktop/impressionLog.csv, range: 2818572288-2952790016, partition values: [empty row]
21/01/31 12:41:35 INFO MemoryStore: Will not store rdd_12_11
21/01/31 12:41:35 WARN MemoryStore: Not enough space to cache rdd_12_11 in memory! (computed 135.8 MiB so far)
21/01/31 12:41:35 INFO MemoryStore: Memory use = 164.4 MiB (blocks) + 106.7 MiB (scratch space shared across 2 tasks(s)) = 271.1 MiB. Storage limit = 366.3 MiB.
21/01/31 12:41:36 INFO Executor: Finished task 11.0 in stage 1.0 (TID 12). 2108 bytes result sent to driver
21/01/31 12:41:36 INFO CoarseGrainedExecutorBackend: Got assigned task 39
21/01/31 12:41:36 INFO Executor: Running task 38.0 in stage 1.0 (TID 39)
21/01/31 12:41:36 INFO FileScanRDD: Reading File path: file:///Users/kinsho/Desktop/impressionLog.csv, range: 5100273664-5234491392, partition values: [empty row]
21/01/31 12:41:48 INFO MemoryStore: Will not store rdd_12_38
21/01/31 12:41:48 WARN MemoryStore: Not enough space to cache rdd_12_38 in memory! (computed 69.2 MiB so far)
21/01/31 12:41:48 INFO MemoryStore: Memory use = 164.4 MiB (blocks) + 155.5 MiB (scratch space shared across 2 tasks(s)) = 319.9 MiB. Storage limit = 366.3 MiB.
21/01/31 12:41:48 WARN BlockManager: Persisting block rdd_12_38 to disk instead.
21/01/31 12:42:04 INFO MemoryStore: Block rdd_12_21 stored as values in memory (estimated size 185.1 MiB, free 16.9 MiB)
21/01/31 12:42:04 INFO Executor: Finished task 21.0 in stage 1.0 (TID 22). 2108 bytes result sent to driver
21/01/31 12:42:04 INFO CoarseGrainedExecutorBackend: Got assigned task 42
21/01/31 12:42:04 INFO Executor: Running task 41.0 in stage 1.0 (TID 42)
21/01/31 12:42:04 INFO FileScanRDD: Reading File path: file:///Users/kinsho/Desktop/impressionLog.csv, range: 5502926848-5637144576, partition values: [empty row]
21/01/31 12:42:07 INFO MemoryStore: Will not store rdd_12_38
21/01/31 12:42:07 WARN MemoryStore: Not enough space to cache rdd_12_38 in memory! (computed 35.5 MiB so far)
21/01/31 12:42:07 INFO MemoryStore: Memory use = 349.4 MiB (blocks) + 6.4 MiB (scratch space shared across 2 tasks(s)) = 355.8 MiB. Storage limit = 366.3 MiB.
21/01/31 12:42:07 INFO Executor: Finished task 38.0 in stage 1.0 (TID 39). 2108 bytes result sent to driver
21/01/31 12:42:07 INFO CoarseGrainedExecutorBackend: Got assigned task 50
21/01/31 12:42:07 INFO Executor: Running task 49.0 in stage 1.0 (TID 50)
21/01/31 12:42:07 INFO FileScanRDD: Reading File path: file:///Users/kinsho/Desktop/impressionLog.csv, range: 6576668672-6710886400, partition values: [empty row]
21/01/31 12:42:11 INFO MemoryStore: Will not store rdd_12_41
21/01/31 12:42:11 WARN MemoryStore: Not enough space to cache rdd_12_41 in memory! (computed 35.7 MiB so far)
21/01/31 12:42:11 INFO MemoryStore: Memory use = 349.4 MiB (blocks) + 6.3 MiB (scratch space shared across 2 tasks(s)) = 355.8 MiB. Storage limit = 366.3 MiB.
21/01/31 12:42:11 WARN BlockManager: Persisting block rdd_12_41 to disk instead.
21/01/31 12:42:14 INFO MemoryStore: Will not store rdd_12_49
21/01/31 12:42:14 WARN MemoryStore: Not enough space to cache rdd_12_49 in memory! (computed 35.8 MiB so far)
21/01/31 12:42:14 INFO MemoryStore: Memory use = 349.4 MiB (blocks) + 3.1 MiB (scratch space shared across 1 tasks(s)) = 352.6 MiB. Storage limit = 366.3 MiB.
21/01/31 12:42:14 WARN BlockManager: Persisting block rdd_12_49 to disk instead.
21/01/31 12:42:35 INFO MemoryStore: Will not store rdd_12_41
21/01/31 12:42:35 WARN MemoryStore: Not enough space to cache rdd_12_41 in memory! (computed 35.7 MiB so far)
21/01/31 12:42:35 INFO MemoryStore: Memory use = 349.4 MiB (blocks) + 3.2 MiB (scratch space shared across 1 tasks(s)) = 352.6 MiB. Storage limit = 366.3 MiB.
21/01/31 12:42:35 INFO Executor: Finished task 41.0 in stage 1.0 (TID 42). 2108 bytes result sent to driver
21/01/31 12:42:35 INFO CoarseGrainedExecutorBackend: Got assigned task 61
21/01/31 12:42:35 INFO Executor: Running task 60.0 in stage 1.0 (TID 61)
21/01/31 12:42:35 INFO FileScanRDD: Reading File path: file:///Users/kinsho/Desktop/impressionLog.csv, range: 8053063680-8187281408, partition values: [empty row]
21/01/31 12:42:38 INFO MemoryStore: Will not store rdd_12_49
21/01/31 12:42:38 WARN MemoryStore: Not enough space to cache rdd_12_49 in memory! (computed 35.8 MiB so far)
21/01/31 12:42:38 INFO MemoryStore: Memory use = 349.4 MiB (blocks) + 6.2 MiB (scratch space shared across 2 tasks(s)) = 355.7 MiB. Storage limit = 366.3 MiB.
21/01/31 12:42:38 INFO Executor: Finished task 49.0 in stage 1.0 (TID 50). 2108 bytes result sent to driver
21/01/31 12:42:38 INFO CoarseGrainedExecutorBackend: Got assigned task 68
21/01/31 12:42:38 INFO Executor: Running task 67.0 in stage 1.0 (TID 68)
21/01/31 12:42:38 INFO FileScanRDD: Reading File path: file:///Users/kinsho/Desktop/impressionLog.csv, range: 8992587776-9126805504, partition values: [empty row]
21/01/31 12:42:43 INFO MemoryStore: Will not store rdd_12_60
21/01/31 12:42:43 WARN MemoryStore: Not enough space to cache rdd_12_60 in memory! (computed 35.5 MiB so far)
21/01/31 12:42:43 INFO MemoryStore: Memory use = 349.4 MiB (blocks) + 6.4 MiB (scratch space shared across 2 tasks(s)) = 355.8 MiB. Storage limit = 366.3 MiB.
21/01/31 12:42:43 WARN BlockManager: Persisting block rdd_12_60 to disk instead.
21/01/31 12:42:45 INFO MemoryStore: Will not store rdd_12_67
21/01/31 12:42:45 WARN MemoryStore: Not enough space to cache rdd_12_67 in memory! (computed 35.1 MiB so far)
21/01/31 12:42:45 INFO MemoryStore: Memory use = 349.4 MiB (blocks) + 3.2 MiB (scratch space shared across 1 tasks(s)) = 352.7 MiB. Storage limit = 366.3 MiB.
21/01/31 12:42:45 WARN BlockManager: Persisting block rdd_12_67 to disk instead.
21/01/31 12:43:07 INFO MemoryStore: Will not store rdd_12_60
21/01/31 12:43:07 WARN MemoryStore: Not enough space to cache rdd_12_60 in memory! (computed 35.5 MiB so far)
21/01/31 12:43:07 INFO MemoryStore: Memory use = 349.4 MiB (blocks) + 3.1 MiB (scratch space shared across 1 tasks(s)) = 352.5 MiB. Storage limit = 366.3 MiB.
21/01/31 12:43:07 INFO Executor: Finished task 60.0 in stage 1.0 (TID 61). 2108 bytes result sent to driver
21/01/31 12:43:07 INFO CoarseGrainedExecutorBackend: Got assigned task 82
21/01/31 12:43:07 INFO Executor: Running task 81.0 in stage 1.0 (TID 82)
21/01/31 12:43:07 INFO FileScanRDD: Reading File path: file:///Users/kinsho/Desktop/impressionLog.csv, range: 10871635968-11005853696, partition values: [empty row]
21/01/31 12:43:10 INFO MemoryStore: Will not store rdd_12_67
21/01/31 12:43:10 WARN MemoryStore: Not enough space to cache rdd_12_67 in memory! (computed 35.1 MiB so far)
21/01/31 12:43:10 INFO MemoryStore: Memory use = 349.4 MiB (blocks) + 6.2 MiB (scratch space shared across 2 tasks(s)) = 355.6 MiB. Storage limit = 366.3 MiB.
21/01/31 12:43:10 INFO Executor: Finished task 67.0 in stage 1.0 (TID 68). 2108 bytes result sent to driver
21/01/31 12:43:10 INFO CoarseGrainedExecutorBackend: Got assigned task 87
21/01/31 12:43:10 INFO Executor: Running task 86.0 in stage 1.0 (TID 87)
21/01/31 12:43:10 INFO FileScanRDD: Reading File path: file:///Users/kinsho/Desktop/impressionLog.csv, range: 11542724608-11676942336, partition values: [empty row]
21/01/31 12:43:14 INFO MemoryStore: Will not store rdd_12_81
21/01/31 12:43:14 WARN MemoryStore: Not enough space to cache rdd_12_81 in memory! (computed 34.9 MiB so far)
21/01/31 12:43:14 INFO MemoryStore: Memory use = 349.4 MiB (blocks) + 6.1 MiB (scratch space shared across 2 tasks(s)) = 355.6 MiB. Storage limit = 366.3 MiB.
21/01/31 12:43:14 WARN BlockManager: Persisting block rdd_12_81 to disk instead.
21/01/31 12:43:17 INFO MemoryStore: Will not store rdd_12_86
21/01/31 12:43:17 WARN MemoryStore: Not enough space to cache rdd_12_86 in memory! (computed 36.5 MiB so far)
21/01/31 12:43:17 INFO MemoryStore: Memory use = 349.4 MiB (blocks) + 3.2 MiB (scratch space shared across 1 tasks(s)) = 352.7 MiB. Storage limit = 366.3 MiB.
21/01/31 12:43:17 WARN BlockManager: Persisting block rdd_12_86 to disk instead.
21/01/31 12:43:39 INFO MemoryStore: Will not store rdd_12_81
21/01/31 12:43:39 WARN MemoryStore: Not enough space to cache rdd_12_81 in memory! (computed 34.9 MiB so far)
21/01/31 12:43:39 INFO MemoryStore: Memory use = 349.4 MiB (blocks) + 2.9 MiB (scratch space shared across 1 tasks(s)) = 352.3 MiB. Storage limit = 366.3 MiB.
21/01/31 12:43:39 INFO Executor: Finished task 81.0 in stage 1.0 (TID 82). 2108 bytes result sent to driver
21/01/31 12:43:39 INFO CoarseGrainedExecutorBackend: Got assigned task 102
21/01/31 12:43:39 INFO Executor: Running task 101.0 in stage 1.0 (TID 102)
21/01/31 12:43:39 INFO FileScanRDD: Reading File path: file:///Users/kinsho/Desktop/impressionLog.csv, range: 13555990528-13690208256, partition values: [empty row]
21/01/31 12:43:41 INFO MemoryStore: Will not store rdd_12_86
21/01/31 12:43:41 WARN MemoryStore: Not enough space to cache rdd_12_86 in memory! (computed 36.5 MiB so far)
21/01/31 12:43:41 INFO MemoryStore: Memory use = 349.4 MiB (blocks) + 6.0 MiB (scratch space shared across 2 tasks(s)) = 355.5 MiB. Storage limit = 366.3 MiB.
21/01/31 12:43:41 INFO Executor: Finished task 86.0 in stage 1.0 (TID 87). 2108 bytes result sent to driver
21/01/31 12:43:41 INFO CoarseGrainedExecutorBackend: Got assigned task 105
21/01/31 12:43:41 INFO Executor: Running task 104.0 in stage 1.0 (TID 105)
21/01/31 12:43:41 INFO FileScanRDD: Reading File path: file:///Users/kinsho/Desktop/impressionLog.csv, range: 13958643712-14092861440, partition values: [empty row]
21/01/31 12:43:46 INFO MemoryStore: Will not store rdd_12_101
21/01/31 12:43:46 WARN MemoryStore: Not enough space to cache rdd_12_101 in memory! (computed 33.1 MiB so far)
21/01/31 12:43:46 INFO MemoryStore: Memory use = 349.4 MiB (blocks) + 5.9 MiB (scratch space shared across 2 tasks(s)) = 355.3 MiB. Storage limit = 366.3 MiB.
21/01/31 12:43:46 WARN BlockManager: Persisting block rdd_12_101 to disk instead.
21/01/31 12:43:48 INFO MemoryStore: Will not store rdd_12_104
21/01/31 12:43:48 WARN MemoryStore: Not enough space to cache rdd_12_104 in memory! (computed 34.5 MiB so far)
21/01/31 12:43:48 INFO MemoryStore: Memory use = 349.4 MiB (blocks) + 3.1 MiB (scratch space shared across 1 tasks(s)) = 352.5 MiB. Storage limit = 366.3 MiB.
21/01/31 12:43:48 WARN BlockManager: Persisting block rdd_12_104 to disk instead.
21/01/31 12:44:10 INFO MemoryStore: Will not store rdd_12_101
21/01/31 12:44:10 WARN MemoryStore: Not enough space to cache rdd_12_101 in memory! (computed 33.1 MiB so far)
21/01/31 12:44:10 INFO MemoryStore: Memory use = 349.4 MiB (blocks) + 2.8 MiB (scratch space shared across 1 tasks(s)) = 352.3 MiB. Storage limit = 366.3 MiB.
21/01/31 12:44:11 INFO Executor: Finished task 101.0 in stage 1.0 (TID 102). 2108 bytes result sent to driver
21/01/31 12:44:11 INFO CoarseGrainedExecutorBackend: Got assigned task 123
21/01/31 12:44:11 INFO Executor: Running task 122.0 in stage 1.0 (TID 123)
21/01/31 12:44:11 INFO FileScanRDD: Reading File path: file:///Users/kinsho/Desktop/impressionLog.csv, range: 16374562816-16508780544, partition values: [empty row]
21/01/31 12:44:11 INFO MemoryStore: Will not store rdd_12_104
21/01/31 12:44:11 WARN MemoryStore: Not enough space to cache rdd_12_104 in memory! (computed 34.5 MiB so far)
21/01/31 12:44:11 INFO MemoryStore: Memory use = 349.4 MiB (blocks) + 6.1 MiB (scratch space shared across 2 tasks(s)) = 355.5 MiB. Storage limit = 366.3 MiB.
21/01/31 12:44:12 INFO Executor: Finished task 104.0 in stage 1.0 (TID 105). 2108 bytes result sent to driver
21/01/31 12:44:12 INFO CoarseGrainedExecutorBackend: Got assigned task 124
21/01/31 12:44:12 INFO Executor: Running task 123.0 in stage 1.0 (TID 124)
21/01/31 12:44:12 INFO FileScanRDD: Reading File path: file:///Users/kinsho/Desktop/impressionLog.csv, range: 16508780544-16642998272, partition values: [empty row]
21/01/31 12:44:18 INFO MemoryStore: Will not store rdd_12_122
21/01/31 12:44:18 WARN MemoryStore: Not enough space to cache rdd_12_122 in memory! (computed 34.6 MiB so far)
21/01/31 12:44:18 INFO MemoryStore: Memory use = 349.4 MiB (blocks) + 6.1 MiB (scratch space shared across 2 tasks(s)) = 355.5 MiB. Storage limit = 366.3 MiB.
21/01/31 12:44:18 WARN BlockManager: Persisting block rdd_12_122 to disk instead.
21/01/31 12:44:19 INFO MemoryStore: Will not store rdd_12_123
21/01/31 12:44:19 WARN MemoryStore: Not enough space to cache rdd_12_123 in memory! (computed 35.1 MiB so far)
21/01/31 12:44:19 INFO MemoryStore: Memory use = 349.4 MiB (blocks) + 3.1 MiB (scratch space shared across 1 tasks(s)) = 352.5 MiB. Storage limit = 366.3 MiB.
21/01/31 12:44:19 WARN BlockManager: Persisting block rdd_12_123 to disk instead.
21/01/31 12:44:41 INFO MemoryStore: Will not store rdd_12_122
21/01/31 12:44:41 WARN MemoryStore: Not enough space to cache rdd_12_122 in memory! (computed 34.6 MiB so far)
21/01/31 12:44:41 INFO MemoryStore: Memory use = 349.4 MiB (blocks) + 3.0 MiB (scratch space shared across 1 tasks(s)) = 352.4 MiB. Storage limit = 366.3 MiB.
21/01/31 12:44:41 INFO Executor: Finished task 122.0 in stage 1.0 (TID 123). 2108 bytes result sent to driver
21/01/31 12:44:41 INFO CoarseGrainedExecutorBackend: Got assigned task 143
21/01/31 12:44:41 INFO Executor: Running task 142.0 in stage 1.0 (TID 143)
21/01/31 12:44:41 INFO FileScanRDD: Reading File path: file:///Users/kinsho/Desktop/impressionLog.csv, range: 19058917376-19193135104, partition values: [empty row]
21/01/31 12:44:42 INFO MemoryStore: Will not store rdd_12_123
21/01/31 12:44:42 WARN MemoryStore: Not enough space to cache rdd_12_123 in memory! (computed 35.1 MiB so far)
21/01/31 12:44:42 INFO MemoryStore: Memory use = 349.4 MiB (blocks) + 6.2 MiB (scratch space shared across 2 tasks(s)) = 355.6 MiB. Storage limit = 366.3 MiB.
21/01/31 12:44:42 INFO Executor: Finished task 123.0 in stage 1.0 (TID 124). 2108 bytes result sent to driver
21/01/31 12:44:42 INFO CoarseGrainedExecutorBackend: Got assigned task 144
21/01/31 12:44:42 INFO Executor: Running task 143.0 in stage 1.0 (TID 144)
21/01/31 12:44:42 INFO FileScanRDD: Reading File path: file:///Users/kinsho/Desktop/impressionLog.csv, range: 19193135104-19327352832, partition values: [empty row]
21/01/31 12:44:48 INFO MemoryStore: Will not store rdd_12_142
21/01/31 12:44:48 WARN MemoryStore: Not enough space to cache rdd_12_142 in memory! (computed 35.2 MiB so far)
21/01/31 12:44:48 INFO MemoryStore: Memory use = 349.4 MiB (blocks) + 6.2 MiB (scratch space shared across 2 tasks(s)) = 355.6 MiB. Storage limit = 366.3 MiB.
21/01/31 12:44:48 WARN BlockManager: Persisting block rdd_12_142 to disk instead.
21/01/31 12:44:49 INFO MemoryStore: Will not store rdd_12_143
21/01/31 12:44:49 WARN MemoryStore: Not enough space to cache rdd_12_143 in memory! (computed 36.6 MiB so far)
21/01/31 12:44:49 INFO MemoryStore: Memory use = 349.4 MiB (blocks) + 3.1 MiB (scratch space shared across 1 tasks(s)) = 352.5 MiB. Storage limit = 366.3 MiB.
21/01/31 12:44:49 WARN BlockManager: Persisting block rdd_12_143 to disk instead.
21/01/31 12:45:12 INFO MemoryStore: Will not store rdd_12_142
21/01/31 12:45:12 WARN MemoryStore: Not enough space to cache rdd_12_142 in memory! (computed 35.2 MiB so far)
21/01/31 12:45:12 INFO MemoryStore: Memory use = 349.4 MiB (blocks) + 3.1 MiB (scratch space shared across 1 tasks(s)) = 352.5 MiB. Storage limit = 366.3 MiB.
21/01/31 12:45:12 INFO MemoryStore: Will not store rdd_12_143
21/01/31 12:45:12 WARN MemoryStore: Not enough space to cache rdd_12_143 in memory! (computed 36.6 MiB so far)
21/01/31 12:45:12 INFO MemoryStore: Memory use = 349.4 MiB (blocks) + 3.1 MiB (scratch space shared across 1 tasks(s)) = 352.5 MiB. Storage limit = 366.3 MiB.
21/01/31 12:45:12 INFO Executor: Finished task 142.0 in stage 1.0 (TID 143). 2108 bytes result sent to driver
21/01/31 12:45:12 INFO CoarseGrainedExecutorBackend: Got assigned task 163
21/01/31 12:45:12 INFO Executor: Running task 162.0 in stage 1.0 (TID 163)
21/01/31 12:45:12 INFO FileScanRDD: Reading File path: file:///Users/kinsho/Desktop/impressionLog.csv, range: 21743271936-21877489664, partition values: [empty row]
21/01/31 12:45:13 INFO Executor: Finished task 143.0 in stage 1.0 (TID 144). 2108 bytes result sent to driver
21/01/31 12:45:13 INFO CoarseGrainedExecutorBackend: Got assigned task 164
21/01/31 12:45:13 INFO Executor: Running task 163.0 in stage 1.0 (TID 164)
21/01/31 12:45:13 INFO FileScanRDD: Reading File path: file:///Users/kinsho/Desktop/impressionLog.csv, range: 21877489664-22011707392, partition values: [empty row]
21/01/31 12:45:19 INFO MemoryStore: Will not store rdd_12_162
21/01/31 12:45:19 WARN MemoryStore: Not enough space to cache rdd_12_162 in memory! (computed 37.4 MiB so far)
21/01/31 12:45:20 INFO MemoryStore: Memory use = 349.4 MiB (blocks) + 6.7 MiB (scratch space shared across 2 tasks(s)) = 356.1 MiB. Storage limit = 366.3 MiB.
21/01/31 12:45:20 WARN BlockManager: Persisting block rdd_12_162 to disk instead.
21/01/31 12:45:20 INFO MemoryStore: Will not store rdd_12_163
21/01/31 12:45:20 WARN MemoryStore: Not enough space to cache rdd_12_163 in memory! (computed 37.4 MiB so far)
21/01/31 12:45:20 INFO MemoryStore: Memory use = 349.4 MiB (blocks) + 6.7 MiB (scratch space shared across 2 tasks(s)) = 356.1 MiB. Storage limit = 366.3 MiB.
21/01/31 12:45:20 WARN BlockManager: Persisting block rdd_12_163 to disk instead.
21/01/31 12:45:36 INFO MemoryStore: Will not store rdd_12_162
21/01/31 12:45:36 WARN MemoryStore: Not enough space to cache rdd_12_162 in memory! (computed 37.4 MiB so far)
21/01/31 12:45:36 INFO MemoryStore: Memory use = 349.4 MiB (blocks) + 3.2 MiB (scratch space shared across 1 tasks(s)) = 352.7 MiB. Storage limit = 366.3 MiB.
21/01/31 12:45:36 INFO MemoryStore: Will not store rdd_12_163
21/01/31 12:45:36 WARN MemoryStore: Not enough space to cache rdd_12_163 in memory! (computed 37.4 MiB so far)
21/01/31 12:45:36 INFO MemoryStore: Memory use = 349.4 MiB (blocks) + 3.4 MiB (scratch space shared across 1 tasks(s)) = 352.9 MiB. Storage limit = 366.3 MiB.
21/01/31 12:45:36 INFO Executor: Finished task 162.0 in stage 1.0 (TID 163). 2108 bytes result sent to driver
21/01/31 12:45:36 INFO Executor: Finished task 163.0 in stage 1.0 (TID 164). 2108 bytes result sent to driver
21/01/31 12:45:41 INFO CoarseGrainedExecutorBackend: Got assigned task 182
21/01/31 12:45:41 INFO CoarseGrainedExecutorBackend: Got assigned task 192
21/01/31 12:45:41 INFO Executor: Running task 1.0 in stage 3.0 (TID 182)
21/01/31 12:45:41 INFO Executor: Running task 11.0 in stage 3.0 (TID 192)
21/01/31 12:45:41 INFO MapOutputTrackerWorker: Updating epoch to 1 and clearing cache
21/01/31 12:45:41 INFO TorrentBroadcast: Started reading broadcast variable 6 with 1 pieces (estimated total size 4.0 MiB)
21/01/31 12:45:41 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 69.4 KiB, free 16.8 MiB)
21/01/31 12:45:41 INFO TorrentBroadcast: Reading broadcast variable 6 took 21 ms
21/01/31 12:45:41 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 194.5 KiB, free 16.6 MiB)
21/01/31 12:45:41 INFO BlockManager: Found block rdd_12_1 locally
21/01/31 12:45:41 INFO MemoryStore: Will not store rdd_12_11
21/01/31 12:45:41 WARN MemoryStore: Not enough space to cache rdd_12_11 in memory! (computed 35.6 MiB so far)
21/01/31 12:45:41 INFO MemoryStore: Memory use = 349.6 MiB (blocks) + 3.1 MiB (scratch space shared across 1 tasks(s)) = 352.7 MiB. Storage limit = 366.3 MiB.
21/01/31 12:45:41 INFO BlockManager: Found block rdd_12_11 locally
21/01/31 12:45:41 INFO CodeGenerator: Code generated in 281.227032 ms
21/01/31 12:45:41 INFO CodeGenerator: Code generated in 183.14445 ms
21/01/31 12:45:41 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/01/31 12:45:41 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/01/31 12:45:41 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/01/31 12:45:41 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/01/31 12:45:41 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/01/31 12:45:41 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/01/31 12:45:41 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/01/31 12:45:41 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/01/31 12:45:41 INFO CodecConfig: Compression: SNAPPY
21/01/31 12:45:41 INFO CodecConfig: Compression: SNAPPY
21/01/31 12:45:41 INFO CodecConfig: Compression: SNAPPY
21/01/31 12:45:41 INFO CodecConfig: Compression: SNAPPY
21/01/31 12:45:42 INFO ParquetOutputFormat: Parquet block size to 134217728
21/01/31 12:45:42 INFO ParquetOutputFormat: Parquet page size to 1048576
21/01/31 12:45:42 INFO ParquetOutputFormat: Parquet dictionary page size to 1048576
21/01/31 12:45:42 INFO ParquetOutputFormat: Dictionary is on
21/01/31 12:45:42 INFO ParquetOutputFormat: Parquet block size to 134217728
21/01/31 12:45:42 INFO ParquetOutputFormat: Parquet page size to 1048576
21/01/31 12:45:42 INFO ParquetOutputFormat: Parquet dictionary page size to 1048576
21/01/31 12:45:42 INFO ParquetOutputFormat: Dictionary is on
21/01/31 12:45:42 INFO ParquetOutputFormat: Validation is off
21/01/31 12:45:42 INFO ParquetOutputFormat: Writer version is: PARQUET_1_0
21/01/31 12:45:42 INFO ParquetOutputFormat: Maximum row group padding size is 8388608 bytes
21/01/31 12:45:42 INFO ParquetOutputFormat: Page size checking is: estimated
21/01/31 12:45:42 INFO ParquetOutputFormat: Min row count for page size check is: 100
21/01/31 12:45:42 INFO ParquetOutputFormat: Max row count for page size check is: 10000
21/01/31 12:45:42 INFO ParquetOutputFormat: Validation is off
21/01/31 12:45:42 INFO ParquetOutputFormat: Writer version is: PARQUET_1_0
21/01/31 12:45:42 INFO ParquetOutputFormat: Maximum row group padding size is 8388608 bytes
21/01/31 12:45:42 INFO ParquetOutputFormat: Page size checking is: estimated
21/01/31 12:45:42 INFO ParquetOutputFormat: Min row count for page size check is: 100
21/01/31 12:45:42 INFO ParquetOutputFormat: Max row count for page size check is: 10000
21/01/31 12:45:42 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "distributionid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "advertiserid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "distributionhourjst",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "distributiondatetime",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "requestid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "uid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "uavalue",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "uacategory",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "documentid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "documenturl",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "sitecode",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "documenttitle",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "campaignid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "campaigntype",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "publisherid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "publisherchannelid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "maxcpc",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "bidcpc",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "contractcpc",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "finalscore",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "originalscore",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "distributionorder",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "israndom",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "jobchanneltype",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "buckettype",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "predictctr",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "dt",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "isGsp",
    "type" : "boolean",
    "nullable" : false,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary distributionid (UTF8);
  optional binary advertiserid (UTF8);
  optional binary distributionhourjst (UTF8);
  optional binary distributiondatetime (UTF8);
  optional binary requestid (UTF8);
  optional binary uid (UTF8);
  optional binary uavalue (UTF8);
  optional binary uacategory (UTF8);
  optional binary documentid (UTF8);
  optional binary documenturl (UTF8);
  optional binary sitecode (UTF8);
  optional binary documenttitle (UTF8);
  optional binary campaignid (UTF8);
  optional binary campaigntype (UTF8);
  optional binary publisherid (UTF8);
  optional binary publisherchannelid (UTF8);
  optional binary maxcpc (UTF8);
  optional binary bidcpc (UTF8);
  optional binary contractcpc (UTF8);
  optional binary finalscore (UTF8);
  optional binary originalscore (UTF8);
  optional binary distributionorder (UTF8);
  optional binary israndom (UTF8);
  optional binary jobchanneltype (UTF8);
  optional binary buckettype (UTF8);
  optional binary predictctr (UTF8);
  optional binary dt (UTF8);
  required boolean isGsp;
}

       
21/01/31 12:45:42 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "distributionid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "advertiserid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "distributionhourjst",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "distributiondatetime",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "requestid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "uid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "uavalue",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "uacategory",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "documentid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "documenturl",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "sitecode",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "documenttitle",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "campaignid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "campaigntype",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "publisherid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "publisherchannelid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "maxcpc",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "bidcpc",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "contractcpc",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "finalscore",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "originalscore",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "distributionorder",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "israndom",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "jobchanneltype",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "buckettype",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "predictctr",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "dt",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "isGsp",
    "type" : "boolean",
    "nullable" : false,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary distributionid (UTF8);
  optional binary advertiserid (UTF8);
  optional binary distributionhourjst (UTF8);
  optional binary distributiondatetime (UTF8);
  optional binary requestid (UTF8);
  optional binary uid (UTF8);
  optional binary uavalue (UTF8);
  optional binary uacategory (UTF8);
  optional binary documentid (UTF8);
  optional binary documenturl (UTF8);
  optional binary sitecode (UTF8);
  optional binary documenttitle (UTF8);
  optional binary campaignid (UTF8);
  optional binary campaigntype (UTF8);
  optional binary publisherid (UTF8);
  optional binary publisherchannelid (UTF8);
  optional binary maxcpc (UTF8);
  optional binary bidcpc (UTF8);
  optional binary contractcpc (UTF8);
  optional binary finalscore (UTF8);
  optional binary originalscore (UTF8);
  optional binary distributionorder (UTF8);
  optional binary israndom (UTF8);
  optional binary jobchanneltype (UTF8);
  optional binary buckettype (UTF8);
  optional binary predictctr (UTF8);
  optional binary dt (UTF8);
  required boolean isGsp;
}

       
21/01/31 12:45:42 INFO CodecPool: Got brand-new compressor [.snappy]
21/01/31 12:45:42 INFO CodecPool: Got brand-new compressor [.snappy]
21/01/31 12:45:52 INFO InternalParquetRecordWriter: Flushing mem columnStore to file. allocated memory: 37907071
21/01/31 12:45:53 INFO FileOutputCommitter: Saved output of task 'attempt_20210131124540_0003_m_000001_182' to file:/Users/kinsho/Desktop/log/_temporary/0/task_20210131124540_0003_m_000001
21/01/31 12:45:53 INFO SparkHadoopMapRedUtil: attempt_20210131124540_0003_m_000001_182: Committed
21/01/31 12:45:53 INFO Executor: Finished task 1.0 in stage 3.0 (TID 182). 2504 bytes result sent to driver
21/01/31 12:45:53 INFO CoarseGrainedExecutorBackend: Got assigned task 199
21/01/31 12:45:53 INFO Executor: Running task 21.0 in stage 3.0 (TID 199)
21/01/31 12:45:53 INFO BlockManager: Found block rdd_12_21 locally
21/01/31 12:45:53 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/01/31 12:45:53 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/01/31 12:45:53 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/01/31 12:45:53 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/01/31 12:45:53 INFO CodecConfig: Compression: SNAPPY
21/01/31 12:45:53 INFO CodecConfig: Compression: SNAPPY
21/01/31 12:45:53 INFO ParquetOutputFormat: Parquet block size to 134217728
21/01/31 12:45:53 INFO ParquetOutputFormat: Parquet page size to 1048576
21/01/31 12:45:53 INFO ParquetOutputFormat: Parquet dictionary page size to 1048576
21/01/31 12:45:53 INFO ParquetOutputFormat: Dictionary is on
21/01/31 12:45:53 INFO ParquetOutputFormat: Validation is off
21/01/31 12:45:53 INFO ParquetOutputFormat: Writer version is: PARQUET_1_0
21/01/31 12:45:53 INFO ParquetOutputFormat: Maximum row group padding size is 8388608 bytes
21/01/31 12:45:53 INFO ParquetOutputFormat: Page size checking is: estimated
21/01/31 12:45:53 INFO ParquetOutputFormat: Min row count for page size check is: 100
21/01/31 12:45:53 INFO ParquetOutputFormat: Max row count for page size check is: 10000
21/01/31 12:45:53 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "distributionid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "advertiserid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "distributionhourjst",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "distributiondatetime",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "requestid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "uid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "uavalue",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "uacategory",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "documentid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "documenturl",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "sitecode",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "documenttitle",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "campaignid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "campaigntype",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "publisherid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "publisherchannelid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "maxcpc",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "bidcpc",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "contractcpc",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "finalscore",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "originalscore",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "distributionorder",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "israndom",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "jobchanneltype",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "buckettype",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "predictctr",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "dt",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "isGsp",
    "type" : "boolean",
    "nullable" : false,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary distributionid (UTF8);
  optional binary advertiserid (UTF8);
  optional binary distributionhourjst (UTF8);
  optional binary distributiondatetime (UTF8);
  optional binary requestid (UTF8);
  optional binary uid (UTF8);
  optional binary uavalue (UTF8);
  optional binary uacategory (UTF8);
  optional binary documentid (UTF8);
  optional binary documenturl (UTF8);
  optional binary sitecode (UTF8);
  optional binary documenttitle (UTF8);
  optional binary campaignid (UTF8);
  optional binary campaigntype (UTF8);
  optional binary publisherid (UTF8);
  optional binary publisherchannelid (UTF8);
  optional binary maxcpc (UTF8);
  optional binary bidcpc (UTF8);
  optional binary contractcpc (UTF8);
  optional binary finalscore (UTF8);
  optional binary originalscore (UTF8);
  optional binary distributionorder (UTF8);
  optional binary israndom (UTF8);
  optional binary jobchanneltype (UTF8);
  optional binary buckettype (UTF8);
  optional binary predictctr (UTF8);
  optional binary dt (UTF8);
  required boolean isGsp;
}

       
21/01/31 12:45:54 INFO InternalParquetRecordWriter: Flushing mem columnStore to file. allocated memory: 40739463
21/01/31 12:45:55 INFO FileOutputCommitter: Saved output of task 'attempt_20210131124540_0003_m_000011_192' to file:/Users/kinsho/Desktop/log/_temporary/0/task_20210131124540_0003_m_000011
21/01/31 12:45:55 INFO SparkHadoopMapRedUtil: attempt_20210131124540_0003_m_000011_192: Committed
21/01/31 12:45:55 INFO Executor: Finished task 11.0 in stage 3.0 (TID 192). 2461 bytes result sent to driver
21/01/31 12:45:55 INFO CoarseGrainedExecutorBackend: Got assigned task 207
21/01/31 12:45:55 INFO Executor: Running task 38.0 in stage 3.0 (TID 207)
21/01/31 12:45:55 INFO MemoryStore: Will not store rdd_12_38
21/01/31 12:45:55 WARN MemoryStore: Not enough space to cache rdd_12_38 in memory! (computed 35.5 MiB so far)
21/01/31 12:45:55 INFO MemoryStore: Memory use = 349.6 MiB (blocks) + 3.2 MiB (scratch space shared across 1 tasks(s)) = 352.8 MiB. Storage limit = 366.3 MiB.
21/01/31 12:45:55 INFO BlockManager: Found block rdd_12_38 locally
21/01/31 12:45:55 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/01/31 12:45:55 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/01/31 12:45:55 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/01/31 12:45:55 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/01/31 12:45:55 INFO CodecConfig: Compression: SNAPPY
21/01/31 12:45:55 INFO CodecConfig: Compression: SNAPPY
21/01/31 12:45:55 INFO ParquetOutputFormat: Parquet block size to 134217728
21/01/31 12:45:55 INFO ParquetOutputFormat: Parquet page size to 1048576
21/01/31 12:45:55 INFO ParquetOutputFormat: Parquet dictionary page size to 1048576
21/01/31 12:45:55 INFO ParquetOutputFormat: Dictionary is on
21/01/31 12:45:55 INFO ParquetOutputFormat: Validation is off
21/01/31 12:45:55 INFO ParquetOutputFormat: Writer version is: PARQUET_1_0
21/01/31 12:45:55 INFO ParquetOutputFormat: Maximum row group padding size is 8388608 bytes
21/01/31 12:45:55 INFO ParquetOutputFormat: Page size checking is: estimated
21/01/31 12:45:55 INFO ParquetOutputFormat: Min row count for page size check is: 100
21/01/31 12:45:55 INFO ParquetOutputFormat: Max row count for page size check is: 10000
21/01/31 12:45:55 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "distributionid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "advertiserid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "distributionhourjst",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "distributiondatetime",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "requestid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "uid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "uavalue",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "uacategory",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "documentid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "documenturl",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "sitecode",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "documenttitle",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "campaignid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "campaigntype",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "publisherid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "publisherchannelid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "maxcpc",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "bidcpc",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "contractcpc",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "finalscore",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "originalscore",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "distributionorder",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "israndom",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "jobchanneltype",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "buckettype",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "predictctr",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "dt",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "isGsp",
    "type" : "boolean",
    "nullable" : false,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary distributionid (UTF8);
  optional binary advertiserid (UTF8);
  optional binary distributionhourjst (UTF8);
  optional binary distributiondatetime (UTF8);
  optional binary requestid (UTF8);
  optional binary uid (UTF8);
  optional binary uavalue (UTF8);
  optional binary uacategory (UTF8);
  optional binary documentid (UTF8);
  optional binary documenturl (UTF8);
  optional binary sitecode (UTF8);
  optional binary documenttitle (UTF8);
  optional binary campaignid (UTF8);
  optional binary campaigntype (UTF8);
  optional binary publisherid (UTF8);
  optional binary publisherchannelid (UTF8);
  optional binary maxcpc (UTF8);
  optional binary bidcpc (UTF8);
  optional binary contractcpc (UTF8);
  optional binary finalscore (UTF8);
  optional binary originalscore (UTF8);
  optional binary distributionorder (UTF8);
  optional binary israndom (UTF8);
  optional binary jobchanneltype (UTF8);
  optional binary buckettype (UTF8);
  optional binary predictctr (UTF8);
  optional binary dt (UTF8);
  required boolean isGsp;
}

       
21/01/31 12:46:05 INFO InternalParquetRecordWriter: Flushing mem columnStore to file. allocated memory: 42152638
21/01/31 12:46:06 INFO FileOutputCommitter: Saved output of task 'attempt_20210131124540_0003_m_000021_199' to file:/Users/kinsho/Desktop/log/_temporary/0/task_20210131124540_0003_m_000021
21/01/31 12:46:06 INFO SparkHadoopMapRedUtil: attempt_20210131124540_0003_m_000021_199: Committed
21/01/31 12:46:06 INFO Executor: Finished task 21.0 in stage 3.0 (TID 199). 2461 bytes result sent to driver
21/01/31 12:46:06 INFO CoarseGrainedExecutorBackend: Got assigned task 223
21/01/31 12:46:06 INFO Executor: Running task 41.0 in stage 3.0 (TID 223)
21/01/31 12:46:06 INFO InternalParquetRecordWriter: Flushing mem columnStore to file. allocated memory: 38621455
21/01/31 12:46:06 INFO MemoryStore: Will not store rdd_12_41
21/01/31 12:46:06 WARN MemoryStore: Not enough space to cache rdd_12_41 in memory! (computed 35.7 MiB so far)
21/01/31 12:46:06 INFO MemoryStore: Memory use = 349.6 MiB (blocks) + 3.2 MiB (scratch space shared across 1 tasks(s)) = 352.8 MiB. Storage limit = 366.3 MiB.
21/01/31 12:46:06 INFO BlockManager: Found block rdd_12_41 locally
21/01/31 12:46:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/01/31 12:46:06 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/01/31 12:46:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/01/31 12:46:06 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/01/31 12:46:06 INFO CodecConfig: Compression: SNAPPY
21/01/31 12:46:06 INFO CodecConfig: Compression: SNAPPY
21/01/31 12:46:06 INFO ParquetOutputFormat: Parquet block size to 134217728
21/01/31 12:46:06 INFO ParquetOutputFormat: Parquet page size to 1048576
21/01/31 12:46:06 INFO ParquetOutputFormat: Parquet dictionary page size to 1048576
21/01/31 12:46:06 INFO ParquetOutputFormat: Dictionary is on
21/01/31 12:46:06 INFO ParquetOutputFormat: Validation is off
21/01/31 12:46:06 INFO ParquetOutputFormat: Writer version is: PARQUET_1_0
21/01/31 12:46:06 INFO ParquetOutputFormat: Maximum row group padding size is 8388608 bytes
21/01/31 12:46:06 INFO ParquetOutputFormat: Page size checking is: estimated
21/01/31 12:46:06 INFO ParquetOutputFormat: Min row count for page size check is: 100
21/01/31 12:46:06 INFO ParquetOutputFormat: Max row count for page size check is: 10000
21/01/31 12:46:06 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "distributionid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "advertiserid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "distributionhourjst",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "distributiondatetime",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "requestid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "uid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "uavalue",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "uacategory",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "documentid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "documenturl",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "sitecode",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "documenttitle",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "campaignid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "campaigntype",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "publisherid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "publisherchannelid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "maxcpc",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "bidcpc",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "contractcpc",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "finalscore",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "originalscore",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "distributionorder",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "israndom",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "jobchanneltype",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "buckettype",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "predictctr",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "dt",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "isGsp",
    "type" : "boolean",
    "nullable" : false,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary distributionid (UTF8);
  optional binary advertiserid (UTF8);
  optional binary distributionhourjst (UTF8);
  optional binary distributiondatetime (UTF8);
  optional binary requestid (UTF8);
  optional binary uid (UTF8);
  optional binary uavalue (UTF8);
  optional binary uacategory (UTF8);
  optional binary documentid (UTF8);
  optional binary documenturl (UTF8);
  optional binary sitecode (UTF8);
  optional binary documenttitle (UTF8);
  optional binary campaignid (UTF8);
  optional binary campaigntype (UTF8);
  optional binary publisherid (UTF8);
  optional binary publisherchannelid (UTF8);
  optional binary maxcpc (UTF8);
  optional binary bidcpc (UTF8);
  optional binary contractcpc (UTF8);
  optional binary finalscore (UTF8);
  optional binary originalscore (UTF8);
  optional binary distributionorder (UTF8);
  optional binary israndom (UTF8);
  optional binary jobchanneltype (UTF8);
  optional binary buckettype (UTF8);
  optional binary predictctr (UTF8);
  optional binary dt (UTF8);
  required boolean isGsp;
}

       
21/01/31 12:46:06 INFO FileOutputCommitter: Saved output of task 'attempt_20210131124540_0003_m_000038_207' to file:/Users/kinsho/Desktop/log/_temporary/0/task_20210131124540_0003_m_000038
21/01/31 12:46:06 INFO SparkHadoopMapRedUtil: attempt_20210131124540_0003_m_000038_207: Committed
21/01/31 12:46:06 INFO Executor: Finished task 38.0 in stage 3.0 (TID 207). 2461 bytes result sent to driver
21/01/31 12:46:06 INFO CoarseGrainedExecutorBackend: Got assigned task 225
21/01/31 12:46:06 INFO Executor: Running task 49.0 in stage 3.0 (TID 225)
21/01/31 12:46:07 INFO MemoryStore: Will not store rdd_12_49
21/01/31 12:46:07 WARN MemoryStore: Not enough space to cache rdd_12_49 in memory! (computed 35.8 MiB so far)
21/01/31 12:46:07 INFO MemoryStore: Memory use = 349.6 MiB (blocks) + 6.3 MiB (scratch space shared across 2 tasks(s)) = 356.0 MiB. Storage limit = 366.3 MiB.
21/01/31 12:46:07 INFO BlockManager: Found block rdd_12_49 locally
21/01/31 12:46:07 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/01/31 12:46:07 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/01/31 12:46:07 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/01/31 12:46:07 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/01/31 12:46:07 INFO CodecConfig: Compression: SNAPPY
21/01/31 12:46:07 INFO CodecConfig: Compression: SNAPPY
21/01/31 12:46:07 INFO ParquetOutputFormat: Parquet block size to 134217728
21/01/31 12:46:07 INFO ParquetOutputFormat: Parquet page size to 1048576
21/01/31 12:46:07 INFO ParquetOutputFormat: Parquet dictionary page size to 1048576
21/01/31 12:46:07 INFO ParquetOutputFormat: Dictionary is on
21/01/31 12:46:07 INFO ParquetOutputFormat: Validation is off
21/01/31 12:46:07 INFO ParquetOutputFormat: Writer version is: PARQUET_1_0
21/01/31 12:46:07 INFO ParquetOutputFormat: Maximum row group padding size is 8388608 bytes
21/01/31 12:46:07 INFO ParquetOutputFormat: Page size checking is: estimated
21/01/31 12:46:07 INFO ParquetOutputFormat: Min row count for page size check is: 100
21/01/31 12:46:07 INFO ParquetOutputFormat: Max row count for page size check is: 10000
21/01/31 12:46:07 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "distributionid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "advertiserid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "distributionhourjst",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "distributiondatetime",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "requestid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "uid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "uavalue",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "uacategory",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "documentid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "documenturl",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "sitecode",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "documenttitle",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "campaignid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "campaigntype",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "publisherid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "publisherchannelid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "maxcpc",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "bidcpc",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "contractcpc",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "finalscore",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "originalscore",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "distributionorder",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "israndom",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "jobchanneltype",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "buckettype",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "predictctr",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "dt",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "isGsp",
    "type" : "boolean",
    "nullable" : false,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary distributionid (UTF8);
  optional binary advertiserid (UTF8);
  optional binary distributionhourjst (UTF8);
  optional binary distributiondatetime (UTF8);
  optional binary requestid (UTF8);
  optional binary uid (UTF8);
  optional binary uavalue (UTF8);
  optional binary uacategory (UTF8);
  optional binary documentid (UTF8);
  optional binary documenturl (UTF8);
  optional binary sitecode (UTF8);
  optional binary documenttitle (UTF8);
  optional binary campaignid (UTF8);
  optional binary campaigntype (UTF8);
  optional binary publisherid (UTF8);
  optional binary publisherchannelid (UTF8);
  optional binary maxcpc (UTF8);
  optional binary bidcpc (UTF8);
  optional binary contractcpc (UTF8);
  optional binary finalscore (UTF8);
  optional binary originalscore (UTF8);
  optional binary distributionorder (UTF8);
  optional binary israndom (UTF8);
  optional binary jobchanneltype (UTF8);
  optional binary buckettype (UTF8);
  optional binary predictctr (UTF8);
  optional binary dt (UTF8);
  required boolean isGsp;
}

       
21/01/31 12:46:23 INFO InternalParquetRecordWriter: Flushing mem columnStore to file. allocated memory: 38551941
21/01/31 12:46:23 INFO InternalParquetRecordWriter: Flushing mem columnStore to file. allocated memory: 38242605
21/01/31 12:46:23 INFO FileOutputCommitter: Saved output of task 'attempt_20210131124540_0003_m_000041_223' to file:/Users/kinsho/Desktop/log/_temporary/0/task_20210131124540_0003_m_000041
21/01/31 12:46:23 INFO SparkHadoopMapRedUtil: attempt_20210131124540_0003_m_000041_223: Committed
21/01/31 12:46:23 INFO Executor: Finished task 41.0 in stage 3.0 (TID 223). 2461 bytes result sent to driver
21/01/31 12:46:23 INFO CoarseGrainedExecutorBackend: Got assigned task 244
21/01/31 12:46:23 INFO Executor: Running task 60.0 in stage 3.0 (TID 244)
21/01/31 12:46:24 INFO MemoryStore: Will not store rdd_12_60
21/01/31 12:46:24 WARN MemoryStore: Not enough space to cache rdd_12_60 in memory! (computed 35.5 MiB so far)
21/01/31 12:46:24 INFO MemoryStore: Memory use = 349.6 MiB (blocks) + 3.1 MiB (scratch space shared across 1 tasks(s)) = 352.7 MiB. Storage limit = 366.3 MiB.
21/01/31 12:46:24 INFO BlockManager: Found block rdd_12_60 locally
21/01/31 12:46:24 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/01/31 12:46:24 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/01/31 12:46:24 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/01/31 12:46:24 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/01/31 12:46:24 INFO CodecConfig: Compression: SNAPPY
21/01/31 12:46:24 INFO CodecConfig: Compression: SNAPPY
21/01/31 12:46:24 INFO ParquetOutputFormat: Parquet block size to 134217728
21/01/31 12:46:24 INFO ParquetOutputFormat: Parquet page size to 1048576
21/01/31 12:46:24 INFO ParquetOutputFormat: Parquet dictionary page size to 1048576
21/01/31 12:46:24 INFO ParquetOutputFormat: Dictionary is on
21/01/31 12:46:24 INFO ParquetOutputFormat: Validation is off
21/01/31 12:46:24 INFO ParquetOutputFormat: Writer version is: PARQUET_1_0
21/01/31 12:46:24 INFO ParquetOutputFormat: Maximum row group padding size is 8388608 bytes
21/01/31 12:46:24 INFO ParquetOutputFormat: Page size checking is: estimated
21/01/31 12:46:24 INFO ParquetOutputFormat: Min row count for page size check is: 100
21/01/31 12:46:24 INFO ParquetOutputFormat: Max row count for page size check is: 10000
21/01/31 12:46:24 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "distributionid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "advertiserid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "distributionhourjst",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "distributiondatetime",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "requestid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "uid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "uavalue",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "uacategory",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "documentid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "documenturl",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "sitecode",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "documenttitle",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "campaignid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "campaigntype",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "publisherid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "publisherchannelid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "maxcpc",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "bidcpc",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "contractcpc",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "finalscore",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "originalscore",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "distributionorder",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "israndom",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "jobchanneltype",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "buckettype",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "predictctr",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "dt",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "isGsp",
    "type" : "boolean",
    "nullable" : false,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary distributionid (UTF8);
  optional binary advertiserid (UTF8);
  optional binary distributionhourjst (UTF8);
  optional binary distributiondatetime (UTF8);
  optional binary requestid (UTF8);
  optional binary uid (UTF8);
  optional binary uavalue (UTF8);
  optional binary uacategory (UTF8);
  optional binary documentid (UTF8);
  optional binary documenturl (UTF8);
  optional binary sitecode (UTF8);
  optional binary documenttitle (UTF8);
  optional binary campaignid (UTF8);
  optional binary campaigntype (UTF8);
  optional binary publisherid (UTF8);
  optional binary publisherchannelid (UTF8);
  optional binary maxcpc (UTF8);
  optional binary bidcpc (UTF8);
  optional binary contractcpc (UTF8);
  optional binary finalscore (UTF8);
  optional binary originalscore (UTF8);
  optional binary distributionorder (UTF8);
  optional binary israndom (UTF8);
  optional binary jobchanneltype (UTF8);
  optional binary buckettype (UTF8);
  optional binary predictctr (UTF8);
  optional binary dt (UTF8);
  required boolean isGsp;
}

       
21/01/31 12:46:24 INFO FileOutputCommitter: Saved output of task 'attempt_20210131124540_0003_m_000049_225' to file:/Users/kinsho/Desktop/log/_temporary/0/task_20210131124540_0003_m_000049
21/01/31 12:46:24 INFO SparkHadoopMapRedUtil: attempt_20210131124540_0003_m_000049_225: Committed
21/01/31 12:46:24 INFO Executor: Finished task 49.0 in stage 3.0 (TID 225). 2461 bytes result sent to driver
21/01/31 12:46:24 INFO CoarseGrainedExecutorBackend: Got assigned task 245
21/01/31 12:46:24 INFO Executor: Running task 67.0 in stage 3.0 (TID 245)
21/01/31 12:46:24 INFO MemoryStore: Will not store rdd_12_67
21/01/31 12:46:24 WARN MemoryStore: Not enough space to cache rdd_12_67 in memory! (computed 35.1 MiB so far)
21/01/31 12:46:24 INFO MemoryStore: Memory use = 349.6 MiB (blocks) + 6.4 MiB (scratch space shared across 2 tasks(s)) = 356.0 MiB. Storage limit = 366.3 MiB.
21/01/31 12:46:24 INFO BlockManager: Found block rdd_12_67 locally
21/01/31 12:46:24 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/01/31 12:46:24 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/01/31 12:46:24 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/01/31 12:46:24 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/01/31 12:46:24 INFO CodecConfig: Compression: SNAPPY
21/01/31 12:46:24 INFO CodecConfig: Compression: SNAPPY
21/01/31 12:46:24 INFO ParquetOutputFormat: Parquet block size to 134217728
21/01/31 12:46:24 INFO ParquetOutputFormat: Parquet page size to 1048576
21/01/31 12:46:24 INFO ParquetOutputFormat: Parquet dictionary page size to 1048576
21/01/31 12:46:24 INFO ParquetOutputFormat: Dictionary is on
21/01/31 12:46:24 INFO ParquetOutputFormat: Validation is off
21/01/31 12:46:24 INFO ParquetOutputFormat: Writer version is: PARQUET_1_0
21/01/31 12:46:24 INFO ParquetOutputFormat: Maximum row group padding size is 8388608 bytes
21/01/31 12:46:24 INFO ParquetOutputFormat: Page size checking is: estimated
21/01/31 12:46:24 INFO ParquetOutputFormat: Min row count for page size check is: 100
21/01/31 12:46:24 INFO ParquetOutputFormat: Max row count for page size check is: 10000
21/01/31 12:46:24 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "distributionid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "advertiserid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "distributionhourjst",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "distributiondatetime",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "requestid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "uid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "uavalue",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "uacategory",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "documentid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "documenturl",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "sitecode",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "documenttitle",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "campaignid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "campaigntype",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "publisherid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "publisherchannelid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "maxcpc",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "bidcpc",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "contractcpc",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "finalscore",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "originalscore",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "distributionorder",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "israndom",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "jobchanneltype",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "buckettype",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "predictctr",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "dt",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "isGsp",
    "type" : "boolean",
    "nullable" : false,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary distributionid (UTF8);
  optional binary advertiserid (UTF8);
  optional binary distributionhourjst (UTF8);
  optional binary distributiondatetime (UTF8);
  optional binary requestid (UTF8);
  optional binary uid (UTF8);
  optional binary uavalue (UTF8);
  optional binary uacategory (UTF8);
  optional binary documentid (UTF8);
  optional binary documenturl (UTF8);
  optional binary sitecode (UTF8);
  optional binary documenttitle (UTF8);
  optional binary campaignid (UTF8);
  optional binary campaigntype (UTF8);
  optional binary publisherid (UTF8);
  optional binary publisherchannelid (UTF8);
  optional binary maxcpc (UTF8);
  optional binary bidcpc (UTF8);
  optional binary contractcpc (UTF8);
  optional binary finalscore (UTF8);
  optional binary originalscore (UTF8);
  optional binary distributionorder (UTF8);
  optional binary israndom (UTF8);
  optional binary jobchanneltype (UTF8);
  optional binary buckettype (UTF8);
  optional binary predictctr (UTF8);
  optional binary dt (UTF8);
  required boolean isGsp;
}

       
21/01/31 12:46:36 INFO InternalParquetRecordWriter: Flushing mem columnStore to file. allocated memory: 37224216
21/01/31 12:46:37 INFO FileOutputCommitter: Saved output of task 'attempt_20210131124540_0003_m_000060_244' to file:/Users/kinsho/Desktop/log/_temporary/0/task_20210131124540_0003_m_000060
21/01/31 12:46:37 INFO SparkHadoopMapRedUtil: attempt_20210131124540_0003_m_000060_244: Committed
21/01/31 12:46:37 INFO Executor: Finished task 60.0 in stage 3.0 (TID 244). 2461 bytes result sent to driver
21/01/31 12:46:37 INFO CoarseGrainedExecutorBackend: Got assigned task 259
21/01/31 12:46:37 INFO Executor: Running task 81.0 in stage 3.0 (TID 259)
21/01/31 12:46:37 INFO InternalParquetRecordWriter: Flushing mem columnStore to file. allocated memory: 36902869
21/01/31 12:46:37 INFO MemoryStore: Will not store rdd_12_81
21/01/31 12:46:37 WARN MemoryStore: Not enough space to cache rdd_12_81 in memory! (computed 34.9 MiB so far)
21/01/31 12:46:37 INFO MemoryStore: Memory use = 349.6 MiB (blocks) + 2.9 MiB (scratch space shared across 1 tasks(s)) = 352.5 MiB. Storage limit = 366.3 MiB.
21/01/31 12:46:37 INFO BlockManager: Found block rdd_12_81 locally
21/01/31 12:46:37 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/01/31 12:46:37 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/01/31 12:46:37 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/01/31 12:46:37 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/01/31 12:46:37 INFO CodecConfig: Compression: SNAPPY
21/01/31 12:46:37 INFO CodecConfig: Compression: SNAPPY
21/01/31 12:46:37 INFO ParquetOutputFormat: Parquet block size to 134217728
21/01/31 12:46:37 INFO ParquetOutputFormat: Parquet page size to 1048576
21/01/31 12:46:37 INFO ParquetOutputFormat: Parquet dictionary page size to 1048576
21/01/31 12:46:37 INFO ParquetOutputFormat: Dictionary is on
21/01/31 12:46:37 INFO ParquetOutputFormat: Validation is off
21/01/31 12:46:37 INFO ParquetOutputFormat: Writer version is: PARQUET_1_0
21/01/31 12:46:37 INFO ParquetOutputFormat: Maximum row group padding size is 8388608 bytes
21/01/31 12:46:37 INFO ParquetOutputFormat: Page size checking is: estimated
21/01/31 12:46:37 INFO ParquetOutputFormat: Min row count for page size check is: 100
21/01/31 12:46:37 INFO ParquetOutputFormat: Max row count for page size check is: 10000
21/01/31 12:46:37 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "distributionid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "advertiserid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "distributionhourjst",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "distributiondatetime",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "requestid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "uid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "uavalue",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "uacategory",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "documentid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "documenturl",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "sitecode",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "documenttitle",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "campaignid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "campaigntype",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "publisherid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "publisherchannelid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "maxcpc",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "bidcpc",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "contractcpc",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "finalscore",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "originalscore",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "distributionorder",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "israndom",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "jobchanneltype",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "buckettype",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "predictctr",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "dt",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "isGsp",
    "type" : "boolean",
    "nullable" : false,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary distributionid (UTF8);
  optional binary advertiserid (UTF8);
  optional binary distributionhourjst (UTF8);
  optional binary distributiondatetime (UTF8);
  optional binary requestid (UTF8);
  optional binary uid (UTF8);
  optional binary uavalue (UTF8);
  optional binary uacategory (UTF8);
  optional binary documentid (UTF8);
  optional binary documenturl (UTF8);
  optional binary sitecode (UTF8);
  optional binary documenttitle (UTF8);
  optional binary campaignid (UTF8);
  optional binary campaigntype (UTF8);
  optional binary publisherid (UTF8);
  optional binary publisherchannelid (UTF8);
  optional binary maxcpc (UTF8);
  optional binary bidcpc (UTF8);
  optional binary contractcpc (UTF8);
  optional binary finalscore (UTF8);
  optional binary originalscore (UTF8);
  optional binary distributionorder (UTF8);
  optional binary israndom (UTF8);
  optional binary jobchanneltype (UTF8);
  optional binary buckettype (UTF8);
  optional binary predictctr (UTF8);
  optional binary dt (UTF8);
  required boolean isGsp;
}

       
21/01/31 12:46:37 INFO FileOutputCommitter: Saved output of task 'attempt_20210131124540_0003_m_000067_245' to file:/Users/kinsho/Desktop/log/_temporary/0/task_20210131124540_0003_m_000067
21/01/31 12:46:37 INFO SparkHadoopMapRedUtil: attempt_20210131124540_0003_m_000067_245: Committed
21/01/31 12:46:37 INFO Executor: Finished task 67.0 in stage 3.0 (TID 245). 2461 bytes result sent to driver
21/01/31 12:46:37 INFO CoarseGrainedExecutorBackend: Got assigned task 261
21/01/31 12:46:37 INFO Executor: Running task 86.0 in stage 3.0 (TID 261)
21/01/31 12:46:37 INFO MemoryStore: Will not store rdd_12_86
21/01/31 12:46:37 WARN MemoryStore: Not enough space to cache rdd_12_86 in memory! (computed 36.5 MiB so far)
21/01/31 12:46:37 INFO MemoryStore: Memory use = 349.6 MiB (blocks) + 6.1 MiB (scratch space shared across 2 tasks(s)) = 355.8 MiB. Storage limit = 366.3 MiB.
21/01/31 12:46:37 INFO BlockManager: Found block rdd_12_86 locally
21/01/31 12:46:37 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/01/31 12:46:37 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/01/31 12:46:37 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/01/31 12:46:37 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/01/31 12:46:37 INFO CodecConfig: Compression: SNAPPY
21/01/31 12:46:37 INFO CodecConfig: Compression: SNAPPY
21/01/31 12:46:37 INFO ParquetOutputFormat: Parquet block size to 134217728
21/01/31 12:46:37 INFO ParquetOutputFormat: Parquet page size to 1048576
21/01/31 12:46:37 INFO ParquetOutputFormat: Parquet dictionary page size to 1048576
21/01/31 12:46:37 INFO ParquetOutputFormat: Dictionary is on
21/01/31 12:46:37 INFO ParquetOutputFormat: Validation is off
21/01/31 12:46:37 INFO ParquetOutputFormat: Writer version is: PARQUET_1_0
21/01/31 12:46:37 INFO ParquetOutputFormat: Maximum row group padding size is 8388608 bytes
21/01/31 12:46:37 INFO ParquetOutputFormat: Page size checking is: estimated
21/01/31 12:46:37 INFO ParquetOutputFormat: Min row count for page size check is: 100
21/01/31 12:46:37 INFO ParquetOutputFormat: Max row count for page size check is: 10000
21/01/31 12:46:37 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "distributionid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "advertiserid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "distributionhourjst",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "distributiondatetime",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "requestid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "uid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "uavalue",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "uacategory",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "documentid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "documenturl",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "sitecode",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "documenttitle",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "campaignid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "campaigntype",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "publisherid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "publisherchannelid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "maxcpc",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "bidcpc",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "contractcpc",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "finalscore",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "originalscore",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "distributionorder",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "israndom",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "jobchanneltype",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "buckettype",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "predictctr",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "dt",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "isGsp",
    "type" : "boolean",
    "nullable" : false,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary distributionid (UTF8);
  optional binary advertiserid (UTF8);
  optional binary distributionhourjst (UTF8);
  optional binary distributiondatetime (UTF8);
  optional binary requestid (UTF8);
  optional binary uid (UTF8);
  optional binary uavalue (UTF8);
  optional binary uacategory (UTF8);
  optional binary documentid (UTF8);
  optional binary documenturl (UTF8);
  optional binary sitecode (UTF8);
  optional binary documenttitle (UTF8);
  optional binary campaignid (UTF8);
  optional binary campaigntype (UTF8);
  optional binary publisherid (UTF8);
  optional binary publisherchannelid (UTF8);
  optional binary maxcpc (UTF8);
  optional binary bidcpc (UTF8);
  optional binary contractcpc (UTF8);
  optional binary finalscore (UTF8);
  optional binary originalscore (UTF8);
  optional binary distributionorder (UTF8);
  optional binary israndom (UTF8);
  optional binary jobchanneltype (UTF8);
  optional binary buckettype (UTF8);
  optional binary predictctr (UTF8);
  optional binary dt (UTF8);
  required boolean isGsp;
}

       
21/01/31 12:46:49 INFO InternalParquetRecordWriter: Flushing mem columnStore to file. allocated memory: 36427733
21/01/31 12:46:49 INFO InternalParquetRecordWriter: Flushing mem columnStore to file. allocated memory: 35946419
21/01/31 12:46:49 INFO FileOutputCommitter: Saved output of task 'attempt_20210131124540_0003_m_000081_259' to file:/Users/kinsho/Desktop/log/_temporary/0/task_20210131124540_0003_m_000081
21/01/31 12:46:49 INFO SparkHadoopMapRedUtil: attempt_20210131124540_0003_m_000081_259: Committed
21/01/31 12:46:49 INFO Executor: Finished task 81.0 in stage 3.0 (TID 259). 2461 bytes result sent to driver
21/01/31 12:46:49 INFO CoarseGrainedExecutorBackend: Got assigned task 277
21/01/31 12:46:49 INFO Executor: Running task 101.0 in stage 3.0 (TID 277)
21/01/31 12:46:49 INFO MemoryStore: Will not store rdd_12_101
21/01/31 12:46:49 WARN MemoryStore: Not enough space to cache rdd_12_101 in memory! (computed 33.1 MiB so far)
21/01/31 12:46:49 INFO MemoryStore: Memory use = 349.6 MiB (blocks) + 2.8 MiB (scratch space shared across 1 tasks(s)) = 352.5 MiB. Storage limit = 366.3 MiB.
21/01/31 12:46:49 INFO BlockManager: Found block rdd_12_101 locally
21/01/31 12:46:49 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/01/31 12:46:49 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/01/31 12:46:49 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/01/31 12:46:49 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/01/31 12:46:49 INFO CodecConfig: Compression: SNAPPY
21/01/31 12:46:49 INFO CodecConfig: Compression: SNAPPY
21/01/31 12:46:49 INFO ParquetOutputFormat: Parquet block size to 134217728
21/01/31 12:46:49 INFO ParquetOutputFormat: Parquet page size to 1048576
21/01/31 12:46:49 INFO ParquetOutputFormat: Parquet dictionary page size to 1048576
21/01/31 12:46:49 INFO ParquetOutputFormat: Dictionary is on
21/01/31 12:46:49 INFO ParquetOutputFormat: Validation is off
21/01/31 12:46:49 INFO ParquetOutputFormat: Writer version is: PARQUET_1_0
21/01/31 12:46:49 INFO ParquetOutputFormat: Maximum row group padding size is 8388608 bytes
21/01/31 12:46:49 INFO ParquetOutputFormat: Page size checking is: estimated
21/01/31 12:46:49 INFO ParquetOutputFormat: Min row count for page size check is: 100
21/01/31 12:46:49 INFO ParquetOutputFormat: Max row count for page size check is: 10000
21/01/31 12:46:49 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "distributionid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "advertiserid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "distributionhourjst",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "distributiondatetime",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "requestid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "uid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "uavalue",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "uacategory",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "documentid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "documenturl",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "sitecode",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "documenttitle",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "campaignid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "campaigntype",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "publisherid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "publisherchannelid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "maxcpc",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "bidcpc",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "contractcpc",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "finalscore",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "originalscore",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "distributionorder",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "israndom",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "jobchanneltype",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "buckettype",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "predictctr",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "dt",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "isGsp",
    "type" : "boolean",
    "nullable" : false,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary distributionid (UTF8);
  optional binary advertiserid (UTF8);
  optional binary distributionhourjst (UTF8);
  optional binary distributiondatetime (UTF8);
  optional binary requestid (UTF8);
  optional binary uid (UTF8);
  optional binary uavalue (UTF8);
  optional binary uacategory (UTF8);
  optional binary documentid (UTF8);
  optional binary documenturl (UTF8);
  optional binary sitecode (UTF8);
  optional binary documenttitle (UTF8);
  optional binary campaignid (UTF8);
  optional binary campaigntype (UTF8);
  optional binary publisherid (UTF8);
  optional binary publisherchannelid (UTF8);
  optional binary maxcpc (UTF8);
  optional binary bidcpc (UTF8);
  optional binary contractcpc (UTF8);
  optional binary finalscore (UTF8);
  optional binary originalscore (UTF8);
  optional binary distributionorder (UTF8);
  optional binary israndom (UTF8);
  optional binary jobchanneltype (UTF8);
  optional binary buckettype (UTF8);
  optional binary predictctr (UTF8);
  optional binary dt (UTF8);
  required boolean isGsp;
}

       
21/01/31 12:46:50 INFO FileOutputCommitter: Saved output of task 'attempt_20210131124540_0003_m_000086_261' to file:/Users/kinsho/Desktop/log/_temporary/0/task_20210131124540_0003_m_000086
21/01/31 12:46:50 INFO SparkHadoopMapRedUtil: attempt_20210131124540_0003_m_000086_261: Committed
21/01/31 12:46:50 INFO Executor: Finished task 86.0 in stage 3.0 (TID 261). 2461 bytes result sent to driver
21/01/31 12:46:50 INFO CoarseGrainedExecutorBackend: Got assigned task 279
21/01/31 12:46:50 INFO Executor: Running task 104.0 in stage 3.0 (TID 279)
21/01/31 12:46:50 INFO MemoryStore: Will not store rdd_12_104
21/01/31 12:46:50 WARN MemoryStore: Not enough space to cache rdd_12_104 in memory! (computed 34.5 MiB so far)
21/01/31 12:46:50 INFO MemoryStore: Memory use = 349.6 MiB (blocks) + 5.9 MiB (scratch space shared across 2 tasks(s)) = 355.5 MiB. Storage limit = 366.3 MiB.
21/01/31 12:46:50 INFO BlockManager: Found block rdd_12_104 locally
21/01/31 12:46:50 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/01/31 12:46:50 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/01/31 12:46:50 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/01/31 12:46:50 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/01/31 12:46:50 INFO CodecConfig: Compression: SNAPPY
21/01/31 12:46:50 INFO CodecConfig: Compression: SNAPPY
21/01/31 12:46:50 INFO ParquetOutputFormat: Parquet block size to 134217728
21/01/31 12:46:50 INFO ParquetOutputFormat: Parquet page size to 1048576
21/01/31 12:46:50 INFO ParquetOutputFormat: Parquet dictionary page size to 1048576
21/01/31 12:46:50 INFO ParquetOutputFormat: Dictionary is on
21/01/31 12:46:50 INFO ParquetOutputFormat: Validation is off
21/01/31 12:46:50 INFO ParquetOutputFormat: Writer version is: PARQUET_1_0
21/01/31 12:46:50 INFO ParquetOutputFormat: Maximum row group padding size is 8388608 bytes
21/01/31 12:46:50 INFO ParquetOutputFormat: Page size checking is: estimated
21/01/31 12:46:50 INFO ParquetOutputFormat: Min row count for page size check is: 100
21/01/31 12:46:50 INFO ParquetOutputFormat: Max row count for page size check is: 10000
21/01/31 12:46:50 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "distributionid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "advertiserid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "distributionhourjst",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "distributiondatetime",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "requestid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "uid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "uavalue",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "uacategory",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "documentid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "documenturl",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "sitecode",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "documenttitle",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "campaignid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "campaigntype",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "publisherid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "publisherchannelid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "maxcpc",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "bidcpc",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "contractcpc",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "finalscore",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "originalscore",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "distributionorder",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "israndom",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "jobchanneltype",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "buckettype",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "predictctr",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "dt",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "isGsp",
    "type" : "boolean",
    "nullable" : false,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary distributionid (UTF8);
  optional binary advertiserid (UTF8);
  optional binary distributionhourjst (UTF8);
  optional binary distributiondatetime (UTF8);
  optional binary requestid (UTF8);
  optional binary uid (UTF8);
  optional binary uavalue (UTF8);
  optional binary uacategory (UTF8);
  optional binary documentid (UTF8);
  optional binary documenturl (UTF8);
  optional binary sitecode (UTF8);
  optional binary documenttitle (UTF8);
  optional binary campaignid (UTF8);
  optional binary campaigntype (UTF8);
  optional binary publisherid (UTF8);
  optional binary publisherchannelid (UTF8);
  optional binary maxcpc (UTF8);
  optional binary bidcpc (UTF8);
  optional binary contractcpc (UTF8);
  optional binary finalscore (UTF8);
  optional binary originalscore (UTF8);
  optional binary distributionorder (UTF8);
  optional binary israndom (UTF8);
  optional binary jobchanneltype (UTF8);
  optional binary buckettype (UTF8);
  optional binary predictctr (UTF8);
  optional binary dt (UTF8);
  required boolean isGsp;
}

       
21/01/31 12:47:01 INFO InternalParquetRecordWriter: Flushing mem columnStore to file. allocated memory: 34998704
21/01/31 12:47:01 INFO InternalParquetRecordWriter: Flushing mem columnStore to file. allocated memory: 34961613
21/01/31 12:47:01 INFO FileOutputCommitter: Saved output of task 'attempt_20210131124540_0003_m_000101_277' to file:/Users/kinsho/Desktop/log/_temporary/0/task_20210131124540_0003_m_000101
21/01/31 12:47:01 INFO SparkHadoopMapRedUtil: attempt_20210131124540_0003_m_000101_277: Committed
21/01/31 12:47:01 INFO Executor: Finished task 101.0 in stage 3.0 (TID 277). 2461 bytes result sent to driver
21/01/31 12:47:01 INFO CoarseGrainedExecutorBackend: Got assigned task 294
21/01/31 12:47:01 INFO Executor: Running task 122.0 in stage 3.0 (TID 294)
21/01/31 12:47:02 INFO MemoryStore: Will not store rdd_12_122
21/01/31 12:47:02 WARN MemoryStore: Not enough space to cache rdd_12_122 in memory! (computed 34.6 MiB so far)
21/01/31 12:47:02 INFO MemoryStore: Memory use = 349.6 MiB (blocks) + 3.0 MiB (scratch space shared across 1 tasks(s)) = 352.6 MiB. Storage limit = 366.3 MiB.
21/01/31 12:47:02 INFO BlockManager: Found block rdd_12_122 locally
21/01/31 12:47:02 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/01/31 12:47:02 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/01/31 12:47:02 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/01/31 12:47:02 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/01/31 12:47:02 INFO CodecConfig: Compression: SNAPPY
21/01/31 12:47:02 INFO CodecConfig: Compression: SNAPPY
21/01/31 12:47:02 INFO ParquetOutputFormat: Parquet block size to 134217728
21/01/31 12:47:02 INFO ParquetOutputFormat: Parquet page size to 1048576
21/01/31 12:47:02 INFO ParquetOutputFormat: Parquet dictionary page size to 1048576
21/01/31 12:47:02 INFO ParquetOutputFormat: Dictionary is on
21/01/31 12:47:02 INFO ParquetOutputFormat: Validation is off
21/01/31 12:47:02 INFO ParquetOutputFormat: Writer version is: PARQUET_1_0
21/01/31 12:47:02 INFO ParquetOutputFormat: Maximum row group padding size is 8388608 bytes
21/01/31 12:47:02 INFO ParquetOutputFormat: Page size checking is: estimated
21/01/31 12:47:02 INFO ParquetOutputFormat: Min row count for page size check is: 100
21/01/31 12:47:02 INFO ParquetOutputFormat: Max row count for page size check is: 10000
21/01/31 12:47:02 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "distributionid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "advertiserid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "distributionhourjst",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "distributiondatetime",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "requestid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "uid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "uavalue",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "uacategory",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "documentid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "documenturl",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "sitecode",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "documenttitle",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "campaignid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "campaigntype",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "publisherid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "publisherchannelid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "maxcpc",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "bidcpc",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "contractcpc",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "finalscore",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "originalscore",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "distributionorder",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "israndom",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "jobchanneltype",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "buckettype",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "predictctr",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "dt",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "isGsp",
    "type" : "boolean",
    "nullable" : false,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary distributionid (UTF8);
  optional binary advertiserid (UTF8);
  optional binary distributionhourjst (UTF8);
  optional binary distributiondatetime (UTF8);
  optional binary requestid (UTF8);
  optional binary uid (UTF8);
  optional binary uavalue (UTF8);
  optional binary uacategory (UTF8);
  optional binary documentid (UTF8);
  optional binary documenturl (UTF8);
  optional binary sitecode (UTF8);
  optional binary documenttitle (UTF8);
  optional binary campaignid (UTF8);
  optional binary campaigntype (UTF8);
  optional binary publisherid (UTF8);
  optional binary publisherchannelid (UTF8);
  optional binary maxcpc (UTF8);
  optional binary bidcpc (UTF8);
  optional binary contractcpc (UTF8);
  optional binary finalscore (UTF8);
  optional binary originalscore (UTF8);
  optional binary distributionorder (UTF8);
  optional binary israndom (UTF8);
  optional binary jobchanneltype (UTF8);
  optional binary buckettype (UTF8);
  optional binary predictctr (UTF8);
  optional binary dt (UTF8);
  required boolean isGsp;
}

       
21/01/31 12:47:02 INFO FileOutputCommitter: Saved output of task 'attempt_20210131124540_0003_m_000104_279' to file:/Users/kinsho/Desktop/log/_temporary/0/task_20210131124540_0003_m_000104
21/01/31 12:47:02 INFO SparkHadoopMapRedUtil: attempt_20210131124540_0003_m_000104_279: Committed
21/01/31 12:47:02 INFO Executor: Finished task 104.0 in stage 3.0 (TID 279). 2461 bytes result sent to driver
21/01/31 12:47:02 INFO CoarseGrainedExecutorBackend: Got assigned task 296
21/01/31 12:47:02 INFO Executor: Running task 123.0 in stage 3.0 (TID 296)
21/01/31 12:47:02 INFO MemoryStore: Will not store rdd_12_123
21/01/31 12:47:02 WARN MemoryStore: Not enough space to cache rdd_12_123 in memory! (computed 35.1 MiB so far)
21/01/31 12:47:02 INFO MemoryStore: Memory use = 349.6 MiB (blocks) + 6.1 MiB (scratch space shared across 2 tasks(s)) = 355.7 MiB. Storage limit = 366.3 MiB.
21/01/31 12:47:02 INFO BlockManager: Found block rdd_12_123 locally
21/01/31 12:47:02 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/01/31 12:47:02 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/01/31 12:47:02 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/01/31 12:47:02 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/01/31 12:47:02 INFO CodecConfig: Compression: SNAPPY
21/01/31 12:47:02 INFO CodecConfig: Compression: SNAPPY
21/01/31 12:47:02 INFO ParquetOutputFormat: Parquet block size to 134217728
21/01/31 12:47:02 INFO ParquetOutputFormat: Parquet page size to 1048576
21/01/31 12:47:02 INFO ParquetOutputFormat: Parquet dictionary page size to 1048576
21/01/31 12:47:02 INFO ParquetOutputFormat: Dictionary is on
21/01/31 12:47:02 INFO ParquetOutputFormat: Validation is off
21/01/31 12:47:02 INFO ParquetOutputFormat: Writer version is: PARQUET_1_0
21/01/31 12:47:02 INFO ParquetOutputFormat: Maximum row group padding size is 8388608 bytes
21/01/31 12:47:02 INFO ParquetOutputFormat: Page size checking is: estimated
21/01/31 12:47:02 INFO ParquetOutputFormat: Min row count for page size check is: 100
21/01/31 12:47:02 INFO ParquetOutputFormat: Max row count for page size check is: 10000
21/01/31 12:47:02 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "distributionid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "advertiserid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "distributionhourjst",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "distributiondatetime",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "requestid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "uid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "uavalue",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "uacategory",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "documentid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "documenturl",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "sitecode",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "documenttitle",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "campaignid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "campaigntype",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "publisherid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "publisherchannelid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "maxcpc",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "bidcpc",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "contractcpc",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "finalscore",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "originalscore",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "distributionorder",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "israndom",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "jobchanneltype",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "buckettype",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "predictctr",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "dt",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "isGsp",
    "type" : "boolean",
    "nullable" : false,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary distributionid (UTF8);
  optional binary advertiserid (UTF8);
  optional binary distributionhourjst (UTF8);
  optional binary distributiondatetime (UTF8);
  optional binary requestid (UTF8);
  optional binary uid (UTF8);
  optional binary uavalue (UTF8);
  optional binary uacategory (UTF8);
  optional binary documentid (UTF8);
  optional binary documenturl (UTF8);
  optional binary sitecode (UTF8);
  optional binary documenttitle (UTF8);
  optional binary campaignid (UTF8);
  optional binary campaigntype (UTF8);
  optional binary publisherid (UTF8);
  optional binary publisherchannelid (UTF8);
  optional binary maxcpc (UTF8);
  optional binary bidcpc (UTF8);
  optional binary contractcpc (UTF8);
  optional binary finalscore (UTF8);
  optional binary originalscore (UTF8);
  optional binary distributionorder (UTF8);
  optional binary israndom (UTF8);
  optional binary jobchanneltype (UTF8);
  optional binary buckettype (UTF8);
  optional binary predictctr (UTF8);
  optional binary dt (UTF8);
  required boolean isGsp;
}

       
21/01/31 12:47:12 INFO InternalParquetRecordWriter: Flushing mem columnStore to file. allocated memory: 35219002
21/01/31 12:47:12 INFO InternalParquetRecordWriter: Flushing mem columnStore to file. allocated memory: 35342618
21/01/31 12:47:12 INFO FileOutputCommitter: Saved output of task 'attempt_20210131124540_0003_m_000122_294' to file:/Users/kinsho/Desktop/log/_temporary/0/task_20210131124540_0003_m_000122
21/01/31 12:47:12 INFO SparkHadoopMapRedUtil: attempt_20210131124540_0003_m_000122_294: Committed
21/01/31 12:47:12 INFO Executor: Finished task 122.0 in stage 3.0 (TID 294). 2461 bytes result sent to driver
21/01/31 12:47:12 INFO CoarseGrainedExecutorBackend: Got assigned task 309
21/01/31 12:47:12 INFO Executor: Running task 142.0 in stage 3.0 (TID 309)
21/01/31 12:47:12 INFO FileOutputCommitter: Saved output of task 'attempt_20210131124540_0003_m_000123_296' to file:/Users/kinsho/Desktop/log/_temporary/0/task_20210131124540_0003_m_000123
21/01/31 12:47:12 INFO SparkHadoopMapRedUtil: attempt_20210131124540_0003_m_000123_296: Committed
21/01/31 12:47:13 INFO Executor: Finished task 123.0 in stage 3.0 (TID 296). 2461 bytes result sent to driver
21/01/31 12:47:13 INFO CoarseGrainedExecutorBackend: Got assigned task 311
21/01/31 12:47:13 INFO Executor: Running task 143.0 in stage 3.0 (TID 311)
21/01/31 12:47:13 INFO MemoryStore: Will not store rdd_12_142
21/01/31 12:47:13 WARN MemoryStore: Not enough space to cache rdd_12_142 in memory! (computed 35.2 MiB so far)
21/01/31 12:47:13 INFO MemoryStore: Memory use = 349.6 MiB (blocks) + 3.1 MiB (scratch space shared across 1 tasks(s)) = 352.7 MiB. Storage limit = 366.3 MiB.
21/01/31 12:47:13 INFO BlockManager: Found block rdd_12_142 locally
21/01/31 12:47:13 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/01/31 12:47:13 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/01/31 12:47:13 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/01/31 12:47:13 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/01/31 12:47:13 INFO CodecConfig: Compression: SNAPPY
21/01/31 12:47:13 INFO CodecConfig: Compression: SNAPPY
21/01/31 12:47:13 INFO ParquetOutputFormat: Parquet block size to 134217728
21/01/31 12:47:13 INFO ParquetOutputFormat: Parquet page size to 1048576
21/01/31 12:47:13 INFO ParquetOutputFormat: Parquet dictionary page size to 1048576
21/01/31 12:47:13 INFO ParquetOutputFormat: Dictionary is on
21/01/31 12:47:13 INFO ParquetOutputFormat: Validation is off
21/01/31 12:47:13 INFO ParquetOutputFormat: Writer version is: PARQUET_1_0
21/01/31 12:47:13 INFO ParquetOutputFormat: Maximum row group padding size is 8388608 bytes
21/01/31 12:47:13 INFO ParquetOutputFormat: Page size checking is: estimated
21/01/31 12:47:13 INFO ParquetOutputFormat: Min row count for page size check is: 100
21/01/31 12:47:13 INFO ParquetOutputFormat: Max row count for page size check is: 10000
21/01/31 12:47:13 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "distributionid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "advertiserid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "distributionhourjst",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "distributiondatetime",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "requestid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "uid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "uavalue",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "uacategory",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "documentid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "documenturl",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "sitecode",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "documenttitle",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "campaignid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "campaigntype",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "publisherid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "publisherchannelid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "maxcpc",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "bidcpc",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "contractcpc",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "finalscore",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "originalscore",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "distributionorder",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "israndom",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "jobchanneltype",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "buckettype",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "predictctr",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "dt",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "isGsp",
    "type" : "boolean",
    "nullable" : false,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary distributionid (UTF8);
  optional binary advertiserid (UTF8);
  optional binary distributionhourjst (UTF8);
  optional binary distributiondatetime (UTF8);
  optional binary requestid (UTF8);
  optional binary uid (UTF8);
  optional binary uavalue (UTF8);
  optional binary uacategory (UTF8);
  optional binary documentid (UTF8);
  optional binary documenturl (UTF8);
  optional binary sitecode (UTF8);
  optional binary documenttitle (UTF8);
  optional binary campaignid (UTF8);
  optional binary campaigntype (UTF8);
  optional binary publisherid (UTF8);
  optional binary publisherchannelid (UTF8);
  optional binary maxcpc (UTF8);
  optional binary bidcpc (UTF8);
  optional binary contractcpc (UTF8);
  optional binary finalscore (UTF8);
  optional binary originalscore (UTF8);
  optional binary distributionorder (UTF8);
  optional binary israndom (UTF8);
  optional binary jobchanneltype (UTF8);
  optional binary buckettype (UTF8);
  optional binary predictctr (UTF8);
  optional binary dt (UTF8);
  required boolean isGsp;
}

       
21/01/31 12:47:13 INFO MemoryStore: Will not store rdd_12_143
21/01/31 12:47:13 WARN MemoryStore: Not enough space to cache rdd_12_143 in memory! (computed 36.6 MiB so far)
21/01/31 12:47:13 INFO MemoryStore: Memory use = 349.6 MiB (blocks) + 6.2 MiB (scratch space shared across 2 tasks(s)) = 355.8 MiB. Storage limit = 366.3 MiB.
21/01/31 12:47:13 INFO BlockManager: Found block rdd_12_143 locally
21/01/31 12:47:13 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/01/31 12:47:13 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/01/31 12:47:13 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/01/31 12:47:13 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/01/31 12:47:13 INFO CodecConfig: Compression: SNAPPY
21/01/31 12:47:13 INFO CodecConfig: Compression: SNAPPY
21/01/31 12:47:13 INFO ParquetOutputFormat: Parquet block size to 134217728
21/01/31 12:47:13 INFO ParquetOutputFormat: Parquet page size to 1048576
21/01/31 12:47:13 INFO ParquetOutputFormat: Parquet dictionary page size to 1048576
21/01/31 12:47:13 INFO ParquetOutputFormat: Dictionary is on
21/01/31 12:47:13 INFO ParquetOutputFormat: Validation is off
21/01/31 12:47:13 INFO ParquetOutputFormat: Writer version is: PARQUET_1_0
21/01/31 12:47:13 INFO ParquetOutputFormat: Maximum row group padding size is 8388608 bytes
21/01/31 12:47:13 INFO ParquetOutputFormat: Page size checking is: estimated
21/01/31 12:47:13 INFO ParquetOutputFormat: Min row count for page size check is: 100
21/01/31 12:47:13 INFO ParquetOutputFormat: Max row count for page size check is: 10000
21/01/31 12:47:13 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "distributionid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "advertiserid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "distributionhourjst",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "distributiondatetime",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "requestid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "uid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "uavalue",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "uacategory",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "documentid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "documenturl",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "sitecode",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "documenttitle",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "campaignid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "campaigntype",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "publisherid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "publisherchannelid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "maxcpc",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "bidcpc",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "contractcpc",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "finalscore",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "originalscore",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "distributionorder",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "israndom",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "jobchanneltype",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "buckettype",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "predictctr",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "dt",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "isGsp",
    "type" : "boolean",
    "nullable" : false,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary distributionid (UTF8);
  optional binary advertiserid (UTF8);
  optional binary distributionhourjst (UTF8);
  optional binary distributiondatetime (UTF8);
  optional binary requestid (UTF8);
  optional binary uid (UTF8);
  optional binary uavalue (UTF8);
  optional binary uacategory (UTF8);
  optional binary documentid (UTF8);
  optional binary documenturl (UTF8);
  optional binary sitecode (UTF8);
  optional binary documenttitle (UTF8);
  optional binary campaignid (UTF8);
  optional binary campaigntype (UTF8);
  optional binary publisherid (UTF8);
  optional binary publisherchannelid (UTF8);
  optional binary maxcpc (UTF8);
  optional binary bidcpc (UTF8);
  optional binary contractcpc (UTF8);
  optional binary finalscore (UTF8);
  optional binary originalscore (UTF8);
  optional binary distributionorder (UTF8);
  optional binary israndom (UTF8);
  optional binary jobchanneltype (UTF8);
  optional binary buckettype (UTF8);
  optional binary predictctr (UTF8);
  optional binary dt (UTF8);
  required boolean isGsp;
}

       
21/01/31 12:47:21 INFO InternalParquetRecordWriter: Flushing mem columnStore to file. allocated memory: 35610283
21/01/31 12:47:22 INFO InternalParquetRecordWriter: Flushing mem columnStore to file. allocated memory: 35515705
21/01/31 12:47:22 INFO FileOutputCommitter: Saved output of task 'attempt_20210131124540_0003_m_000143_311' to file:/Users/kinsho/Desktop/log/_temporary/0/task_20210131124540_0003_m_000143
21/01/31 12:47:22 INFO SparkHadoopMapRedUtil: attempt_20210131124540_0003_m_000143_311: Committed
21/01/31 12:47:22 INFO Executor: Finished task 143.0 in stage 3.0 (TID 311). 2461 bytes result sent to driver
21/01/31 12:47:22 INFO CoarseGrainedExecutorBackend: Got assigned task 324
21/01/31 12:47:22 INFO Executor: Running task 162.0 in stage 3.0 (TID 324)
21/01/31 12:47:22 INFO MemoryStore: Will not store rdd_12_162
21/01/31 12:47:22 WARN MemoryStore: Not enough space to cache rdd_12_162 in memory! (computed 37.4 MiB so far)
21/01/31 12:47:22 INFO MemoryStore: Memory use = 349.6 MiB (blocks) + 3.2 MiB (scratch space shared across 1 tasks(s)) = 352.9 MiB. Storage limit = 366.3 MiB.
21/01/31 12:47:22 INFO BlockManager: Found block rdd_12_162 locally
21/01/31 12:47:22 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/01/31 12:47:22 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/01/31 12:47:22 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/01/31 12:47:22 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/01/31 12:47:22 INFO CodecConfig: Compression: SNAPPY
21/01/31 12:47:22 INFO CodecConfig: Compression: SNAPPY
21/01/31 12:47:22 INFO ParquetOutputFormat: Parquet block size to 134217728
21/01/31 12:47:22 INFO ParquetOutputFormat: Parquet page size to 1048576
21/01/31 12:47:22 INFO ParquetOutputFormat: Parquet dictionary page size to 1048576
21/01/31 12:47:22 INFO ParquetOutputFormat: Dictionary is on
21/01/31 12:47:22 INFO ParquetOutputFormat: Validation is off
21/01/31 12:47:22 INFO ParquetOutputFormat: Writer version is: PARQUET_1_0
21/01/31 12:47:22 INFO ParquetOutputFormat: Maximum row group padding size is 8388608 bytes
21/01/31 12:47:22 INFO ParquetOutputFormat: Page size checking is: estimated
21/01/31 12:47:22 INFO ParquetOutputFormat: Min row count for page size check is: 100
21/01/31 12:47:22 INFO ParquetOutputFormat: Max row count for page size check is: 10000
21/01/31 12:47:22 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "distributionid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "advertiserid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "distributionhourjst",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "distributiondatetime",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "requestid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "uid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "uavalue",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "uacategory",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "documentid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "documenturl",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "sitecode",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "documenttitle",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "campaignid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "campaigntype",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "publisherid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "publisherchannelid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "maxcpc",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "bidcpc",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "contractcpc",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "finalscore",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "originalscore",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "distributionorder",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "israndom",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "jobchanneltype",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "buckettype",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "predictctr",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "dt",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "isGsp",
    "type" : "boolean",
    "nullable" : false,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary distributionid (UTF8);
  optional binary advertiserid (UTF8);
  optional binary distributionhourjst (UTF8);
  optional binary distributiondatetime (UTF8);
  optional binary requestid (UTF8);
  optional binary uid (UTF8);
  optional binary uavalue (UTF8);
  optional binary uacategory (UTF8);
  optional binary documentid (UTF8);
  optional binary documenturl (UTF8);
  optional binary sitecode (UTF8);
  optional binary documenttitle (UTF8);
  optional binary campaignid (UTF8);
  optional binary campaigntype (UTF8);
  optional binary publisherid (UTF8);
  optional binary publisherchannelid (UTF8);
  optional binary maxcpc (UTF8);
  optional binary bidcpc (UTF8);
  optional binary contractcpc (UTF8);
  optional binary finalscore (UTF8);
  optional binary originalscore (UTF8);
  optional binary distributionorder (UTF8);
  optional binary israndom (UTF8);
  optional binary jobchanneltype (UTF8);
  optional binary buckettype (UTF8);
  optional binary predictctr (UTF8);
  optional binary dt (UTF8);
  required boolean isGsp;
}

       
21/01/31 12:47:22 INFO FileOutputCommitter: Saved output of task 'attempt_20210131124540_0003_m_000142_309' to file:/Users/kinsho/Desktop/log/_temporary/0/task_20210131124540_0003_m_000142
21/01/31 12:47:22 INFO SparkHadoopMapRedUtil: attempt_20210131124540_0003_m_000142_309: Committed
21/01/31 12:47:22 INFO Executor: Finished task 142.0 in stage 3.0 (TID 309). 2504 bytes result sent to driver
21/01/31 12:47:22 INFO CoarseGrainedExecutorBackend: Got assigned task 325
21/01/31 12:47:22 INFO Executor: Running task 163.0 in stage 3.0 (TID 325)
21/01/31 12:47:22 INFO MemoryStore: Will not store rdd_12_163
21/01/31 12:47:22 WARN MemoryStore: Not enough space to cache rdd_12_163 in memory! (computed 37.4 MiB so far)
21/01/31 12:47:22 INFO MemoryStore: Memory use = 349.6 MiB (blocks) + 6.7 MiB (scratch space shared across 2 tasks(s)) = 356.3 MiB. Storage limit = 366.3 MiB.
21/01/31 12:47:22 INFO BlockManager: Found block rdd_12_163 locally
21/01/31 12:47:22 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/01/31 12:47:22 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/01/31 12:47:22 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/01/31 12:47:22 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/01/31 12:47:22 INFO CodecConfig: Compression: SNAPPY
21/01/31 12:47:22 INFO CodecConfig: Compression: SNAPPY
21/01/31 12:47:22 INFO ParquetOutputFormat: Parquet block size to 134217728
21/01/31 12:47:22 INFO ParquetOutputFormat: Parquet page size to 1048576
21/01/31 12:47:22 INFO ParquetOutputFormat: Parquet dictionary page size to 1048576
21/01/31 12:47:22 INFO ParquetOutputFormat: Dictionary is on
21/01/31 12:47:22 INFO ParquetOutputFormat: Validation is off
21/01/31 12:47:22 INFO ParquetOutputFormat: Writer version is: PARQUET_1_0
21/01/31 12:47:22 INFO ParquetOutputFormat: Maximum row group padding size is 8388608 bytes
21/01/31 12:47:22 INFO ParquetOutputFormat: Page size checking is: estimated
21/01/31 12:47:22 INFO ParquetOutputFormat: Min row count for page size check is: 100
21/01/31 12:47:22 INFO ParquetOutputFormat: Max row count for page size check is: 10000
21/01/31 12:47:22 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "distributionid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "advertiserid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "distributionhourjst",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "distributiondatetime",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "requestid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "uid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "uavalue",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "uacategory",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "documentid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "documenturl",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "sitecode",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "documenttitle",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "campaignid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "campaigntype",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "publisherid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "publisherchannelid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "maxcpc",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "bidcpc",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "contractcpc",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "finalscore",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "originalscore",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "distributionorder",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "israndom",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "jobchanneltype",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "buckettype",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "predictctr",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "dt",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "isGsp",
    "type" : "boolean",
    "nullable" : false,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary distributionid (UTF8);
  optional binary advertiserid (UTF8);
  optional binary distributionhourjst (UTF8);
  optional binary distributiondatetime (UTF8);
  optional binary requestid (UTF8);
  optional binary uid (UTF8);
  optional binary uavalue (UTF8);
  optional binary uacategory (UTF8);
  optional binary documentid (UTF8);
  optional binary documenturl (UTF8);
  optional binary sitecode (UTF8);
  optional binary documenttitle (UTF8);
  optional binary campaignid (UTF8);
  optional binary campaigntype (UTF8);
  optional binary publisherid (UTF8);
  optional binary publisherchannelid (UTF8);
  optional binary maxcpc (UTF8);
  optional binary bidcpc (UTF8);
  optional binary contractcpc (UTF8);
  optional binary finalscore (UTF8);
  optional binary originalscore (UTF8);
  optional binary distributionorder (UTF8);
  optional binary israndom (UTF8);
  optional binary jobchanneltype (UTF8);
  optional binary buckettype (UTF8);
  optional binary predictctr (UTF8);
  optional binary dt (UTF8);
  required boolean isGsp;
}

       
21/01/31 12:47:31 INFO InternalParquetRecordWriter: Flushing mem columnStore to file. allocated memory: 35627654
21/01/31 12:47:31 INFO InternalParquetRecordWriter: Flushing mem columnStore to file. allocated memory: 35772534
21/01/31 12:47:31 INFO FileOutputCommitter: Saved output of task 'attempt_20210131124540_0003_m_000162_324' to file:/Users/kinsho/Desktop/log/_temporary/0/task_20210131124540_0003_m_000162
21/01/31 12:47:31 INFO SparkHadoopMapRedUtil: attempt_20210131124540_0003_m_000162_324: Committed
21/01/31 12:47:31 INFO Executor: Finished task 162.0 in stage 3.0 (TID 324). 2461 bytes result sent to driver
21/01/31 12:47:31 INFO FileOutputCommitter: Saved output of task 'attempt_20210131124540_0003_m_000163_325' to file:/Users/kinsho/Desktop/log/_temporary/0/task_20210131124540_0003_m_000163
21/01/31 12:47:31 INFO SparkHadoopMapRedUtil: attempt_20210131124540_0003_m_000163_325: Committed
21/01/31 12:47:31 INFO Executor: Finished task 163.0 in stage 3.0 (TID 325). 2461 bytes result sent to driver
21/01/31 12:47:34 INFO CoarseGrainedExecutorBackend: Got assigned task 339
21/01/31 12:47:34 INFO Executor: Running task 91.0 in stage 3.0 (TID 339)
21/01/31 12:47:34 INFO CoarseGrainedExecutorBackend: Got assigned task 341
21/01/31 12:47:34 INFO Executor: Running task 98.0 in stage 3.0 (TID 341)
21/01/31 12:47:34 INFO BlockManager: Read rdd_12_98 from the disk of a same host executor is successful.
21/01/31 12:47:34 INFO BlockManager: Read rdd_12_91 from the disk of a same host executor is successful.
21/01/31 12:47:34 INFO BlockManager: Found block rdd_12_98 remotely
21/01/31 12:47:34 INFO BlockManager: Found block rdd_12_91 remotely
21/01/31 12:47:34 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/01/31 12:47:34 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/01/31 12:47:34 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/01/31 12:47:34 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/01/31 12:47:34 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/01/31 12:47:34 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/01/31 12:47:34 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/01/31 12:47:34 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/01/31 12:47:34 INFO CodecConfig: Compression: SNAPPY
21/01/31 12:47:34 INFO CodecConfig: Compression: SNAPPY
21/01/31 12:47:34 INFO CodecConfig: Compression: SNAPPY
21/01/31 12:47:34 INFO CodecConfig: Compression: SNAPPY
21/01/31 12:47:34 INFO ParquetOutputFormat: Parquet block size to 134217728
21/01/31 12:47:34 INFO ParquetOutputFormat: Parquet page size to 1048576
21/01/31 12:47:34 INFO ParquetOutputFormat: Parquet dictionary page size to 1048576
21/01/31 12:47:34 INFO ParquetOutputFormat: Parquet block size to 134217728
21/01/31 12:47:34 INFO ParquetOutputFormat: Dictionary is on
21/01/31 12:47:34 INFO ParquetOutputFormat: Parquet page size to 1048576
21/01/31 12:47:34 INFO ParquetOutputFormat: Parquet dictionary page size to 1048576
21/01/31 12:47:34 INFO ParquetOutputFormat: Dictionary is on
21/01/31 12:47:34 INFO ParquetOutputFormat: Validation is off
21/01/31 12:47:34 INFO ParquetOutputFormat: Writer version is: PARQUET_1_0
21/01/31 12:47:34 INFO ParquetOutputFormat: Maximum row group padding size is 8388608 bytes
21/01/31 12:47:34 INFO ParquetOutputFormat: Page size checking is: estimated
21/01/31 12:47:34 INFO ParquetOutputFormat: Validation is off
21/01/31 12:47:34 INFO ParquetOutputFormat: Min row count for page size check is: 100
21/01/31 12:47:34 INFO ParquetOutputFormat: Max row count for page size check is: 10000
21/01/31 12:47:34 INFO ParquetOutputFormat: Writer version is: PARQUET_1_0
21/01/31 12:47:34 INFO ParquetOutputFormat: Maximum row group padding size is 8388608 bytes
21/01/31 12:47:34 INFO ParquetOutputFormat: Page size checking is: estimated
21/01/31 12:47:34 INFO ParquetOutputFormat: Min row count for page size check is: 100
21/01/31 12:47:34 INFO ParquetOutputFormat: Max row count for page size check is: 10000
21/01/31 12:47:34 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "distributionid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "advertiserid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "distributionhourjst",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "distributiondatetime",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "requestid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "uid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "uavalue",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "uacategory",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "documentid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "documenturl",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "sitecode",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "documenttitle",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "campaignid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "campaigntype",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "publisherid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "publisherchannelid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "maxcpc",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "bidcpc",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "contractcpc",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "finalscore",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "originalscore",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "distributionorder",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "israndom",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "jobchanneltype",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "buckettype",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "predictctr",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "dt",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "isGsp",
    "type" : "boolean",
    "nullable" : false,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary distributionid (UTF8);
  optional binary advertiserid (UTF8);
  optional binary distributionhourjst (UTF8);
  optional binary distributiondatetime (UTF8);
  optional binary requestid (UTF8);
  optional binary uid (UTF8);
  optional binary uavalue (UTF8);
  optional binary uacategory (UTF8);
  optional binary documentid (UTF8);
  optional binary documenturl (UTF8);
  optional binary sitecode (UTF8);
  optional binary documenttitle (UTF8);
  optional binary campaignid (UTF8);
  optional binary campaigntype (UTF8);
  optional binary publisherid (UTF8);
  optional binary publisherchannelid (UTF8);
  optional binary maxcpc (UTF8);
  optional binary bidcpc (UTF8);
  optional binary contractcpc (UTF8);
  optional binary finalscore (UTF8);
  optional binary originalscore (UTF8);
  optional binary distributionorder (UTF8);
  optional binary israndom (UTF8);
  optional binary jobchanneltype (UTF8);
  optional binary buckettype (UTF8);
  optional binary predictctr (UTF8);
  optional binary dt (UTF8);
  required boolean isGsp;
}

       
21/01/31 12:47:34 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "distributionid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "advertiserid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "distributionhourjst",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "distributiondatetime",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "requestid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "uid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "uavalue",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "uacategory",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "documentid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "documenturl",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "sitecode",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "documenttitle",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "campaignid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "campaigntype",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "publisherid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "publisherchannelid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "maxcpc",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "bidcpc",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "contractcpc",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "finalscore",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "originalscore",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "distributionorder",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "israndom",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "jobchanneltype",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "buckettype",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "predictctr",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "dt",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "isGsp",
    "type" : "boolean",
    "nullable" : false,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary distributionid (UTF8);
  optional binary advertiserid (UTF8);
  optional binary distributionhourjst (UTF8);
  optional binary distributiondatetime (UTF8);
  optional binary requestid (UTF8);
  optional binary uid (UTF8);
  optional binary uavalue (UTF8);
  optional binary uacategory (UTF8);
  optional binary documentid (UTF8);
  optional binary documenturl (UTF8);
  optional binary sitecode (UTF8);
  optional binary documenttitle (UTF8);
  optional binary campaignid (UTF8);
  optional binary campaigntype (UTF8);
  optional binary publisherid (UTF8);
  optional binary publisherchannelid (UTF8);
  optional binary maxcpc (UTF8);
  optional binary bidcpc (UTF8);
  optional binary contractcpc (UTF8);
  optional binary finalscore (UTF8);
  optional binary originalscore (UTF8);
  optional binary distributionorder (UTF8);
  optional binary israndom (UTF8);
  optional binary jobchanneltype (UTF8);
  optional binary buckettype (UTF8);
  optional binary predictctr (UTF8);
  optional binary dt (UTF8);
  required boolean isGsp;
}

       
21/01/31 12:47:45 INFO InternalParquetRecordWriter: Flushing mem columnStore to file. allocated memory: 35804607
21/01/31 12:47:45 INFO InternalParquetRecordWriter: Flushing mem columnStore to file. allocated memory: 35385960
21/01/31 12:47:45 INFO FileOutputCommitter: Saved output of task 'attempt_20210131124540_0003_m_000091_339' to file:/Users/kinsho/Desktop/log/_temporary/0/task_20210131124540_0003_m_000091
21/01/31 12:47:45 INFO SparkHadoopMapRedUtil: attempt_20210131124540_0003_m_000091_339: Committed
21/01/31 12:47:45 INFO Executor: Finished task 91.0 in stage 3.0 (TID 339). 2461 bytes result sent to driver
21/01/31 12:47:46 INFO FileOutputCommitter: Saved output of task 'attempt_20210131124540_0003_m_000098_341' to file:/Users/kinsho/Desktop/log/_temporary/0/task_20210131124540_0003_m_000098
21/01/31 12:47:46 INFO SparkHadoopMapRedUtil: attempt_20210131124540_0003_m_000098_341: Committed
21/01/31 12:47:46 INFO Executor: Finished task 98.0 in stage 3.0 (TID 341). 2461 bytes result sent to driver
21/01/31 12:49:26 INFO CoarseGrainedExecutorBackend: Got assigned task 364
21/01/31 12:49:26 INFO Executor: Running task 36.3 in stage 3.0 (TID 364)
21/01/31 12:49:26 INFO FileScanRDD: Reading File path: file:///Users/kinsho/Desktop/impressionLog.csv, range: 4831838208-4966055936, partition values: [empty row]
21/01/31 12:49:28 INFO MemoryStore: Will not store rdd_12_36
21/01/31 12:49:28 WARN MemoryStore: Not enough space to cache rdd_12_36 in memory! (computed 35.5 MiB so far)
21/01/31 12:49:28 INFO MemoryStore: Memory use = 349.6 MiB (blocks) + 3.1 MiB (scratch space shared across 1 tasks(s)) = 352.8 MiB. Storage limit = 366.3 MiB.
21/01/31 12:49:28 WARN BlockManager: Persisting block rdd_12_36 to disk instead.
21/01/31 12:49:37 INFO MemoryStore: Will not store rdd_12_36
21/01/31 12:49:37 WARN MemoryStore: Not enough space to cache rdd_12_36 in memory! (computed 35.5 MiB so far)
21/01/31 12:49:37 INFO MemoryStore: Memory use = 349.6 MiB (blocks) + 3.1 MiB (scratch space shared across 1 tasks(s)) = 352.8 MiB. Storage limit = 366.3 MiB.
21/01/31 12:49:37 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/01/31 12:49:37 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/01/31 12:49:37 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/01/31 12:49:37 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/01/31 12:49:37 INFO CodecConfig: Compression: SNAPPY
21/01/31 12:49:37 INFO CodecConfig: Compression: SNAPPY
21/01/31 12:49:37 INFO ParquetOutputFormat: Parquet block size to 134217728
21/01/31 12:49:37 INFO ParquetOutputFormat: Parquet page size to 1048576
21/01/31 12:49:37 INFO ParquetOutputFormat: Parquet dictionary page size to 1048576
21/01/31 12:49:37 INFO ParquetOutputFormat: Dictionary is on
21/01/31 12:49:37 INFO ParquetOutputFormat: Validation is off
21/01/31 12:49:37 INFO ParquetOutputFormat: Writer version is: PARQUET_1_0
21/01/31 12:49:37 INFO ParquetOutputFormat: Maximum row group padding size is 8388608 bytes
21/01/31 12:49:37 INFO ParquetOutputFormat: Page size checking is: estimated
21/01/31 12:49:37 INFO ParquetOutputFormat: Min row count for page size check is: 100
21/01/31 12:49:37 INFO ParquetOutputFormat: Max row count for page size check is: 10000
21/01/31 12:49:37 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "distributionid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "advertiserid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "distributionhourjst",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "distributiondatetime",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "requestid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "uid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "uavalue",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "uacategory",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "documentid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "documenturl",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "sitecode",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "documenttitle",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "campaignid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "campaigntype",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "publisherid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "publisherchannelid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "maxcpc",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "bidcpc",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "contractcpc",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "finalscore",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "originalscore",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "distributionorder",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "israndom",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "jobchanneltype",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "buckettype",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "predictctr",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "dt",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "isGsp",
    "type" : "boolean",
    "nullable" : false,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary distributionid (UTF8);
  optional binary advertiserid (UTF8);
  optional binary distributionhourjst (UTF8);
  optional binary distributiondatetime (UTF8);
  optional binary requestid (UTF8);
  optional binary uid (UTF8);
  optional binary uavalue (UTF8);
  optional binary uacategory (UTF8);
  optional binary documentid (UTF8);
  optional binary documenturl (UTF8);
  optional binary sitecode (UTF8);
  optional binary documenttitle (UTF8);
  optional binary campaignid (UTF8);
  optional binary campaigntype (UTF8);
  optional binary publisherid (UTF8);
  optional binary publisherchannelid (UTF8);
  optional binary maxcpc (UTF8);
  optional binary bidcpc (UTF8);
  optional binary contractcpc (UTF8);
  optional binary finalscore (UTF8);
  optional binary originalscore (UTF8);
  optional binary distributionorder (UTF8);
  optional binary israndom (UTF8);
  optional binary jobchanneltype (UTF8);
  optional binary buckettype (UTF8);
  optional binary predictctr (UTF8);
  optional binary dt (UTF8);
  required boolean isGsp;
}

       
21/01/31 12:49:39 INFO InternalParquetRecordWriter: Flushing mem columnStore to file. allocated memory: 39644904
21/01/31 12:49:39 INFO FileOutputCommitter: Saved output of task 'attempt_20210131124540_0003_m_000036_364' to file:/Users/kinsho/Desktop/log/_temporary/0/task_20210131124540_0003_m_000036
21/01/31 12:49:39 INFO SparkHadoopMapRedUtil: attempt_20210131124540_0003_m_000036_364: Committed
21/01/31 12:49:39 INFO Executor: Finished task 36.3 in stage 3.0 (TID 364). 2461 bytes result sent to driver
21/01/31 12:49:40 INFO CoarseGrainedExecutorBackend: Driver commanded a shutdown
