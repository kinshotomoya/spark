Spark Executor Command: "/Library/Java/JavaVirtualMachines/adoptopenjdk-8.jdk/Contents/Home/jre/bin/java" "-cp" "/Users/kinsho/workspace/spark-3.0.1/conf/:/Users/kinsho/workspace/spark-3.0.1/assembly/target/scala-2.12/jars/*" "-Xmx1024M" "-Dspark.driver.port=57817" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@192.168.11.7:57817" "--executor-id" "8" "--hostname" "192.168.11.7" "--cores" "2" "--app-id" "app-20210131143845-0032" "--worker-url" "spark://Worker@192.168.11.7:63978"
========================================

Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
21/01/31 14:38:47 INFO CoarseGrainedExecutorBackend: Started daemon with process name: 28706@ST000000035
21/01/31 14:38:47 INFO SignalUtils: Registered signal handler for TERM
21/01/31 14:38:47 INFO SignalUtils: Registered signal handler for HUP
21/01/31 14:38:47 INFO SignalUtils: Registered signal handler for INT
21/01/31 14:38:48 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
21/01/31 14:38:48 INFO SecurityManager: Changing view acls to: kinsho
21/01/31 14:38:48 INFO SecurityManager: Changing modify acls to: kinsho
21/01/31 14:38:48 INFO SecurityManager: Changing view acls groups to: 
21/01/31 14:38:48 INFO SecurityManager: Changing modify acls groups to: 
21/01/31 14:38:48 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(kinsho); groups with view permissions: Set(); users  with modify permissions: Set(kinsho); groups with modify permissions: Set()
21/01/31 14:38:49 INFO TransportClientFactory: Successfully created connection to /192.168.11.7:57817 after 118 ms (0 ms spent in bootstraps)
21/01/31 14:38:49 INFO SecurityManager: Changing view acls to: kinsho
21/01/31 14:38:49 INFO SecurityManager: Changing modify acls to: kinsho
21/01/31 14:38:49 INFO SecurityManager: Changing view acls groups to: 
21/01/31 14:38:49 INFO SecurityManager: Changing modify acls groups to: 
21/01/31 14:38:49 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(kinsho); groups with view permissions: Set(); users  with modify permissions: Set(kinsho); groups with modify permissions: Set()
21/01/31 14:38:49 INFO TransportClientFactory: Successfully created connection to /192.168.11.7:57817 after 3 ms (0 ms spent in bootstraps)
21/01/31 14:38:49 INFO DiskBlockManager: Created local directory at /private/var/folders/tm/7v5m6cg144g467bsj7zgsxgc0000gn/T/spark-fb50bbc1-385d-42b4-ab16-c5d025f6423b/executor-949f4b37-6ca2-4527-89cd-ac3dea41cb16/blockmgr-9c66f7e3-3f15-4281-9885-4ceee7d3053c
21/01/31 14:38:49 INFO MemoryStore: MemoryStore started with capacity 366.3 MiB
21/01/31 14:38:50 INFO CoarseGrainedExecutorBackend: Connecting to driver: spark://CoarseGrainedScheduler@192.168.11.7:57817
21/01/31 14:38:50 INFO ResourceUtils: ==============================================================
21/01/31 14:38:50 INFO ResourceUtils: Resources for spark.executor:

21/01/31 14:38:50 INFO ResourceUtils: ==============================================================
21/01/31 14:38:50 INFO WorkerWatcher: Connecting to worker spark://Worker@192.168.11.7:63978
21/01/31 14:38:50 INFO CoarseGrainedExecutorBackend: Successfully registered with driver
21/01/31 14:38:50 INFO TransportClientFactory: Successfully created connection to /192.168.11.7:63978 after 42 ms (0 ms spent in bootstraps)
21/01/31 14:38:50 INFO Executor: Starting executor ID 8 on host 192.168.11.7
21/01/31 14:38:50 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 57880.
21/01/31 14:38:50 INFO NettyBlockTransferService: Server created on 192.168.11.7:57880
21/01/31 14:38:50 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
21/01/31 14:38:50 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(8, 192.168.11.7, 57880, None)
21/01/31 14:38:50 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(8, 192.168.11.7, 57880, None)
21/01/31 14:38:50 INFO BlockManager: Initialized BlockManager: BlockManagerId(8, 192.168.11.7, 57880, None)
21/01/31 14:38:54 INFO CoarseGrainedExecutorBackend: Got assigned task 4
21/01/31 14:38:54 INFO CoarseGrainedExecutorBackend: Got assigned task 14
21/01/31 14:38:54 INFO Executor: Running task 3.0 in stage 1.0 (TID 4)
21/01/31 14:38:54 INFO Executor: Running task 13.0 in stage 1.0 (TID 14)
21/01/31 14:38:54 INFO Executor: Fetching spark://192.168.11.7:57817/jars/simple-project_2.12-1.0.jar with timestamp 1612071524858
21/01/31 14:38:54 INFO TransportClientFactory: Successfully created connection to /192.168.11.7:57817 after 15 ms (0 ms spent in bootstraps)
21/01/31 14:38:54 INFO Utils: Fetching spark://192.168.11.7:57817/jars/simple-project_2.12-1.0.jar to /private/var/folders/tm/7v5m6cg144g467bsj7zgsxgc0000gn/T/spark-fb50bbc1-385d-42b4-ab16-c5d025f6423b/executor-949f4b37-6ca2-4527-89cd-ac3dea41cb16/spark-ce94b300-c024-4c85-bb60-3356721a28aa/fetchFileTemp6573388798389233964.tmp
21/01/31 14:38:54 INFO Utils: Copying /private/var/folders/tm/7v5m6cg144g467bsj7zgsxgc0000gn/T/spark-fb50bbc1-385d-42b4-ab16-c5d025f6423b/executor-949f4b37-6ca2-4527-89cd-ac3dea41cb16/spark-ce94b300-c024-4c85-bb60-3356721a28aa/15175652501612071524858_cache to /Users/kinsho/workspace/spark-3.0.1/work/app-20210131143845-0032/8/./simple-project_2.12-1.0.jar
21/01/31 14:38:55 INFO Executor: Adding file:/Users/kinsho/workspace/spark-3.0.1/work/app-20210131143845-0032/8/./simple-project_2.12-1.0.jar to class loader
21/01/31 14:38:55 INFO TorrentBroadcast: Started reading broadcast variable 4 with 1 pieces (estimated total size 4.0 MiB)
21/01/31 14:38:55 INFO TransportClientFactory: Successfully created connection to /192.168.11.7:57823 after 13 ms (0 ms spent in bootstraps)
21/01/31 14:38:55 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 68.7 KiB, free 366.2 MiB)
21/01/31 14:38:55 INFO TorrentBroadcast: Reading broadcast variable 4 took 481 ms
21/01/31 14:38:56 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 193.8 KiB, free 366.0 MiB)
21/01/31 14:38:58 INFO FileScanRDD: Reading File path: file:///Users/kinsho/Desktop/impressionLog.csv, range: 1744830464-1879048192, partition values: [empty row]
21/01/31 14:38:58 INFO FileScanRDD: Reading File path: file:///Users/kinsho/Desktop/impressionLog.csv, range: 402653184-536870912, partition values: [empty row]
21/01/31 14:39:00 INFO CodeGenerator: Code generated in 1129.191768 ms
21/01/31 14:39:00 INFO TorrentBroadcast: Started reading broadcast variable 3 with 1 pieces (estimated total size 4.0 MiB)
21/01/31 14:39:00 INFO TransportClientFactory: Successfully created connection to /192.168.11.7:57878 after 2 ms (0 ms spent in bootstraps)
21/01/31 14:39:00 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 24.0 KiB, free 366.0 MiB)
21/01/31 14:39:00 INFO TorrentBroadcast: Reading broadcast variable 3 took 40 ms
21/01/31 14:39:00 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 336.8 KiB, free 365.7 MiB)
21/01/31 14:39:30 INFO MemoryStore: Will not store rdd_12_13
21/01/31 14:39:30 WARN MemoryStore: Not enough space to cache rdd_12_13 in memory! (computed 135.6 MiB so far)
21/01/31 14:39:30 INFO MemoryStore: Memory use = 623.3 KiB (blocks) + 310.9 MiB (scratch space shared across 2 tasks(s)) = 311.5 MiB. Storage limit = 366.3 MiB.
21/01/31 14:39:30 WARN BlockManager: Persisting block rdd_12_13 to disk instead.
21/01/31 14:39:35 INFO MemoryStore: Block rdd_12_3 stored as values in memory (estimated size 163.6 MiB, free 202.1 MiB)
21/01/31 14:39:35 INFO CodeGenerator: Code generated in 12.289618 ms
21/01/31 14:39:35 INFO CodeGenerator: Code generated in 135.95718 ms
21/01/31 14:39:35 INFO CodeGenerator: Code generated in 118.864732 ms
21/01/31 14:39:35 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/01/31 14:39:35 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/01/31 14:39:35 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/01/31 14:39:35 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/01/31 14:39:35 INFO CodecConfig: Compression: SNAPPY
21/01/31 14:39:35 INFO CodecConfig: Compression: SNAPPY
21/01/31 14:39:35 INFO ParquetOutputFormat: Parquet block size to 134217728
21/01/31 14:39:35 INFO ParquetOutputFormat: Parquet page size to 1048576
21/01/31 14:39:35 INFO ParquetOutputFormat: Parquet dictionary page size to 1048576
21/01/31 14:39:35 INFO ParquetOutputFormat: Dictionary is on
21/01/31 14:39:35 INFO ParquetOutputFormat: Validation is off
21/01/31 14:39:35 INFO ParquetOutputFormat: Writer version is: PARQUET_1_0
21/01/31 14:39:35 INFO ParquetOutputFormat: Maximum row group padding size is 8388608 bytes
21/01/31 14:39:35 INFO ParquetOutputFormat: Page size checking is: estimated
21/01/31 14:39:35 INFO ParquetOutputFormat: Min row count for page size check is: 100
21/01/31 14:39:35 INFO ParquetOutputFormat: Max row count for page size check is: 10000
21/01/31 14:39:36 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "distributionid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "advertiserid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "distributionhourjst",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "distributiondatetime",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "requestid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "uid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "uavalue",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "uacategory",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "documentid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "documenturl",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "sitecode",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "documenttitle",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "campaignid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "campaigntype",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "publisherid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "publisherchannelid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "maxcpc",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "bidcpc",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "contractcpc",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "finalscore",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "originalscore",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "distributionorder",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "israndom",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "jobchanneltype",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "buckettype",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "predictctr",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "dt",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "isGsp",
    "type" : "boolean",
    "nullable" : false,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary distributionid (UTF8);
  optional binary advertiserid (UTF8);
  optional binary distributionhourjst (UTF8);
  optional binary distributiondatetime (UTF8);
  optional binary requestid (UTF8);
  optional binary uid (UTF8);
  optional binary uavalue (UTF8);
  optional binary uacategory (UTF8);
  optional binary documentid (UTF8);
  optional binary documenturl (UTF8);
  optional binary sitecode (UTF8);
  optional binary documenttitle (UTF8);
  optional binary campaignid (UTF8);
  optional binary campaigntype (UTF8);
  optional binary publisherid (UTF8);
  optional binary publisherchannelid (UTF8);
  optional binary maxcpc (UTF8);
  optional binary bidcpc (UTF8);
  optional binary contractcpc (UTF8);
  optional binary finalscore (UTF8);
  optional binary originalscore (UTF8);
  optional binary distributionorder (UTF8);
  optional binary israndom (UTF8);
  optional binary jobchanneltype (UTF8);
  optional binary buckettype (UTF8);
  optional binary predictctr (UTF8);
  optional binary dt (UTF8);
  required boolean isGsp;
}

       
21/01/31 14:39:36 INFO CodecPool: Got brand-new compressor [.snappy]
21/01/31 14:39:44 INFO MemoryStore: Will not store rdd_12_13
21/01/31 14:39:44 WARN MemoryStore: Not enough space to cache rdd_12_13 in memory! (computed 135.6 MiB so far)
21/01/31 14:39:44 INFO MemoryStore: Memory use = 164.2 MiB (blocks) + 103.4 MiB (scratch space shared across 1 tasks(s)) = 267.6 MiB. Storage limit = 366.3 MiB.
21/01/31 14:39:44 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/01/31 14:39:44 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/01/31 14:39:44 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/01/31 14:39:44 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/01/31 14:39:44 INFO CodecConfig: Compression: SNAPPY
21/01/31 14:39:44 INFO CodecConfig: Compression: SNAPPY
21/01/31 14:39:44 INFO ParquetOutputFormat: Parquet block size to 134217728
21/01/31 14:39:44 INFO ParquetOutputFormat: Parquet page size to 1048576
21/01/31 14:39:44 INFO ParquetOutputFormat: Parquet dictionary page size to 1048576
21/01/31 14:39:44 INFO ParquetOutputFormat: Dictionary is on
21/01/31 14:39:44 INFO ParquetOutputFormat: Validation is off
21/01/31 14:39:44 INFO ParquetOutputFormat: Writer version is: PARQUET_1_0
21/01/31 14:39:44 INFO ParquetOutputFormat: Maximum row group padding size is 8388608 bytes
21/01/31 14:39:44 INFO ParquetOutputFormat: Page size checking is: estimated
21/01/31 14:39:44 INFO ParquetOutputFormat: Min row count for page size check is: 100
21/01/31 14:39:44 INFO ParquetOutputFormat: Max row count for page size check is: 10000
21/01/31 14:39:44 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "distributionid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "advertiserid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "distributionhourjst",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "distributiondatetime",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "requestid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "uid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "uavalue",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "uacategory",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "documentid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "documenturl",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "sitecode",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "documenttitle",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "campaignid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "campaigntype",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "publisherid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "publisherchannelid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "maxcpc",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "bidcpc",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "contractcpc",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "finalscore",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "originalscore",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "distributionorder",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "israndom",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "jobchanneltype",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "buckettype",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "predictctr",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "dt",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "isGsp",
    "type" : "boolean",
    "nullable" : false,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary distributionid (UTF8);
  optional binary advertiserid (UTF8);
  optional binary distributionhourjst (UTF8);
  optional binary distributiondatetime (UTF8);
  optional binary requestid (UTF8);
  optional binary uid (UTF8);
  optional binary uavalue (UTF8);
  optional binary uacategory (UTF8);
  optional binary documentid (UTF8);
  optional binary documenturl (UTF8);
  optional binary sitecode (UTF8);
  optional binary documenttitle (UTF8);
  optional binary campaignid (UTF8);
  optional binary campaigntype (UTF8);
  optional binary publisherid (UTF8);
  optional binary publisherchannelid (UTF8);
  optional binary maxcpc (UTF8);
  optional binary bidcpc (UTF8);
  optional binary contractcpc (UTF8);
  optional binary finalscore (UTF8);
  optional binary originalscore (UTF8);
  optional binary distributionorder (UTF8);
  optional binary israndom (UTF8);
  optional binary jobchanneltype (UTF8);
  optional binary buckettype (UTF8);
  optional binary predictctr (UTF8);
  optional binary dt (UTF8);
  required boolean isGsp;
}

       
21/01/31 14:39:44 INFO CodecPool: Got brand-new compressor [.snappy]
21/01/31 14:39:48 INFO InternalParquetRecordWriter: Flushing mem columnStore to file. allocated memory: 37800370
21/01/31 14:39:49 INFO FileOutputCommitter: Saved output of task 'attempt_20210131143854_0001_m_000003_4' to file:/Users/kinsho/Desktop/log/_temporary/0/task_20210131143854_0001_m_000003
21/01/31 14:39:49 INFO SparkHadoopMapRedUtil: attempt_20210131143854_0001_m_000003_4: Committed
21/01/31 14:39:49 INFO Executor: Finished task 3.0 in stage 1.0 (TID 4). 2504 bytes result sent to driver
21/01/31 14:39:49 INFO CoarseGrainedExecutorBackend: Got assigned task 23
21/01/31 14:39:49 INFO Executor: Running task 22.0 in stage 1.0 (TID 23)
21/01/31 14:39:49 INFO FileScanRDD: Reading File path: file:///Users/kinsho/Desktop/impressionLog.csv, range: 2952790016-3087007744, partition values: [empty row]
21/01/31 14:39:54 INFO InternalParquetRecordWriter: Flushing mem columnStore to file. allocated memory: 41412370
21/01/31 14:39:54 INFO FileOutputCommitter: Saved output of task 'attempt_20210131143854_0001_m_000013_14' to file:/Users/kinsho/Desktop/log/_temporary/0/task_20210131143854_0001_m_000013
21/01/31 14:39:54 INFO SparkHadoopMapRedUtil: attempt_20210131143854_0001_m_000013_14: Committed
21/01/31 14:39:54 INFO Executor: Finished task 13.0 in stage 1.0 (TID 14). 2461 bytes result sent to driver
21/01/31 14:39:54 INFO CoarseGrainedExecutorBackend: Got assigned task 32
21/01/31 14:39:54 INFO Executor: Running task 31.0 in stage 1.0 (TID 32)
21/01/31 14:39:54 INFO FileScanRDD: Reading File path: file:///Users/kinsho/Desktop/impressionLog.csv, range: 4160749568-4294967296, partition values: [empty row]
21/01/31 14:40:08 INFO MemoryStore: Will not store rdd_12_31
21/01/31 14:40:08 WARN MemoryStore: Not enough space to cache rdd_12_31 in memory! (computed 69.2 MiB so far)
21/01/31 14:40:08 INFO MemoryStore: Memory use = 164.2 MiB (blocks) + 155.5 MiB (scratch space shared across 2 tasks(s)) = 319.7 MiB. Storage limit = 366.3 MiB.
21/01/31 14:40:08 WARN BlockManager: Persisting block rdd_12_31 to disk instead.
21/01/31 14:40:21 INFO MemoryStore: 4 blocks selected for dropping (623.3 KiB bytes)
21/01/31 14:40:21 INFO BlockManager: Dropping block broadcast_4_piece0 from memory
21/01/31 14:40:21 INFO BlockManager: Writing block broadcast_4_piece0 to disk
21/01/31 14:40:21 INFO BlockManager: Dropping block broadcast_4 from memory
21/01/31 14:40:21 INFO BlockManager: Writing block broadcast_4 to disk
21/01/31 14:40:22 INFO BlockManager: Dropping block broadcast_3_piece0 from memory
21/01/31 14:40:22 INFO BlockManager: Writing block broadcast_3_piece0 to disk
21/01/31 14:40:22 INFO BlockManager: Dropping block broadcast_3 from memory
21/01/31 14:40:22 INFO BlockManager: Writing block broadcast_3 to disk
21/01/31 14:40:22 INFO MemoryStore: After dropping 4 blocks, free memory is 202.7 MiB
21/01/31 14:40:33 INFO MemoryStore: Block rdd_12_22 stored as values in memory (estimated size 184.6 MiB, free 18.1 MiB)
21/01/31 14:40:33 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/01/31 14:40:33 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/01/31 14:40:33 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/01/31 14:40:33 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/01/31 14:40:33 INFO CodecConfig: Compression: SNAPPY
21/01/31 14:40:33 INFO CodecConfig: Compression: SNAPPY
21/01/31 14:40:33 INFO ParquetOutputFormat: Parquet block size to 134217728
21/01/31 14:40:33 INFO ParquetOutputFormat: Parquet page size to 1048576
21/01/31 14:40:33 INFO ParquetOutputFormat: Parquet dictionary page size to 1048576
21/01/31 14:40:33 INFO ParquetOutputFormat: Dictionary is on
21/01/31 14:40:33 INFO ParquetOutputFormat: Validation is off
21/01/31 14:40:33 INFO ParquetOutputFormat: Writer version is: PARQUET_1_0
21/01/31 14:40:33 INFO ParquetOutputFormat: Maximum row group padding size is 8388608 bytes
21/01/31 14:40:33 INFO ParquetOutputFormat: Page size checking is: estimated
21/01/31 14:40:33 INFO ParquetOutputFormat: Min row count for page size check is: 100
21/01/31 14:40:33 INFO ParquetOutputFormat: Max row count for page size check is: 10000
21/01/31 14:40:33 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "distributionid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "advertiserid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "distributionhourjst",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "distributiondatetime",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "requestid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "uid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "uavalue",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "uacategory",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "documentid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "documenturl",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "sitecode",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "documenttitle",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "campaignid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "campaigntype",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "publisherid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "publisherchannelid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "maxcpc",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "bidcpc",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "contractcpc",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "finalscore",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "originalscore",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "distributionorder",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "israndom",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "jobchanneltype",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "buckettype",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "predictctr",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "dt",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "isGsp",
    "type" : "boolean",
    "nullable" : false,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary distributionid (UTF8);
  optional binary advertiserid (UTF8);
  optional binary distributionhourjst (UTF8);
  optional binary distributiondatetime (UTF8);
  optional binary requestid (UTF8);
  optional binary uid (UTF8);
  optional binary uavalue (UTF8);
  optional binary uacategory (UTF8);
  optional binary documentid (UTF8);
  optional binary documenturl (UTF8);
  optional binary sitecode (UTF8);
  optional binary documenttitle (UTF8);
  optional binary campaignid (UTF8);
  optional binary campaigntype (UTF8);
  optional binary publisherid (UTF8);
  optional binary publisherchannelid (UTF8);
  optional binary maxcpc (UTF8);
  optional binary bidcpc (UTF8);
  optional binary contractcpc (UTF8);
  optional binary finalscore (UTF8);
  optional binary originalscore (UTF8);
  optional binary distributionorder (UTF8);
  optional binary israndom (UTF8);
  optional binary jobchanneltype (UTF8);
  optional binary buckettype (UTF8);
  optional binary predictctr (UTF8);
  optional binary dt (UTF8);
  required boolean isGsp;
}

       
21/01/31 14:40:37 INFO MemoryStore: Will not store rdd_12_31
21/01/31 14:40:37 WARN MemoryStore: Not enough space to cache rdd_12_31 in memory! (computed 35.4 MiB so far)
21/01/31 14:40:37 INFO MemoryStore: Memory use = 348.2 MiB (blocks) + 3.1 MiB (scratch space shared across 1 tasks(s)) = 351.4 MiB. Storage limit = 366.3 MiB.
21/01/31 14:40:37 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/01/31 14:40:37 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/01/31 14:40:37 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/01/31 14:40:37 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/01/31 14:40:37 INFO CodecConfig: Compression: SNAPPY
21/01/31 14:40:37 INFO CodecConfig: Compression: SNAPPY
21/01/31 14:40:37 INFO ParquetOutputFormat: Parquet block size to 134217728
21/01/31 14:40:37 INFO ParquetOutputFormat: Parquet page size to 1048576
21/01/31 14:40:37 INFO ParquetOutputFormat: Parquet dictionary page size to 1048576
21/01/31 14:40:37 INFO ParquetOutputFormat: Dictionary is on
21/01/31 14:40:37 INFO ParquetOutputFormat: Validation is off
21/01/31 14:40:37 INFO ParquetOutputFormat: Writer version is: PARQUET_1_0
21/01/31 14:40:37 INFO ParquetOutputFormat: Maximum row group padding size is 8388608 bytes
21/01/31 14:40:37 INFO ParquetOutputFormat: Page size checking is: estimated
21/01/31 14:40:37 INFO ParquetOutputFormat: Min row count for page size check is: 100
21/01/31 14:40:37 INFO ParquetOutputFormat: Max row count for page size check is: 10000
21/01/31 14:40:37 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "distributionid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "advertiserid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "distributionhourjst",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "distributiondatetime",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "requestid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "uid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "uavalue",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "uacategory",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "documentid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "documenturl",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "sitecode",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "documenttitle",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "campaignid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "campaigntype",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "publisherid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "publisherchannelid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "maxcpc",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "bidcpc",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "contractcpc",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "finalscore",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "originalscore",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "distributionorder",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "israndom",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "jobchanneltype",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "buckettype",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "predictctr",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "dt",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "isGsp",
    "type" : "boolean",
    "nullable" : false,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary distributionid (UTF8);
  optional binary advertiserid (UTF8);
  optional binary distributionhourjst (UTF8);
  optional binary distributiondatetime (UTF8);
  optional binary requestid (UTF8);
  optional binary uid (UTF8);
  optional binary uavalue (UTF8);
  optional binary uacategory (UTF8);
  optional binary documentid (UTF8);
  optional binary documenturl (UTF8);
  optional binary sitecode (UTF8);
  optional binary documenttitle (UTF8);
  optional binary campaignid (UTF8);
  optional binary campaigntype (UTF8);
  optional binary publisherid (UTF8);
  optional binary publisherchannelid (UTF8);
  optional binary maxcpc (UTF8);
  optional binary bidcpc (UTF8);
  optional binary contractcpc (UTF8);
  optional binary finalscore (UTF8);
  optional binary originalscore (UTF8);
  optional binary distributionorder (UTF8);
  optional binary israndom (UTF8);
  optional binary jobchanneltype (UTF8);
  optional binary buckettype (UTF8);
  optional binary predictctr (UTF8);
  optional binary dt (UTF8);
  required boolean isGsp;
}

       
21/01/31 14:40:41 INFO InternalParquetRecordWriter: Flushing mem columnStore to file. allocated memory: 42398223
21/01/31 14:40:41 INFO FileOutputCommitter: Saved output of task 'attempt_20210131143854_0001_m_000022_23' to file:/Users/kinsho/Desktop/log/_temporary/0/task_20210131143854_0001_m_000022
21/01/31 14:40:41 INFO SparkHadoopMapRedUtil: attempt_20210131143854_0001_m_000022_23: Committed
21/01/31 14:40:41 INFO Executor: Finished task 22.0 in stage 1.0 (TID 23). 2461 bytes result sent to driver
21/01/31 14:40:42 INFO CoarseGrainedExecutorBackend: Got assigned task 42
21/01/31 14:40:42 INFO Executor: Running task 41.0 in stage 1.0 (TID 42)
21/01/31 14:40:42 INFO FileScanRDD: Reading File path: file:///Users/kinsho/Desktop/impressionLog.csv, range: 5502926848-5637144576, partition values: [empty row]
21/01/31 14:40:46 INFO InternalParquetRecordWriter: Flushing mem columnStore to file. allocated memory: 40215384
21/01/31 14:40:46 INFO FileOutputCommitter: Saved output of task 'attempt_20210131143854_0001_m_000031_32' to file:/Users/kinsho/Desktop/log/_temporary/0/task_20210131143854_0001_m_000031
21/01/31 14:40:46 INFO SparkHadoopMapRedUtil: attempt_20210131143854_0001_m_000031_32: Committed
21/01/31 14:40:46 INFO Executor: Finished task 31.0 in stage 1.0 (TID 32). 2461 bytes result sent to driver
21/01/31 14:40:46 INFO CoarseGrainedExecutorBackend: Got assigned task 50
21/01/31 14:40:46 INFO Executor: Running task 49.0 in stage 1.0 (TID 50)
21/01/31 14:40:46 INFO FileScanRDD: Reading File path: file:///Users/kinsho/Desktop/impressionLog.csv, range: 6576668672-6710886400, partition values: [empty row]
21/01/31 14:40:49 INFO MemoryStore: Will not store rdd_12_41
21/01/31 14:40:49 WARN MemoryStore: Not enough space to cache rdd_12_41 in memory! (computed 35.7 MiB so far)
21/01/31 14:40:49 INFO MemoryStore: Memory use = 348.2 MiB (blocks) + 6.3 MiB (scratch space shared across 2 tasks(s)) = 354.6 MiB. Storage limit = 366.3 MiB.
21/01/31 14:40:49 WARN BlockManager: Persisting block rdd_12_41 to disk instead.
21/01/31 14:40:53 INFO MemoryStore: Will not store rdd_12_49
21/01/31 14:40:53 WARN MemoryStore: Not enough space to cache rdd_12_49 in memory! (computed 35.8 MiB so far)
21/01/31 14:40:53 INFO MemoryStore: Memory use = 348.2 MiB (blocks) + 3.1 MiB (scratch space shared across 1 tasks(s)) = 351.4 MiB. Storage limit = 366.3 MiB.
21/01/31 14:40:53 WARN BlockManager: Persisting block rdd_12_49 to disk instead.
21/01/31 14:41:14 INFO MemoryStore: Will not store rdd_12_41
21/01/31 14:41:14 WARN MemoryStore: Not enough space to cache rdd_12_41 in memory! (computed 35.7 MiB so far)
21/01/31 14:41:14 INFO MemoryStore: Memory use = 348.2 MiB (blocks) + 3.2 MiB (scratch space shared across 1 tasks(s)) = 351.4 MiB. Storage limit = 366.3 MiB.
21/01/31 14:41:14 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/01/31 14:41:14 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/01/31 14:41:14 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/01/31 14:41:14 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/01/31 14:41:14 INFO CodecConfig: Compression: SNAPPY
21/01/31 14:41:14 INFO CodecConfig: Compression: SNAPPY
21/01/31 14:41:14 INFO ParquetOutputFormat: Parquet block size to 134217728
21/01/31 14:41:14 INFO ParquetOutputFormat: Parquet page size to 1048576
21/01/31 14:41:14 INFO ParquetOutputFormat: Parquet dictionary page size to 1048576
21/01/31 14:41:14 INFO ParquetOutputFormat: Dictionary is on
21/01/31 14:41:14 INFO ParquetOutputFormat: Validation is off
21/01/31 14:41:14 INFO ParquetOutputFormat: Writer version is: PARQUET_1_0
21/01/31 14:41:14 INFO ParquetOutputFormat: Maximum row group padding size is 8388608 bytes
21/01/31 14:41:14 INFO ParquetOutputFormat: Page size checking is: estimated
21/01/31 14:41:14 INFO ParquetOutputFormat: Min row count for page size check is: 100
21/01/31 14:41:14 INFO ParquetOutputFormat: Max row count for page size check is: 10000
21/01/31 14:41:14 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "distributionid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "advertiserid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "distributionhourjst",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "distributiondatetime",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "requestid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "uid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "uavalue",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "uacategory",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "documentid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "documenturl",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "sitecode",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "documenttitle",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "campaignid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "campaigntype",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "publisherid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "publisherchannelid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "maxcpc",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "bidcpc",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "contractcpc",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "finalscore",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "originalscore",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "distributionorder",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "israndom",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "jobchanneltype",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "buckettype",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "predictctr",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "dt",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "isGsp",
    "type" : "boolean",
    "nullable" : false,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary distributionid (UTF8);
  optional binary advertiserid (UTF8);
  optional binary distributionhourjst (UTF8);
  optional binary distributiondatetime (UTF8);
  optional binary requestid (UTF8);
  optional binary uid (UTF8);
  optional binary uavalue (UTF8);
  optional binary uacategory (UTF8);
  optional binary documentid (UTF8);
  optional binary documenturl (UTF8);
  optional binary sitecode (UTF8);
  optional binary documenttitle (UTF8);
  optional binary campaignid (UTF8);
  optional binary campaigntype (UTF8);
  optional binary publisherid (UTF8);
  optional binary publisherchannelid (UTF8);
  optional binary maxcpc (UTF8);
  optional binary bidcpc (UTF8);
  optional binary contractcpc (UTF8);
  optional binary finalscore (UTF8);
  optional binary originalscore (UTF8);
  optional binary distributionorder (UTF8);
  optional binary israndom (UTF8);
  optional binary jobchanneltype (UTF8);
  optional binary buckettype (UTF8);
  optional binary predictctr (UTF8);
  optional binary dt (UTF8);
  required boolean isGsp;
}

       
21/01/31 14:41:18 INFO MemoryStore: Will not store rdd_12_49
21/01/31 14:41:18 WARN MemoryStore: Not enough space to cache rdd_12_49 in memory! (computed 35.8 MiB so far)
21/01/31 14:41:18 INFO MemoryStore: Memory use = 348.2 MiB (blocks) + 3.1 MiB (scratch space shared across 1 tasks(s)) = 351.4 MiB. Storage limit = 366.3 MiB.
21/01/31 14:41:18 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/01/31 14:41:18 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/01/31 14:41:18 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/01/31 14:41:18 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/01/31 14:41:18 INFO CodecConfig: Compression: SNAPPY
21/01/31 14:41:18 INFO CodecConfig: Compression: SNAPPY
21/01/31 14:41:18 INFO ParquetOutputFormat: Parquet block size to 134217728
21/01/31 14:41:18 INFO ParquetOutputFormat: Parquet page size to 1048576
21/01/31 14:41:18 INFO ParquetOutputFormat: Parquet dictionary page size to 1048576
21/01/31 14:41:18 INFO ParquetOutputFormat: Dictionary is on
21/01/31 14:41:18 INFO ParquetOutputFormat: Validation is off
21/01/31 14:41:18 INFO ParquetOutputFormat: Writer version is: PARQUET_1_0
21/01/31 14:41:18 INFO ParquetOutputFormat: Maximum row group padding size is 8388608 bytes
21/01/31 14:41:18 INFO ParquetOutputFormat: Page size checking is: estimated
21/01/31 14:41:18 INFO ParquetOutputFormat: Min row count for page size check is: 100
21/01/31 14:41:18 INFO ParquetOutputFormat: Max row count for page size check is: 10000
21/01/31 14:41:18 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "distributionid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "advertiserid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "distributionhourjst",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "distributiondatetime",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "requestid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "uid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "uavalue",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "uacategory",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "documentid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "documenturl",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "sitecode",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "documenttitle",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "campaignid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "campaigntype",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "publisherid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "publisherchannelid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "maxcpc",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "bidcpc",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "contractcpc",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "finalscore",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "originalscore",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "distributionorder",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "israndom",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "jobchanneltype",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "buckettype",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "predictctr",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "dt",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "isGsp",
    "type" : "boolean",
    "nullable" : false,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary distributionid (UTF8);
  optional binary advertiserid (UTF8);
  optional binary distributionhourjst (UTF8);
  optional binary distributiondatetime (UTF8);
  optional binary requestid (UTF8);
  optional binary uid (UTF8);
  optional binary uavalue (UTF8);
  optional binary uacategory (UTF8);
  optional binary documentid (UTF8);
  optional binary documenturl (UTF8);
  optional binary sitecode (UTF8);
  optional binary documenttitle (UTF8);
  optional binary campaignid (UTF8);
  optional binary campaigntype (UTF8);
  optional binary publisherid (UTF8);
  optional binary publisherchannelid (UTF8);
  optional binary maxcpc (UTF8);
  optional binary bidcpc (UTF8);
  optional binary contractcpc (UTF8);
  optional binary finalscore (UTF8);
  optional binary originalscore (UTF8);
  optional binary distributionorder (UTF8);
  optional binary israndom (UTF8);
  optional binary jobchanneltype (UTF8);
  optional binary buckettype (UTF8);
  optional binary predictctr (UTF8);
  optional binary dt (UTF8);
  required boolean isGsp;
}

       
21/01/31 14:41:21 INFO InternalParquetRecordWriter: Flushing mem columnStore to file. allocated memory: 38551941
21/01/31 14:41:22 INFO FileOutputCommitter: Saved output of task 'attempt_20210131143854_0001_m_000041_42' to file:/Users/kinsho/Desktop/log/_temporary/0/task_20210131143854_0001_m_000041
21/01/31 14:41:22 INFO SparkHadoopMapRedUtil: attempt_20210131143854_0001_m_000041_42: Committed
21/01/31 14:41:22 INFO Executor: Finished task 41.0 in stage 1.0 (TID 42). 2461 bytes result sent to driver
21/01/31 14:41:22 INFO CoarseGrainedExecutorBackend: Got assigned task 61
21/01/31 14:41:22 INFO Executor: Running task 60.0 in stage 1.0 (TID 61)
21/01/31 14:41:22 INFO FileScanRDD: Reading File path: file:///Users/kinsho/Desktop/impressionLog.csv, range: 8053063680-8187281408, partition values: [empty row]
21/01/31 14:41:26 INFO InternalParquetRecordWriter: Flushing mem columnStore to file. allocated memory: 38242605
21/01/31 14:41:26 INFO FileOutputCommitter: Saved output of task 'attempt_20210131143854_0001_m_000049_50' to file:/Users/kinsho/Desktop/log/_temporary/0/task_20210131143854_0001_m_000049
21/01/31 14:41:26 INFO SparkHadoopMapRedUtil: attempt_20210131143854_0001_m_000049_50: Committed
21/01/31 14:41:26 INFO Executor: Finished task 49.0 in stage 1.0 (TID 50). 2461 bytes result sent to driver
21/01/31 14:41:26 INFO CoarseGrainedExecutorBackend: Got assigned task 64
21/01/31 14:41:26 INFO Executor: Running task 63.0 in stage 1.0 (TID 64)
21/01/31 14:41:26 INFO FileScanRDD: Reading File path: file:///Users/kinsho/Desktop/impressionLog.csv, range: 8455716864-8589934592, partition values: [empty row]
21/01/31 14:41:30 INFO MemoryStore: Will not store rdd_12_60
21/01/31 14:41:30 WARN MemoryStore: Not enough space to cache rdd_12_60 in memory! (computed 35.5 MiB so far)
21/01/31 14:41:30 INFO MemoryStore: Memory use = 348.2 MiB (blocks) + 6.4 MiB (scratch space shared across 2 tasks(s)) = 354.6 MiB. Storage limit = 366.3 MiB.
21/01/31 14:41:30 WARN BlockManager: Persisting block rdd_12_60 to disk instead.
21/01/31 14:41:33 INFO MemoryStore: Will not store rdd_12_63
21/01/31 14:41:33 WARN MemoryStore: Not enough space to cache rdd_12_63 in memory! (computed 36.3 MiB so far)
21/01/31 14:41:33 INFO MemoryStore: Memory use = 348.2 MiB (blocks) + 3.3 MiB (scratch space shared across 1 tasks(s)) = 351.5 MiB. Storage limit = 366.3 MiB.
21/01/31 14:41:33 WARN BlockManager: Persisting block rdd_12_63 to disk instead.
21/01/31 14:41:56 INFO MemoryStore: Will not store rdd_12_60
21/01/31 14:41:56 WARN MemoryStore: Not enough space to cache rdd_12_60 in memory! (computed 35.5 MiB so far)
21/01/31 14:41:56 INFO MemoryStore: Memory use = 348.2 MiB (blocks) + 3.1 MiB (scratch space shared across 1 tasks(s)) = 351.4 MiB. Storage limit = 366.3 MiB.
21/01/31 14:41:56 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/01/31 14:41:56 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/01/31 14:41:56 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/01/31 14:41:56 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/01/31 14:41:56 INFO CodecConfig: Compression: SNAPPY
21/01/31 14:41:56 INFO CodecConfig: Compression: SNAPPY
21/01/31 14:41:56 INFO ParquetOutputFormat: Parquet block size to 134217728
21/01/31 14:41:56 INFO ParquetOutputFormat: Parquet page size to 1048576
21/01/31 14:41:56 INFO ParquetOutputFormat: Parquet dictionary page size to 1048576
21/01/31 14:41:56 INFO ParquetOutputFormat: Dictionary is on
21/01/31 14:41:56 INFO ParquetOutputFormat: Validation is off
21/01/31 14:41:56 INFO ParquetOutputFormat: Writer version is: PARQUET_1_0
21/01/31 14:41:56 INFO ParquetOutputFormat: Maximum row group padding size is 8388608 bytes
21/01/31 14:41:56 INFO ParquetOutputFormat: Page size checking is: estimated
21/01/31 14:41:56 INFO ParquetOutputFormat: Min row count for page size check is: 100
21/01/31 14:41:56 INFO ParquetOutputFormat: Max row count for page size check is: 10000
21/01/31 14:41:56 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "distributionid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "advertiserid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "distributionhourjst",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "distributiondatetime",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "requestid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "uid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "uavalue",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "uacategory",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "documentid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "documenturl",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "sitecode",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "documenttitle",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "campaignid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "campaigntype",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "publisherid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "publisherchannelid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "maxcpc",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "bidcpc",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "contractcpc",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "finalscore",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "originalscore",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "distributionorder",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "israndom",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "jobchanneltype",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "buckettype",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "predictctr",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "dt",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "isGsp",
    "type" : "boolean",
    "nullable" : false,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary distributionid (UTF8);
  optional binary advertiserid (UTF8);
  optional binary distributionhourjst (UTF8);
  optional binary distributiondatetime (UTF8);
  optional binary requestid (UTF8);
  optional binary uid (UTF8);
  optional binary uavalue (UTF8);
  optional binary uacategory (UTF8);
  optional binary documentid (UTF8);
  optional binary documenturl (UTF8);
  optional binary sitecode (UTF8);
  optional binary documenttitle (UTF8);
  optional binary campaignid (UTF8);
  optional binary campaigntype (UTF8);
  optional binary publisherid (UTF8);
  optional binary publisherchannelid (UTF8);
  optional binary maxcpc (UTF8);
  optional binary bidcpc (UTF8);
  optional binary contractcpc (UTF8);
  optional binary finalscore (UTF8);
  optional binary originalscore (UTF8);
  optional binary distributionorder (UTF8);
  optional binary israndom (UTF8);
  optional binary jobchanneltype (UTF8);
  optional binary buckettype (UTF8);
  optional binary predictctr (UTF8);
  optional binary dt (UTF8);
  required boolean isGsp;
}

       
21/01/31 14:42:00 INFO MemoryStore: Will not store rdd_12_63
21/01/31 14:42:00 WARN MemoryStore: Not enough space to cache rdd_12_63 in memory! (computed 36.3 MiB so far)
21/01/31 14:42:00 INFO MemoryStore: Memory use = 348.2 MiB (blocks) + 3.3 MiB (scratch space shared across 1 tasks(s)) = 351.5 MiB. Storage limit = 366.3 MiB.
21/01/31 14:42:00 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/01/31 14:42:00 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/01/31 14:42:00 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/01/31 14:42:00 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/01/31 14:42:00 INFO CodecConfig: Compression: SNAPPY
21/01/31 14:42:00 INFO CodecConfig: Compression: SNAPPY
21/01/31 14:42:00 INFO ParquetOutputFormat: Parquet block size to 134217728
21/01/31 14:42:00 INFO ParquetOutputFormat: Parquet page size to 1048576
21/01/31 14:42:00 INFO ParquetOutputFormat: Parquet dictionary page size to 1048576
21/01/31 14:42:00 INFO ParquetOutputFormat: Dictionary is on
21/01/31 14:42:00 INFO ParquetOutputFormat: Validation is off
21/01/31 14:42:00 INFO ParquetOutputFormat: Writer version is: PARQUET_1_0
21/01/31 14:42:00 INFO ParquetOutputFormat: Maximum row group padding size is 8388608 bytes
21/01/31 14:42:00 INFO ParquetOutputFormat: Page size checking is: estimated
21/01/31 14:42:00 INFO ParquetOutputFormat: Min row count for page size check is: 100
21/01/31 14:42:00 INFO ParquetOutputFormat: Max row count for page size check is: 10000
21/01/31 14:42:00 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "distributionid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "advertiserid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "distributionhourjst",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "distributiondatetime",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "requestid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "uid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "uavalue",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "uacategory",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "documentid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "documenturl",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "sitecode",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "documenttitle",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "campaignid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "campaigntype",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "publisherid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "publisherchannelid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "maxcpc",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "bidcpc",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "contractcpc",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "finalscore",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "originalscore",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "distributionorder",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "israndom",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "jobchanneltype",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "buckettype",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "predictctr",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "dt",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "isGsp",
    "type" : "boolean",
    "nullable" : false,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary distributionid (UTF8);
  optional binary advertiserid (UTF8);
  optional binary distributionhourjst (UTF8);
  optional binary distributiondatetime (UTF8);
  optional binary requestid (UTF8);
  optional binary uid (UTF8);
  optional binary uavalue (UTF8);
  optional binary uacategory (UTF8);
  optional binary documentid (UTF8);
  optional binary documenturl (UTF8);
  optional binary sitecode (UTF8);
  optional binary documenttitle (UTF8);
  optional binary campaignid (UTF8);
  optional binary campaigntype (UTF8);
  optional binary publisherid (UTF8);
  optional binary publisherchannelid (UTF8);
  optional binary maxcpc (UTF8);
  optional binary bidcpc (UTF8);
  optional binary contractcpc (UTF8);
  optional binary finalscore (UTF8);
  optional binary originalscore (UTF8);
  optional binary distributionorder (UTF8);
  optional binary israndom (UTF8);
  optional binary jobchanneltype (UTF8);
  optional binary buckettype (UTF8);
  optional binary predictctr (UTF8);
  optional binary dt (UTF8);
  required boolean isGsp;
}

       
21/01/31 14:42:03 INFO InternalParquetRecordWriter: Flushing mem columnStore to file. allocated memory: 37224216
21/01/31 14:42:03 INFO FileOutputCommitter: Saved output of task 'attempt_20210131143854_0001_m_000060_61' to file:/Users/kinsho/Desktop/log/_temporary/0/task_20210131143854_0001_m_000060
21/01/31 14:42:03 INFO SparkHadoopMapRedUtil: attempt_20210131143854_0001_m_000060_61: Committed
21/01/31 14:42:03 INFO Executor: Finished task 60.0 in stage 1.0 (TID 61). 2461 bytes result sent to driver
21/01/31 14:42:03 INFO CoarseGrainedExecutorBackend: Got assigned task 81
21/01/31 14:42:03 INFO Executor: Running task 80.0 in stage 1.0 (TID 81)
21/01/31 14:42:03 INFO FileScanRDD: Reading File path: file:///Users/kinsho/Desktop/impressionLog.csv, range: 10737418240-10871635968, partition values: [empty row]
21/01/31 14:42:07 INFO InternalParquetRecordWriter: Flushing mem columnStore to file. allocated memory: 36805555
21/01/31 14:42:07 INFO FileOutputCommitter: Saved output of task 'attempt_20210131143854_0001_m_000063_64' to file:/Users/kinsho/Desktop/log/_temporary/0/task_20210131143854_0001_m_000063
21/01/31 14:42:07 INFO SparkHadoopMapRedUtil: attempt_20210131143854_0001_m_000063_64: Committed
21/01/31 14:42:07 INFO Executor: Finished task 63.0 in stage 1.0 (TID 64). 2461 bytes result sent to driver
21/01/31 14:42:07 INFO CoarseGrainedExecutorBackend: Got assigned task 84
21/01/31 14:42:07 INFO Executor: Running task 83.0 in stage 1.0 (TID 84)
21/01/31 14:42:07 INFO FileScanRDD: Reading File path: file:///Users/kinsho/Desktop/impressionLog.csv, range: 11140071424-11274289152, partition values: [empty row]
21/01/31 14:42:10 INFO MemoryStore: Will not store rdd_12_80
21/01/31 14:42:10 WARN MemoryStore: Not enough space to cache rdd_12_80 in memory! (computed 35.4 MiB so far)
21/01/31 14:42:10 INFO MemoryStore: Memory use = 348.2 MiB (blocks) + 6.3 MiB (scratch space shared across 2 tasks(s)) = 354.5 MiB. Storage limit = 366.3 MiB.
21/01/31 14:42:10 WARN BlockManager: Persisting block rdd_12_80 to disk instead.
21/01/31 14:42:14 INFO MemoryStore: Will not store rdd_12_83
21/01/31 14:42:14 WARN MemoryStore: Not enough space to cache rdd_12_83 in memory! (computed 36.2 MiB so far)
21/01/31 14:42:14 INFO MemoryStore: Memory use = 348.2 MiB (blocks) + 3.2 MiB (scratch space shared across 1 tasks(s)) = 351.4 MiB. Storage limit = 366.3 MiB.
21/01/31 14:42:14 WARN BlockManager: Persisting block rdd_12_83 to disk instead.
21/01/31 14:42:34 INFO MemoryStore: Will not store rdd_12_80
21/01/31 14:42:34 WARN MemoryStore: Not enough space to cache rdd_12_80 in memory! (computed 35.4 MiB so far)
21/01/31 14:42:34 INFO MemoryStore: Memory use = 348.2 MiB (blocks) + 3.1 MiB (scratch space shared across 1 tasks(s)) = 351.4 MiB. Storage limit = 366.3 MiB.
21/01/31 14:42:34 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/01/31 14:42:34 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/01/31 14:42:34 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/01/31 14:42:34 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/01/31 14:42:34 INFO CodecConfig: Compression: SNAPPY
21/01/31 14:42:34 INFO CodecConfig: Compression: SNAPPY
21/01/31 14:42:34 INFO ParquetOutputFormat: Parquet block size to 134217728
21/01/31 14:42:34 INFO ParquetOutputFormat: Parquet page size to 1048576
21/01/31 14:42:34 INFO ParquetOutputFormat: Parquet dictionary page size to 1048576
21/01/31 14:42:34 INFO ParquetOutputFormat: Dictionary is on
21/01/31 14:42:34 INFO ParquetOutputFormat: Validation is off
21/01/31 14:42:34 INFO ParquetOutputFormat: Writer version is: PARQUET_1_0
21/01/31 14:42:34 INFO ParquetOutputFormat: Maximum row group padding size is 8388608 bytes
21/01/31 14:42:34 INFO ParquetOutputFormat: Page size checking is: estimated
21/01/31 14:42:34 INFO ParquetOutputFormat: Min row count for page size check is: 100
21/01/31 14:42:34 INFO ParquetOutputFormat: Max row count for page size check is: 10000
21/01/31 14:42:34 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "distributionid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "advertiserid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "distributionhourjst",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "distributiondatetime",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "requestid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "uid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "uavalue",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "uacategory",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "documentid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "documenturl",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "sitecode",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "documenttitle",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "campaignid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "campaigntype",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "publisherid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "publisherchannelid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "maxcpc",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "bidcpc",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "contractcpc",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "finalscore",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "originalscore",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "distributionorder",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "israndom",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "jobchanneltype",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "buckettype",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "predictctr",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "dt",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "isGsp",
    "type" : "boolean",
    "nullable" : false,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary distributionid (UTF8);
  optional binary advertiserid (UTF8);
  optional binary distributionhourjst (UTF8);
  optional binary distributiondatetime (UTF8);
  optional binary requestid (UTF8);
  optional binary uid (UTF8);
  optional binary uavalue (UTF8);
  optional binary uacategory (UTF8);
  optional binary documentid (UTF8);
  optional binary documenturl (UTF8);
  optional binary sitecode (UTF8);
  optional binary documenttitle (UTF8);
  optional binary campaignid (UTF8);
  optional binary campaigntype (UTF8);
  optional binary publisherid (UTF8);
  optional binary publisherchannelid (UTF8);
  optional binary maxcpc (UTF8);
  optional binary bidcpc (UTF8);
  optional binary contractcpc (UTF8);
  optional binary finalscore (UTF8);
  optional binary originalscore (UTF8);
  optional binary distributionorder (UTF8);
  optional binary israndom (UTF8);
  optional binary jobchanneltype (UTF8);
  optional binary buckettype (UTF8);
  optional binary predictctr (UTF8);
  optional binary dt (UTF8);
  required boolean isGsp;
}

       
21/01/31 14:42:38 INFO MemoryStore: Will not store rdd_12_83
21/01/31 14:42:38 WARN MemoryStore: Not enough space to cache rdd_12_83 in memory! (computed 36.2 MiB so far)
21/01/31 14:42:38 INFO MemoryStore: Memory use = 348.2 MiB (blocks) + 3.2 MiB (scratch space shared across 1 tasks(s)) = 351.4 MiB. Storage limit = 366.3 MiB.
21/01/31 14:42:38 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/01/31 14:42:38 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/01/31 14:42:38 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/01/31 14:42:38 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/01/31 14:42:38 INFO CodecConfig: Compression: SNAPPY
21/01/31 14:42:38 INFO CodecConfig: Compression: SNAPPY
21/01/31 14:42:38 INFO ParquetOutputFormat: Parquet block size to 134217728
21/01/31 14:42:38 INFO ParquetOutputFormat: Parquet page size to 1048576
21/01/31 14:42:38 INFO ParquetOutputFormat: Parquet dictionary page size to 1048576
21/01/31 14:42:38 INFO ParquetOutputFormat: Dictionary is on
21/01/31 14:42:38 INFO ParquetOutputFormat: Validation is off
21/01/31 14:42:38 INFO ParquetOutputFormat: Writer version is: PARQUET_1_0
21/01/31 14:42:38 INFO ParquetOutputFormat: Maximum row group padding size is 8388608 bytes
21/01/31 14:42:38 INFO ParquetOutputFormat: Page size checking is: estimated
21/01/31 14:42:38 INFO ParquetOutputFormat: Min row count for page size check is: 100
21/01/31 14:42:38 INFO ParquetOutputFormat: Max row count for page size check is: 10000
21/01/31 14:42:38 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "distributionid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "advertiserid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "distributionhourjst",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "distributiondatetime",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "requestid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "uid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "uavalue",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "uacategory",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "documentid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "documenturl",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "sitecode",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "documenttitle",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "campaignid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "campaigntype",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "publisherid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "publisherchannelid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "maxcpc",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "bidcpc",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "contractcpc",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "finalscore",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "originalscore",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "distributionorder",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "israndom",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "jobchanneltype",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "buckettype",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "predictctr",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "dt",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "isGsp",
    "type" : "boolean",
    "nullable" : false,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary distributionid (UTF8);
  optional binary advertiserid (UTF8);
  optional binary distributionhourjst (UTF8);
  optional binary distributiondatetime (UTF8);
  optional binary requestid (UTF8);
  optional binary uid (UTF8);
  optional binary uavalue (UTF8);
  optional binary uacategory (UTF8);
  optional binary documentid (UTF8);
  optional binary documenturl (UTF8);
  optional binary sitecode (UTF8);
  optional binary documenttitle (UTF8);
  optional binary campaignid (UTF8);
  optional binary campaigntype (UTF8);
  optional binary publisherid (UTF8);
  optional binary publisherchannelid (UTF8);
  optional binary maxcpc (UTF8);
  optional binary bidcpc (UTF8);
  optional binary contractcpc (UTF8);
  optional binary finalscore (UTF8);
  optional binary originalscore (UTF8);
  optional binary distributionorder (UTF8);
  optional binary israndom (UTF8);
  optional binary jobchanneltype (UTF8);
  optional binary buckettype (UTF8);
  optional binary predictctr (UTF8);
  optional binary dt (UTF8);
  required boolean isGsp;
}

       
21/01/31 14:42:40 INFO InternalParquetRecordWriter: Flushing mem columnStore to file. allocated memory: 36289996
21/01/31 14:42:41 INFO FileOutputCommitter: Saved output of task 'attempt_20210131143854_0001_m_000080_81' to file:/Users/kinsho/Desktop/log/_temporary/0/task_20210131143854_0001_m_000080
21/01/31 14:42:41 INFO SparkHadoopMapRedUtil: attempt_20210131143854_0001_m_000080_81: Committed
21/01/31 14:42:41 INFO Executor: Finished task 80.0 in stage 1.0 (TID 81). 2461 bytes result sent to driver
21/01/31 14:42:41 INFO CoarseGrainedExecutorBackend: Got assigned task 101
21/01/31 14:42:41 INFO Executor: Running task 100.0 in stage 1.0 (TID 101)
21/01/31 14:42:41 INFO FileScanRDD: Reading File path: file:///Users/kinsho/Desktop/impressionLog.csv, range: 13421772800-13555990528, partition values: [empty row]
21/01/31 14:42:44 INFO InternalParquetRecordWriter: Flushing mem columnStore to file. allocated memory: 36115141
21/01/31 14:42:45 INFO FileOutputCommitter: Saved output of task 'attempt_20210131143854_0001_m_000083_84' to file:/Users/kinsho/Desktop/log/_temporary/0/task_20210131143854_0001_m_000083
21/01/31 14:42:45 INFO SparkHadoopMapRedUtil: attempt_20210131143854_0001_m_000083_84: Committed
21/01/31 14:42:45 INFO Executor: Finished task 83.0 in stage 1.0 (TID 84). 2461 bytes result sent to driver
21/01/31 14:42:45 INFO CoarseGrainedExecutorBackend: Got assigned task 103
21/01/31 14:42:45 INFO Executor: Running task 102.0 in stage 1.0 (TID 103)
21/01/31 14:42:45 INFO FileScanRDD: Reading File path: file:///Users/kinsho/Desktop/impressionLog.csv, range: 13690208256-13824425984, partition values: [empty row]
21/01/31 14:42:48 INFO MemoryStore: Will not store rdd_12_100
21/01/31 14:42:48 WARN MemoryStore: Not enough space to cache rdd_12_100 in memory! (computed 36.2 MiB so far)
21/01/31 14:42:48 INFO MemoryStore: Memory use = 348.2 MiB (blocks) + 6.3 MiB (scratch space shared across 2 tasks(s)) = 354.5 MiB. Storage limit = 366.3 MiB.
21/01/31 14:42:48 WARN BlockManager: Persisting block rdd_12_100 to disk instead.
21/01/31 14:42:52 INFO MemoryStore: Will not store rdd_12_102
21/01/31 14:42:52 WARN MemoryStore: Not enough space to cache rdd_12_102 in memory! (computed 35.3 MiB so far)
21/01/31 14:42:52 INFO MemoryStore: Memory use = 348.2 MiB (blocks) + 3.0 MiB (scratch space shared across 1 tasks(s)) = 351.2 MiB. Storage limit = 366.3 MiB.
21/01/31 14:42:52 WARN BlockManager: Persisting block rdd_12_102 to disk instead.
21/01/31 14:43:17 INFO MemoryStore: Will not store rdd_12_100
21/01/31 14:43:17 WARN MemoryStore: Not enough space to cache rdd_12_100 in memory! (computed 36.2 MiB so far)
21/01/31 14:43:17 INFO MemoryStore: Memory use = 348.2 MiB (blocks) + 3.3 MiB (scratch space shared across 1 tasks(s)) = 351.5 MiB. Storage limit = 366.3 MiB.
21/01/31 14:43:17 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/01/31 14:43:17 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/01/31 14:43:17 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/01/31 14:43:17 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/01/31 14:43:17 INFO CodecConfig: Compression: SNAPPY
21/01/31 14:43:17 INFO CodecConfig: Compression: SNAPPY
21/01/31 14:43:17 INFO ParquetOutputFormat: Parquet block size to 134217728
21/01/31 14:43:17 INFO ParquetOutputFormat: Parquet page size to 1048576
21/01/31 14:43:17 INFO ParquetOutputFormat: Parquet dictionary page size to 1048576
21/01/31 14:43:17 INFO ParquetOutputFormat: Dictionary is on
21/01/31 14:43:17 INFO ParquetOutputFormat: Validation is off
21/01/31 14:43:17 INFO ParquetOutputFormat: Writer version is: PARQUET_1_0
21/01/31 14:43:17 INFO ParquetOutputFormat: Maximum row group padding size is 8388608 bytes
21/01/31 14:43:17 INFO ParquetOutputFormat: Page size checking is: estimated
21/01/31 14:43:17 INFO ParquetOutputFormat: Min row count for page size check is: 100
21/01/31 14:43:17 INFO ParquetOutputFormat: Max row count for page size check is: 10000
21/01/31 14:43:17 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "distributionid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "advertiserid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "distributionhourjst",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "distributiondatetime",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "requestid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "uid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "uavalue",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "uacategory",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "documentid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "documenturl",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "sitecode",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "documenttitle",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "campaignid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "campaigntype",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "publisherid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "publisherchannelid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "maxcpc",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "bidcpc",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "contractcpc",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "finalscore",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "originalscore",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "distributionorder",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "israndom",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "jobchanneltype",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "buckettype",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "predictctr",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "dt",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "isGsp",
    "type" : "boolean",
    "nullable" : false,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary distributionid (UTF8);
  optional binary advertiserid (UTF8);
  optional binary distributionhourjst (UTF8);
  optional binary distributiondatetime (UTF8);
  optional binary requestid (UTF8);
  optional binary uid (UTF8);
  optional binary uavalue (UTF8);
  optional binary uacategory (UTF8);
  optional binary documentid (UTF8);
  optional binary documenturl (UTF8);
  optional binary sitecode (UTF8);
  optional binary documenttitle (UTF8);
  optional binary campaignid (UTF8);
  optional binary campaigntype (UTF8);
  optional binary publisherid (UTF8);
  optional binary publisherchannelid (UTF8);
  optional binary maxcpc (UTF8);
  optional binary bidcpc (UTF8);
  optional binary contractcpc (UTF8);
  optional binary finalscore (UTF8);
  optional binary originalscore (UTF8);
  optional binary distributionorder (UTF8);
  optional binary israndom (UTF8);
  optional binary jobchanneltype (UTF8);
  optional binary buckettype (UTF8);
  optional binary predictctr (UTF8);
  optional binary dt (UTF8);
  required boolean isGsp;
}

       
21/01/31 14:43:20 INFO MemoryStore: Will not store rdd_12_102
21/01/31 14:43:20 WARN MemoryStore: Not enough space to cache rdd_12_102 in memory! (computed 35.3 MiB so far)
21/01/31 14:43:20 INFO MemoryStore: Memory use = 348.2 MiB (blocks) + 3.0 MiB (scratch space shared across 1 tasks(s)) = 351.2 MiB. Storage limit = 366.3 MiB.
21/01/31 14:43:20 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/01/31 14:43:20 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/01/31 14:43:20 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/01/31 14:43:20 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/01/31 14:43:20 INFO CodecConfig: Compression: SNAPPY
21/01/31 14:43:20 INFO CodecConfig: Compression: SNAPPY
21/01/31 14:43:20 INFO ParquetOutputFormat: Parquet block size to 134217728
21/01/31 14:43:20 INFO ParquetOutputFormat: Parquet page size to 1048576
21/01/31 14:43:20 INFO ParquetOutputFormat: Parquet dictionary page size to 1048576
21/01/31 14:43:20 INFO ParquetOutputFormat: Dictionary is on
21/01/31 14:43:20 INFO ParquetOutputFormat: Validation is off
21/01/31 14:43:20 INFO ParquetOutputFormat: Writer version is: PARQUET_1_0
21/01/31 14:43:20 INFO ParquetOutputFormat: Maximum row group padding size is 8388608 bytes
21/01/31 14:43:20 INFO ParquetOutputFormat: Page size checking is: estimated
21/01/31 14:43:20 INFO ParquetOutputFormat: Min row count for page size check is: 100
21/01/31 14:43:20 INFO ParquetOutputFormat: Max row count for page size check is: 10000
21/01/31 14:43:20 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "distributionid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "advertiserid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "distributionhourjst",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "distributiondatetime",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "requestid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "uid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "uavalue",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "uacategory",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "documentid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "documenturl",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "sitecode",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "documenttitle",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "campaignid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "campaigntype",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "publisherid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "publisherchannelid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "maxcpc",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "bidcpc",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "contractcpc",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "finalscore",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "originalscore",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "distributionorder",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "israndom",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "jobchanneltype",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "buckettype",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "predictctr",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "dt",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "isGsp",
    "type" : "boolean",
    "nullable" : false,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary distributionid (UTF8);
  optional binary advertiserid (UTF8);
  optional binary distributionhourjst (UTF8);
  optional binary distributiondatetime (UTF8);
  optional binary requestid (UTF8);
  optional binary uid (UTF8);
  optional binary uavalue (UTF8);
  optional binary uacategory (UTF8);
  optional binary documentid (UTF8);
  optional binary documenturl (UTF8);
  optional binary sitecode (UTF8);
  optional binary documenttitle (UTF8);
  optional binary campaignid (UTF8);
  optional binary campaigntype (UTF8);
  optional binary publisherid (UTF8);
  optional binary publisherchannelid (UTF8);
  optional binary maxcpc (UTF8);
  optional binary bidcpc (UTF8);
  optional binary contractcpc (UTF8);
  optional binary finalscore (UTF8);
  optional binary originalscore (UTF8);
  optional binary distributionorder (UTF8);
  optional binary israndom (UTF8);
  optional binary jobchanneltype (UTF8);
  optional binary buckettype (UTF8);
  optional binary predictctr (UTF8);
  optional binary dt (UTF8);
  required boolean isGsp;
}

       
21/01/31 14:43:24 INFO InternalParquetRecordWriter: Flushing mem columnStore to file. allocated memory: 35252637
21/01/31 14:43:24 INFO FileOutputCommitter: Saved output of task 'attempt_20210131143854_0001_m_000100_101' to file:/Users/kinsho/Desktop/log/_temporary/0/task_20210131143854_0001_m_000100
21/01/31 14:43:24 INFO SparkHadoopMapRedUtil: attempt_20210131143854_0001_m_000100_101: Committed
21/01/31 14:43:24 INFO Executor: Finished task 100.0 in stage 1.0 (TID 101). 2461 bytes result sent to driver
21/01/31 14:43:24 INFO CoarseGrainedExecutorBackend: Got assigned task 121
21/01/31 14:43:24 INFO Executor: Running task 120.0 in stage 1.0 (TID 121)
21/01/31 14:43:24 INFO FileScanRDD: Reading File path: file:///Users/kinsho/Desktop/impressionLog.csv, range: 16106127360-16240345088, partition values: [empty row]
21/01/31 14:43:27 INFO InternalParquetRecordWriter: Flushing mem columnStore to file. allocated memory: 35684300
21/01/31 14:43:28 INFO FileOutputCommitter: Saved output of task 'attempt_20210131143854_0001_m_000102_103' to file:/Users/kinsho/Desktop/log/_temporary/0/task_20210131143854_0001_m_000102
21/01/31 14:43:28 INFO SparkHadoopMapRedUtil: attempt_20210131143854_0001_m_000102_103: Committed
21/01/31 14:43:28 INFO Executor: Finished task 102.0 in stage 1.0 (TID 103). 2461 bytes result sent to driver
21/01/31 14:43:28 INFO CoarseGrainedExecutorBackend: Got assigned task 123
21/01/31 14:43:28 INFO Executor: Running task 122.0 in stage 1.0 (TID 123)
21/01/31 14:43:28 INFO FileScanRDD: Reading File path: file:///Users/kinsho/Desktop/impressionLog.csv, range: 16374562816-16508780544, partition values: [empty row]
21/01/31 14:43:32 INFO MemoryStore: Will not store rdd_12_120
21/01/31 14:43:32 WARN MemoryStore: Not enough space to cache rdd_12_120 in memory! (computed 35.5 MiB so far)
21/01/31 14:43:32 INFO MemoryStore: Memory use = 348.2 MiB (blocks) + 6.2 MiB (scratch space shared across 2 tasks(s)) = 354.4 MiB. Storage limit = 366.3 MiB.
21/01/31 14:43:32 WARN BlockManager: Persisting block rdd_12_120 to disk instead.
21/01/31 14:43:36 INFO MemoryStore: Will not store rdd_12_122
21/01/31 14:43:36 WARN MemoryStore: Not enough space to cache rdd_12_122 in memory! (computed 34.6 MiB so far)
21/01/31 14:43:36 INFO MemoryStore: Memory use = 348.2 MiB (blocks) + 3.0 MiB (scratch space shared across 1 tasks(s)) = 351.2 MiB. Storage limit = 366.3 MiB.
21/01/31 14:43:36 WARN BlockManager: Persisting block rdd_12_122 to disk instead.
21/01/31 14:44:04 INFO MemoryStore: Will not store rdd_12_120
21/01/31 14:44:04 WARN MemoryStore: Not enough space to cache rdd_12_120 in memory! (computed 35.5 MiB so far)
21/01/31 14:44:04 INFO MemoryStore: Memory use = 348.2 MiB (blocks) + 3.2 MiB (scratch space shared across 1 tasks(s)) = 351.5 MiB. Storage limit = 366.3 MiB.
21/01/31 14:44:04 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/01/31 14:44:04 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/01/31 14:44:04 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/01/31 14:44:04 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/01/31 14:44:04 INFO CodecConfig: Compression: SNAPPY
21/01/31 14:44:04 INFO CodecConfig: Compression: SNAPPY
21/01/31 14:44:04 INFO ParquetOutputFormat: Parquet block size to 134217728
21/01/31 14:44:04 INFO ParquetOutputFormat: Parquet page size to 1048576
21/01/31 14:44:04 INFO ParquetOutputFormat: Parquet dictionary page size to 1048576
21/01/31 14:44:04 INFO ParquetOutputFormat: Dictionary is on
21/01/31 14:44:04 INFO ParquetOutputFormat: Validation is off
21/01/31 14:44:04 INFO ParquetOutputFormat: Writer version is: PARQUET_1_0
21/01/31 14:44:04 INFO ParquetOutputFormat: Maximum row group padding size is 8388608 bytes
21/01/31 14:44:04 INFO ParquetOutputFormat: Page size checking is: estimated
21/01/31 14:44:04 INFO ParquetOutputFormat: Min row count for page size check is: 100
21/01/31 14:44:04 INFO ParquetOutputFormat: Max row count for page size check is: 10000
21/01/31 14:44:04 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "distributionid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "advertiserid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "distributionhourjst",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "distributiondatetime",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "requestid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "uid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "uavalue",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "uacategory",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "documentid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "documenturl",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "sitecode",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "documenttitle",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "campaignid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "campaigntype",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "publisherid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "publisherchannelid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "maxcpc",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "bidcpc",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "contractcpc",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "finalscore",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "originalscore",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "distributionorder",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "israndom",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "jobchanneltype",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "buckettype",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "predictctr",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "dt",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "isGsp",
    "type" : "boolean",
    "nullable" : false,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary distributionid (UTF8);
  optional binary advertiserid (UTF8);
  optional binary distributionhourjst (UTF8);
  optional binary distributiondatetime (UTF8);
  optional binary requestid (UTF8);
  optional binary uid (UTF8);
  optional binary uavalue (UTF8);
  optional binary uacategory (UTF8);
  optional binary documentid (UTF8);
  optional binary documenturl (UTF8);
  optional binary sitecode (UTF8);
  optional binary documenttitle (UTF8);
  optional binary campaignid (UTF8);
  optional binary campaigntype (UTF8);
  optional binary publisherid (UTF8);
  optional binary publisherchannelid (UTF8);
  optional binary maxcpc (UTF8);
  optional binary bidcpc (UTF8);
  optional binary contractcpc (UTF8);
  optional binary finalscore (UTF8);
  optional binary originalscore (UTF8);
  optional binary distributionorder (UTF8);
  optional binary israndom (UTF8);
  optional binary jobchanneltype (UTF8);
  optional binary buckettype (UTF8);
  optional binary predictctr (UTF8);
  optional binary dt (UTF8);
  required boolean isGsp;
}

       
21/01/31 14:44:07 INFO MemoryStore: Will not store rdd_12_122
21/01/31 14:44:07 WARN MemoryStore: Not enough space to cache rdd_12_122 in memory! (computed 34.6 MiB so far)
21/01/31 14:44:07 INFO MemoryStore: Memory use = 348.2 MiB (blocks) + 3.0 MiB (scratch space shared across 1 tasks(s)) = 351.2 MiB. Storage limit = 366.3 MiB.
21/01/31 14:44:07 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/01/31 14:44:07 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/01/31 14:44:07 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/01/31 14:44:07 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/01/31 14:44:07 INFO CodecConfig: Compression: SNAPPY
21/01/31 14:44:07 INFO CodecConfig: Compression: SNAPPY
21/01/31 14:44:07 INFO ParquetOutputFormat: Parquet block size to 134217728
21/01/31 14:44:07 INFO ParquetOutputFormat: Parquet page size to 1048576
21/01/31 14:44:07 INFO ParquetOutputFormat: Parquet dictionary page size to 1048576
21/01/31 14:44:07 INFO ParquetOutputFormat: Dictionary is on
21/01/31 14:44:07 INFO ParquetOutputFormat: Validation is off
21/01/31 14:44:07 INFO ParquetOutputFormat: Writer version is: PARQUET_1_0
21/01/31 14:44:07 INFO ParquetOutputFormat: Maximum row group padding size is 8388608 bytes
21/01/31 14:44:07 INFO ParquetOutputFormat: Page size checking is: estimated
21/01/31 14:44:07 INFO ParquetOutputFormat: Min row count for page size check is: 100
21/01/31 14:44:07 INFO ParquetOutputFormat: Max row count for page size check is: 10000
21/01/31 14:44:07 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "distributionid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "advertiserid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "distributionhourjst",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "distributiondatetime",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "requestid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "uid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "uavalue",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "uacategory",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "documentid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "documenturl",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "sitecode",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "documenttitle",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "campaignid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "campaigntype",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "publisherid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "publisherchannelid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "maxcpc",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "bidcpc",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "contractcpc",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "finalscore",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "originalscore",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "distributionorder",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "israndom",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "jobchanneltype",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "buckettype",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "predictctr",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "dt",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "isGsp",
    "type" : "boolean",
    "nullable" : false,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary distributionid (UTF8);
  optional binary advertiserid (UTF8);
  optional binary distributionhourjst (UTF8);
  optional binary distributiondatetime (UTF8);
  optional binary requestid (UTF8);
  optional binary uid (UTF8);
  optional binary uavalue (UTF8);
  optional binary uacategory (UTF8);
  optional binary documentid (UTF8);
  optional binary documenturl (UTF8);
  optional binary sitecode (UTF8);
  optional binary documenttitle (UTF8);
  optional binary campaignid (UTF8);
  optional binary campaigntype (UTF8);
  optional binary publisherid (UTF8);
  optional binary publisherchannelid (UTF8);
  optional binary maxcpc (UTF8);
  optional binary bidcpc (UTF8);
  optional binary contractcpc (UTF8);
  optional binary finalscore (UTF8);
  optional binary originalscore (UTF8);
  optional binary distributionorder (UTF8);
  optional binary israndom (UTF8);
  optional binary jobchanneltype (UTF8);
  optional binary buckettype (UTF8);
  optional binary predictctr (UTF8);
  optional binary dt (UTF8);
  required boolean isGsp;
}

       
21/01/31 14:44:10 INFO InternalParquetRecordWriter: Flushing mem columnStore to file. allocated memory: 35456272
21/01/31 14:44:10 INFO FileOutputCommitter: Saved output of task 'attempt_20210131143854_0001_m_000120_121' to file:/Users/kinsho/Desktop/log/_temporary/0/task_20210131143854_0001_m_000120
21/01/31 14:44:10 INFO SparkHadoopMapRedUtil: attempt_20210131143854_0001_m_000120_121: Committed
21/01/31 14:44:10 INFO Executor: Finished task 120.0 in stage 1.0 (TID 121). 2461 bytes result sent to driver
21/01/31 14:44:10 INFO CoarseGrainedExecutorBackend: Got assigned task 141
21/01/31 14:44:10 INFO Executor: Running task 140.0 in stage 1.0 (TID 141)
21/01/31 14:44:10 INFO FileScanRDD: Reading File path: file:///Users/kinsho/Desktop/impressionLog.csv, range: 18790481920-18924699648, partition values: [empty row]
21/01/31 14:44:13 INFO InternalParquetRecordWriter: Flushing mem columnStore to file. allocated memory: 35219002
21/01/31 14:45:26 INFO MemoryStore: Will not store rdd_12_140
21/01/31 14:45:26 WARN MemoryStore: Not enough space to cache rdd_12_140 in memory! (computed 36.4 MiB so far)
21/01/31 14:45:26 INFO MemoryStore: Memory use = 348.2 MiB (blocks) + 3.2 MiB (scratch space shared across 1 tasks(s)) = 351.5 MiB. Storage limit = 366.3 MiB.
21/01/31 14:45:26 WARN BlockManager: Persisting block rdd_12_140 to disk instead.
21/01/31 14:45:31 WARN Executor: Issue communicating with driver in heartbeater
org.apache.spark.rpc.RpcTimeoutException: Futures timed out after [10000 milliseconds]. This timeout is controlled by spark.executor.heartbeatInterval
	at org.apache.spark.rpc.RpcTimeout.org$apache$spark$rpc$RpcTimeout$$createRpcTimeoutException(RpcTimeout.scala:47)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:62)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:58)
	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:38)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:76)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)
	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:913)
	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:200)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1932)
	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.util.concurrent.TimeoutException: Futures timed out after [10000 milliseconds]
	at scala.concurrent.impl.Promise$DefaultPromise.ready(Promise.scala:259)
	at scala.concurrent.impl.Promise$DefaultPromise.result(Promise.scala:263)
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:294)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	... 13 more
21/01/31 14:45:38 WARN TransportResponseHandler: Ignoring response for RPC 7395591973333654455 from /192.168.11.7:57817 (81 bytes) since it is not outstanding
21/01/31 14:45:38 INFO Executor: Told to re-register on heartbeat
21/01/31 14:45:38 INFO CoarseGrainedExecutorBackend: Driver commanded a shutdown
21/01/31 14:45:38 INFO BlockManager: BlockManager BlockManagerId(8, 192.168.11.7, 57880, None) re-registering with master
21/01/31 14:45:38 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(8, 192.168.11.7, 57880, None)
21/01/31 14:45:38 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(8, 192.168.11.7, 57880, None)
21/01/31 14:45:38 INFO BlockManager: Reporting 19 blocks to the master.
