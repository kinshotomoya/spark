Spark Executor Command: "/Library/Java/JavaVirtualMachines/adoptopenjdk-8.jdk/Contents/Home/jre/bin/java" "-cp" "/Users/kinsho/workspace/spark-3.0.1/conf/:/Users/kinsho/workspace/spark-3.0.1/assembly/target/scala-2.12/jars/*" "-Xmx1024M" "-Dspark.driver.port=57817" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@192.168.11.7:57817" "--executor-id" "4" "--hostname" "192.168.11.7" "--cores" "2" "--app-id" "app-20210131143845-0032" "--worker-url" "spark://Worker@192.168.11.7:63944"
========================================

Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
21/01/31 14:38:47 INFO CoarseGrainedExecutorBackend: Started daemon with process name: 28707@ST000000035
21/01/31 14:38:47 INFO SignalUtils: Registered signal handler for TERM
21/01/31 14:38:47 INFO SignalUtils: Registered signal handler for HUP
21/01/31 14:38:47 INFO SignalUtils: Registered signal handler for INT
21/01/31 14:38:48 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
21/01/31 14:38:48 INFO SecurityManager: Changing view acls to: kinsho
21/01/31 14:38:48 INFO SecurityManager: Changing modify acls to: kinsho
21/01/31 14:38:48 INFO SecurityManager: Changing view acls groups to: 
21/01/31 14:38:48 INFO SecurityManager: Changing modify acls groups to: 
21/01/31 14:38:48 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(kinsho); groups with view permissions: Set(); users  with modify permissions: Set(kinsho); groups with modify permissions: Set()
21/01/31 14:38:49 INFO TransportClientFactory: Successfully created connection to /192.168.11.7:57817 after 107 ms (0 ms spent in bootstraps)
21/01/31 14:38:49 INFO SecurityManager: Changing view acls to: kinsho
21/01/31 14:38:49 INFO SecurityManager: Changing modify acls to: kinsho
21/01/31 14:38:49 INFO SecurityManager: Changing view acls groups to: 
21/01/31 14:38:49 INFO SecurityManager: Changing modify acls groups to: 
21/01/31 14:38:49 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(kinsho); groups with view permissions: Set(); users  with modify permissions: Set(kinsho); groups with modify permissions: Set()
21/01/31 14:38:49 INFO TransportClientFactory: Successfully created connection to /192.168.11.7:57817 after 2 ms (0 ms spent in bootstraps)
21/01/31 14:38:49 INFO DiskBlockManager: Created local directory at /private/var/folders/tm/7v5m6cg144g467bsj7zgsxgc0000gn/T/spark-b22e2ad3-deb4-457b-874f-8b2b4492df5b/executor-e139f6de-5d3a-40a8-ad09-9e9cdce2621b/blockmgr-7fbc8611-436c-4d45-a449-0ddd2b6afdfa
21/01/31 14:38:49 INFO MemoryStore: MemoryStore started with capacity 366.3 MiB
21/01/31 14:38:50 INFO CoarseGrainedExecutorBackend: Connecting to driver: spark://CoarseGrainedScheduler@192.168.11.7:57817
21/01/31 14:38:50 INFO WorkerWatcher: Connecting to worker spark://Worker@192.168.11.7:63944
21/01/31 14:38:50 INFO TransportClientFactory: Successfully created connection to /192.168.11.7:63944 after 3 ms (0 ms spent in bootstraps)
21/01/31 14:38:50 INFO WorkerWatcher: Successfully connected to spark://Worker@192.168.11.7:63944
21/01/31 14:38:50 INFO ResourceUtils: ==============================================================
21/01/31 14:38:50 INFO ResourceUtils: Resources for spark.executor:

21/01/31 14:38:50 INFO ResourceUtils: ==============================================================
21/01/31 14:38:50 INFO CoarseGrainedExecutorBackend: Successfully registered with driver
21/01/31 14:38:50 INFO Executor: Starting executor ID 4 on host 192.168.11.7
21/01/31 14:38:50 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 57872.
21/01/31 14:38:50 INFO NettyBlockTransferService: Server created on 192.168.11.7:57872
21/01/31 14:38:50 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
21/01/31 14:38:50 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(4, 192.168.11.7, 57872, None)
21/01/31 14:38:50 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(4, 192.168.11.7, 57872, None)
21/01/31 14:38:50 INFO BlockManager: Initialized BlockManager: BlockManagerId(4, 192.168.11.7, 57872, None)
21/01/31 14:38:54 INFO CoarseGrainedExecutorBackend: Got assigned task 7
21/01/31 14:38:54 INFO CoarseGrainedExecutorBackend: Got assigned task 17
21/01/31 14:38:54 INFO Executor: Running task 6.0 in stage 1.0 (TID 7)
21/01/31 14:38:54 INFO Executor: Running task 16.0 in stage 1.0 (TID 17)
21/01/31 14:38:54 INFO Executor: Fetching spark://192.168.11.7:57817/jars/simple-project_2.12-1.0.jar with timestamp 1612071524858
21/01/31 14:38:54 INFO TransportClientFactory: Successfully created connection to /192.168.11.7:57817 after 2 ms (0 ms spent in bootstraps)
21/01/31 14:38:54 INFO Utils: Fetching spark://192.168.11.7:57817/jars/simple-project_2.12-1.0.jar to /private/var/folders/tm/7v5m6cg144g467bsj7zgsxgc0000gn/T/spark-b22e2ad3-deb4-457b-874f-8b2b4492df5b/executor-e139f6de-5d3a-40a8-ad09-9e9cdce2621b/spark-16c91410-52d2-4a6b-a083-f74822b937da/fetchFileTemp1260735495275510917.tmp
21/01/31 14:38:54 INFO Utils: Copying /private/var/folders/tm/7v5m6cg144g467bsj7zgsxgc0000gn/T/spark-b22e2ad3-deb4-457b-874f-8b2b4492df5b/executor-e139f6de-5d3a-40a8-ad09-9e9cdce2621b/spark-16c91410-52d2-4a6b-a083-f74822b937da/15175652501612071524858_cache to /Users/kinsho/workspace/spark-3.0.1/work/app-20210131143845-0032/4/./simple-project_2.12-1.0.jar
21/01/31 14:38:55 INFO Executor: Adding file:/Users/kinsho/workspace/spark-3.0.1/work/app-20210131143845-0032/4/./simple-project_2.12-1.0.jar to class loader
21/01/31 14:38:55 INFO TorrentBroadcast: Started reading broadcast variable 4 with 1 pieces (estimated total size 4.0 MiB)
21/01/31 14:38:55 INFO TransportClientFactory: Successfully created connection to /192.168.11.7:57881 after 8 ms (0 ms spent in bootstraps)
21/01/31 14:38:55 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 68.7 KiB, free 366.2 MiB)
21/01/31 14:38:55 INFO TorrentBroadcast: Reading broadcast variable 4 took 409 ms
21/01/31 14:38:56 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 193.8 KiB, free 366.0 MiB)
21/01/31 14:38:57 INFO FileScanRDD: Reading File path: file:///Users/kinsho/Desktop/impressionLog.csv, range: 2147483648-2281701376, partition values: [empty row]
21/01/31 14:38:57 INFO FileScanRDD: Reading File path: file:///Users/kinsho/Desktop/impressionLog.csv, range: 805306368-939524096, partition values: [empty row]
21/01/31 14:39:00 INFO CodeGenerator: Code generated in 1108.664973 ms
21/01/31 14:39:00 INFO TorrentBroadcast: Started reading broadcast variable 3 with 1 pieces (estimated total size 4.0 MiB)
21/01/31 14:39:00 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 24.0 KiB, free 366.0 MiB)
21/01/31 14:39:00 INFO TorrentBroadcast: Reading broadcast variable 3 took 16 ms
21/01/31 14:39:00 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 336.8 KiB, free 365.7 MiB)
21/01/31 14:39:30 INFO MemoryStore: Will not store rdd_12_16
21/01/31 14:39:30 WARN MemoryStore: Not enough space to cache rdd_12_16 in memory! (computed 134.3 MiB so far)
21/01/31 14:39:30 INFO MemoryStore: Memory use = 623.3 KiB (blocks) + 309.3 MiB (scratch space shared across 2 tasks(s)) = 309.9 MiB. Storage limit = 366.3 MiB.
21/01/31 14:39:30 WARN BlockManager: Persisting block rdd_12_16 to disk instead.
21/01/31 14:39:35 INFO MemoryStore: Block rdd_12_6 stored as values in memory (estimated size 165.3 MiB, free 200.4 MiB)
21/01/31 14:39:35 INFO CodeGenerator: Code generated in 38.743365 ms
21/01/31 14:39:35 INFO CodeGenerator: Code generated in 130.546821 ms
21/01/31 14:39:35 INFO CodeGenerator: Code generated in 108.770007 ms
21/01/31 14:39:35 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/01/31 14:39:35 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/01/31 14:39:35 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/01/31 14:39:35 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/01/31 14:39:35 INFO CodecConfig: Compression: SNAPPY
21/01/31 14:39:35 INFO CodecConfig: Compression: SNAPPY
21/01/31 14:39:35 INFO ParquetOutputFormat: Parquet block size to 134217728
21/01/31 14:39:35 INFO ParquetOutputFormat: Parquet page size to 1048576
21/01/31 14:39:35 INFO ParquetOutputFormat: Parquet dictionary page size to 1048576
21/01/31 14:39:35 INFO ParquetOutputFormat: Dictionary is on
21/01/31 14:39:35 INFO ParquetOutputFormat: Validation is off
21/01/31 14:39:35 INFO ParquetOutputFormat: Writer version is: PARQUET_1_0
21/01/31 14:39:35 INFO ParquetOutputFormat: Maximum row group padding size is 8388608 bytes
21/01/31 14:39:35 INFO ParquetOutputFormat: Page size checking is: estimated
21/01/31 14:39:35 INFO ParquetOutputFormat: Min row count for page size check is: 100
21/01/31 14:39:35 INFO ParquetOutputFormat: Max row count for page size check is: 10000
21/01/31 14:39:36 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "distributionid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "advertiserid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "distributionhourjst",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "distributiondatetime",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "requestid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "uid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "uavalue",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "uacategory",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "documentid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "documenturl",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "sitecode",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "documenttitle",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "campaignid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "campaigntype",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "publisherid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "publisherchannelid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "maxcpc",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "bidcpc",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "contractcpc",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "finalscore",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "originalscore",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "distributionorder",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "israndom",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "jobchanneltype",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "buckettype",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "predictctr",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "dt",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "isGsp",
    "type" : "boolean",
    "nullable" : false,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary distributionid (UTF8);
  optional binary advertiserid (UTF8);
  optional binary distributionhourjst (UTF8);
  optional binary distributiondatetime (UTF8);
  optional binary requestid (UTF8);
  optional binary uid (UTF8);
  optional binary uavalue (UTF8);
  optional binary uacategory (UTF8);
  optional binary documentid (UTF8);
  optional binary documenturl (UTF8);
  optional binary sitecode (UTF8);
  optional binary documenttitle (UTF8);
  optional binary campaignid (UTF8);
  optional binary campaigntype (UTF8);
  optional binary publisherid (UTF8);
  optional binary publisherchannelid (UTF8);
  optional binary maxcpc (UTF8);
  optional binary bidcpc (UTF8);
  optional binary contractcpc (UTF8);
  optional binary finalscore (UTF8);
  optional binary originalscore (UTF8);
  optional binary distributionorder (UTF8);
  optional binary israndom (UTF8);
  optional binary jobchanneltype (UTF8);
  optional binary buckettype (UTF8);
  optional binary predictctr (UTF8);
  optional binary dt (UTF8);
  required boolean isGsp;
}

       
21/01/31 14:39:36 INFO CodecPool: Got brand-new compressor [.snappy]
21/01/31 14:39:47 INFO MemoryStore: Will not store rdd_12_16
21/01/31 14:39:47 WARN MemoryStore: Not enough space to cache rdd_12_16 in memory! (computed 134.3 MiB so far)
21/01/31 14:39:47 INFO MemoryStore: Memory use = 165.9 MiB (blocks) + 102.3 MiB (scratch space shared across 1 tasks(s)) = 268.2 MiB. Storage limit = 366.3 MiB.
21/01/31 14:39:47 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/01/31 14:39:47 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/01/31 14:39:47 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/01/31 14:39:47 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/01/31 14:39:47 INFO CodecConfig: Compression: SNAPPY
21/01/31 14:39:47 INFO CodecConfig: Compression: SNAPPY
21/01/31 14:39:47 INFO ParquetOutputFormat: Parquet block size to 134217728
21/01/31 14:39:47 INFO ParquetOutputFormat: Parquet page size to 1048576
21/01/31 14:39:47 INFO ParquetOutputFormat: Parquet dictionary page size to 1048576
21/01/31 14:39:47 INFO ParquetOutputFormat: Dictionary is on
21/01/31 14:39:47 INFO ParquetOutputFormat: Validation is off
21/01/31 14:39:47 INFO ParquetOutputFormat: Writer version is: PARQUET_1_0
21/01/31 14:39:47 INFO ParquetOutputFormat: Maximum row group padding size is 8388608 bytes
21/01/31 14:39:47 INFO ParquetOutputFormat: Page size checking is: estimated
21/01/31 14:39:47 INFO ParquetOutputFormat: Min row count for page size check is: 100
21/01/31 14:39:47 INFO ParquetOutputFormat: Max row count for page size check is: 10000
21/01/31 14:39:47 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "distributionid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "advertiserid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "distributionhourjst",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "distributiondatetime",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "requestid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "uid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "uavalue",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "uacategory",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "documentid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "documenturl",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "sitecode",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "documenttitle",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "campaignid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "campaigntype",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "publisherid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "publisherchannelid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "maxcpc",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "bidcpc",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "contractcpc",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "finalscore",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "originalscore",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "distributionorder",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "israndom",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "jobchanneltype",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "buckettype",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "predictctr",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "dt",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "isGsp",
    "type" : "boolean",
    "nullable" : false,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary distributionid (UTF8);
  optional binary advertiserid (UTF8);
  optional binary distributionhourjst (UTF8);
  optional binary distributiondatetime (UTF8);
  optional binary requestid (UTF8);
  optional binary uid (UTF8);
  optional binary uavalue (UTF8);
  optional binary uacategory (UTF8);
  optional binary documentid (UTF8);
  optional binary documenturl (UTF8);
  optional binary sitecode (UTF8);
  optional binary documenttitle (UTF8);
  optional binary campaignid (UTF8);
  optional binary campaigntype (UTF8);
  optional binary publisherid (UTF8);
  optional binary publisherchannelid (UTF8);
  optional binary maxcpc (UTF8);
  optional binary bidcpc (UTF8);
  optional binary contractcpc (UTF8);
  optional binary finalscore (UTF8);
  optional binary originalscore (UTF8);
  optional binary distributionorder (UTF8);
  optional binary israndom (UTF8);
  optional binary jobchanneltype (UTF8);
  optional binary buckettype (UTF8);
  optional binary predictctr (UTF8);
  optional binary dt (UTF8);
  required boolean isGsp;
}

       
21/01/31 14:39:47 INFO CodecPool: Got brand-new compressor [.snappy]
21/01/31 14:39:49 INFO InternalParquetRecordWriter: Flushing mem columnStore to file. allocated memory: 38170915
21/01/31 14:39:49 INFO FileOutputCommitter: Saved output of task 'attempt_20210131143854_0001_m_000006_7' to file:/Users/kinsho/Desktop/log/_temporary/0/task_20210131143854_0001_m_000006
21/01/31 14:39:49 INFO SparkHadoopMapRedUtil: attempt_20210131143854_0001_m_000006_7: Committed
21/01/31 14:39:49 INFO Executor: Finished task 6.0 in stage 1.0 (TID 7). 2504 bytes result sent to driver
21/01/31 14:39:49 INFO CoarseGrainedExecutorBackend: Got assigned task 25
21/01/31 14:39:49 INFO Executor: Running task 24.0 in stage 1.0 (TID 25)
21/01/31 14:39:49 INFO FileScanRDD: Reading File path: file:///Users/kinsho/Desktop/impressionLog.csv, range: 3221225472-3355443200, partition values: [empty row]
21/01/31 14:39:56 INFO InternalParquetRecordWriter: Flushing mem columnStore to file. allocated memory: 42854867
21/01/31 14:39:57 INFO FileOutputCommitter: Saved output of task 'attempt_20210131143854_0001_m_000016_17' to file:/Users/kinsho/Desktop/log/_temporary/0/task_20210131143854_0001_m_000016
21/01/31 14:39:57 INFO SparkHadoopMapRedUtil: attempt_20210131143854_0001_m_000016_17: Committed
21/01/31 14:39:57 INFO Executor: Finished task 16.0 in stage 1.0 (TID 17). 2461 bytes result sent to driver
21/01/31 14:39:57 INFO CoarseGrainedExecutorBackend: Got assigned task 37
21/01/31 14:39:57 INFO Executor: Running task 36.0 in stage 1.0 (TID 37)
21/01/31 14:39:57 INFO FileScanRDD: Reading File path: file:///Users/kinsho/Desktop/impressionLog.csv, range: 4831838208-4966055936, partition values: [empty row]
21/01/31 14:40:12 INFO MemoryStore: Will not store rdd_12_36
21/01/31 14:40:12 WARN MemoryStore: Not enough space to cache rdd_12_36 in memory! (computed 69.1 MiB so far)
21/01/31 14:40:12 INFO MemoryStore: Memory use = 165.9 MiB (blocks) + 156.8 MiB (scratch space shared across 2 tasks(s)) = 322.7 MiB. Storage limit = 366.3 MiB.
21/01/31 14:40:12 WARN BlockManager: Persisting block rdd_12_36 to disk instead.
21/01/31 14:40:23 INFO MemoryStore: Will not store rdd_12_24
21/01/31 14:40:23 WARN MemoryStore: Not enough space to cache rdd_12_24 in memory! (computed 135.7 MiB so far)
21/01/31 14:40:23 INFO MemoryStore: Memory use = 165.9 MiB (blocks) + 103.6 MiB (scratch space shared across 1 tasks(s)) = 269.5 MiB. Storage limit = 366.3 MiB.
21/01/31 14:40:23 WARN BlockManager: Persisting block rdd_12_24 to disk instead.
21/01/31 14:40:34 INFO MemoryStore: Will not store rdd_12_24
21/01/31 14:40:34 WARN MemoryStore: Not enough space to cache rdd_12_24 in memory! (computed 135.7 MiB so far)
21/01/31 14:40:34 INFO MemoryStore: Memory use = 165.9 MiB (blocks) + 103.6 MiB (scratch space shared across 1 tasks(s)) = 269.5 MiB. Storage limit = 366.3 MiB.
21/01/31 14:40:34 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/01/31 14:40:34 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/01/31 14:40:34 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/01/31 14:40:34 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/01/31 14:40:34 INFO CodecConfig: Compression: SNAPPY
21/01/31 14:40:34 INFO CodecConfig: Compression: SNAPPY
21/01/31 14:40:34 INFO ParquetOutputFormat: Parquet block size to 134217728
21/01/31 14:40:34 INFO ParquetOutputFormat: Parquet page size to 1048576
21/01/31 14:40:34 INFO ParquetOutputFormat: Parquet dictionary page size to 1048576
21/01/31 14:40:34 INFO ParquetOutputFormat: Dictionary is on
21/01/31 14:40:34 INFO ParquetOutputFormat: Validation is off
21/01/31 14:40:34 INFO ParquetOutputFormat: Writer version is: PARQUET_1_0
21/01/31 14:40:34 INFO ParquetOutputFormat: Maximum row group padding size is 8388608 bytes
21/01/31 14:40:34 INFO ParquetOutputFormat: Page size checking is: estimated
21/01/31 14:40:34 INFO ParquetOutputFormat: Min row count for page size check is: 100
21/01/31 14:40:34 INFO ParquetOutputFormat: Max row count for page size check is: 10000
21/01/31 14:40:34 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "distributionid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "advertiserid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "distributionhourjst",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "distributiondatetime",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "requestid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "uid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "uavalue",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "uacategory",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "documentid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "documenturl",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "sitecode",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "documenttitle",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "campaignid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "campaigntype",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "publisherid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "publisherchannelid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "maxcpc",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "bidcpc",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "contractcpc",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "finalscore",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "originalscore",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "distributionorder",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "israndom",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "jobchanneltype",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "buckettype",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "predictctr",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "dt",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "isGsp",
    "type" : "boolean",
    "nullable" : false,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary distributionid (UTF8);
  optional binary advertiserid (UTF8);
  optional binary distributionhourjst (UTF8);
  optional binary distributiondatetime (UTF8);
  optional binary requestid (UTF8);
  optional binary uid (UTF8);
  optional binary uavalue (UTF8);
  optional binary uacategory (UTF8);
  optional binary documentid (UTF8);
  optional binary documenturl (UTF8);
  optional binary sitecode (UTF8);
  optional binary documenttitle (UTF8);
  optional binary campaignid (UTF8);
  optional binary campaigntype (UTF8);
  optional binary publisherid (UTF8);
  optional binary publisherchannelid (UTF8);
  optional binary maxcpc (UTF8);
  optional binary bidcpc (UTF8);
  optional binary contractcpc (UTF8);
  optional binary finalscore (UTF8);
  optional binary originalscore (UTF8);
  optional binary distributionorder (UTF8);
  optional binary israndom (UTF8);
  optional binary jobchanneltype (UTF8);
  optional binary buckettype (UTF8);
  optional binary predictctr (UTF8);
  optional binary dt (UTF8);
  required boolean isGsp;
}

       
21/01/31 14:40:41 INFO MemoryStore: Will not store rdd_12_36
21/01/31 14:40:41 WARN MemoryStore: Not enough space to cache rdd_12_36 in memory! (computed 136.2 MiB so far)
21/01/31 14:40:41 INFO MemoryStore: Memory use = 165.9 MiB (blocks) + 103.6 MiB (scratch space shared across 1 tasks(s)) = 269.5 MiB. Storage limit = 366.3 MiB.
21/01/31 14:40:41 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/01/31 14:40:41 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/01/31 14:40:41 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/01/31 14:40:41 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/01/31 14:40:41 INFO CodecConfig: Compression: SNAPPY
21/01/31 14:40:41 INFO CodecConfig: Compression: SNAPPY
21/01/31 14:40:41 INFO ParquetOutputFormat: Parquet block size to 134217728
21/01/31 14:40:41 INFO ParquetOutputFormat: Parquet page size to 1048576
21/01/31 14:40:41 INFO ParquetOutputFormat: Parquet dictionary page size to 1048576
21/01/31 14:40:41 INFO ParquetOutputFormat: Dictionary is on
21/01/31 14:40:41 INFO ParquetOutputFormat: Validation is off
21/01/31 14:40:41 INFO ParquetOutputFormat: Writer version is: PARQUET_1_0
21/01/31 14:40:41 INFO ParquetOutputFormat: Maximum row group padding size is 8388608 bytes
21/01/31 14:40:41 INFO ParquetOutputFormat: Page size checking is: estimated
21/01/31 14:40:41 INFO ParquetOutputFormat: Min row count for page size check is: 100
21/01/31 14:40:41 INFO ParquetOutputFormat: Max row count for page size check is: 10000
21/01/31 14:40:41 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "distributionid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "advertiserid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "distributionhourjst",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "distributiondatetime",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "requestid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "uid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "uavalue",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "uacategory",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "documentid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "documenturl",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "sitecode",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "documenttitle",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "campaignid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "campaigntype",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "publisherid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "publisherchannelid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "maxcpc",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "bidcpc",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "contractcpc",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "finalscore",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "originalscore",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "distributionorder",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "israndom",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "jobchanneltype",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "buckettype",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "predictctr",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "dt",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "isGsp",
    "type" : "boolean",
    "nullable" : false,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary distributionid (UTF8);
  optional binary advertiserid (UTF8);
  optional binary distributionhourjst (UTF8);
  optional binary distributiondatetime (UTF8);
  optional binary requestid (UTF8);
  optional binary uid (UTF8);
  optional binary uavalue (UTF8);
  optional binary uacategory (UTF8);
  optional binary documentid (UTF8);
  optional binary documenturl (UTF8);
  optional binary sitecode (UTF8);
  optional binary documenttitle (UTF8);
  optional binary campaignid (UTF8);
  optional binary campaigntype (UTF8);
  optional binary publisherid (UTF8);
  optional binary publisherchannelid (UTF8);
  optional binary maxcpc (UTF8);
  optional binary bidcpc (UTF8);
  optional binary contractcpc (UTF8);
  optional binary finalscore (UTF8);
  optional binary originalscore (UTF8);
  optional binary distributionorder (UTF8);
  optional binary israndom (UTF8);
  optional binary jobchanneltype (UTF8);
  optional binary buckettype (UTF8);
  optional binary predictctr (UTF8);
  optional binary dt (UTF8);
  required boolean isGsp;
}

       
21/01/31 14:40:43 INFO InternalParquetRecordWriter: Flushing mem columnStore to file. allocated memory: 41046304
21/01/31 14:40:43 INFO FileOutputCommitter: Saved output of task 'attempt_20210131143854_0001_m_000024_25' to file:/Users/kinsho/Desktop/log/_temporary/0/task_20210131143854_0001_m_000024
21/01/31 14:40:43 INFO SparkHadoopMapRedUtil: attempt_20210131143854_0001_m_000024_25: Committed
21/01/31 14:40:43 INFO Executor: Finished task 24.0 in stage 1.0 (TID 25). 2461 bytes result sent to driver
21/01/31 14:40:43 INFO CoarseGrainedExecutorBackend: Got assigned task 44
21/01/31 14:40:43 INFO Executor: Running task 43.0 in stage 1.0 (TID 44)
21/01/31 14:40:43 INFO FileScanRDD: Reading File path: file:///Users/kinsho/Desktop/impressionLog.csv, range: 5771362304-5905580032, partition values: [empty row]
21/01/31 14:40:48 INFO InternalParquetRecordWriter: Flushing mem columnStore to file. allocated memory: 39644904
21/01/31 14:40:49 INFO FileOutputCommitter: Saved output of task 'attempt_20210131143854_0001_m_000036_37' to file:/Users/kinsho/Desktop/log/_temporary/0/task_20210131143854_0001_m_000036
21/01/31 14:40:49 INFO SparkHadoopMapRedUtil: attempt_20210131143854_0001_m_000036_37: Committed
21/01/31 14:40:49 INFO Executor: Finished task 36.0 in stage 1.0 (TID 37). 2461 bytes result sent to driver
21/01/31 14:40:49 INFO CoarseGrainedExecutorBackend: Got assigned task 56
21/01/31 14:40:49 INFO Executor: Running task 55.0 in stage 1.0 (TID 56)
21/01/31 14:40:49 INFO FileScanRDD: Reading File path: file:///Users/kinsho/Desktop/impressionLog.csv, range: 7381975040-7516192768, partition values: [empty row]
21/01/31 14:41:02 INFO MemoryStore: Will not store rdd_12_55
21/01/31 14:41:02 WARN MemoryStore: Not enough space to cache rdd_12_55 in memory! (computed 69.8 MiB so far)
21/01/31 14:41:02 INFO MemoryStore: Memory use = 165.9 MiB (blocks) + 156.9 MiB (scratch space shared across 2 tasks(s)) = 322.8 MiB. Storage limit = 366.3 MiB.
21/01/31 14:41:02 WARN BlockManager: Persisting block rdd_12_55 to disk instead.
21/01/31 14:41:10 INFO MemoryStore: Will not store rdd_12_43
21/01/31 14:41:10 WARN MemoryStore: Not enough space to cache rdd_12_43 in memory! (computed 136.8 MiB so far)
21/01/31 14:41:10 INFO MemoryStore: Memory use = 165.9 MiB (blocks) + 103.3 MiB (scratch space shared across 1 tasks(s)) = 269.2 MiB. Storage limit = 366.3 MiB.
21/01/31 14:41:10 WARN BlockManager: Persisting block rdd_12_43 to disk instead.
21/01/31 14:41:17 INFO MemoryStore: Will not store rdd_12_43
21/01/31 14:41:17 WARN MemoryStore: Not enough space to cache rdd_12_43 in memory! (computed 136.8 MiB so far)
21/01/31 14:41:17 INFO MemoryStore: Memory use = 165.9 MiB (blocks) + 103.3 MiB (scratch space shared across 1 tasks(s)) = 269.2 MiB. Storage limit = 366.3 MiB.
21/01/31 14:41:17 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/01/31 14:41:17 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/01/31 14:41:17 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/01/31 14:41:17 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/01/31 14:41:17 INFO CodecConfig: Compression: SNAPPY
21/01/31 14:41:17 INFO CodecConfig: Compression: SNAPPY
21/01/31 14:41:17 INFO ParquetOutputFormat: Parquet block size to 134217728
21/01/31 14:41:17 INFO ParquetOutputFormat: Parquet page size to 1048576
21/01/31 14:41:17 INFO ParquetOutputFormat: Parquet dictionary page size to 1048576
21/01/31 14:41:17 INFO ParquetOutputFormat: Dictionary is on
21/01/31 14:41:17 INFO ParquetOutputFormat: Validation is off
21/01/31 14:41:17 INFO ParquetOutputFormat: Writer version is: PARQUET_1_0
21/01/31 14:41:17 INFO ParquetOutputFormat: Maximum row group padding size is 8388608 bytes
21/01/31 14:41:17 INFO ParquetOutputFormat: Page size checking is: estimated
21/01/31 14:41:17 INFO ParquetOutputFormat: Min row count for page size check is: 100
21/01/31 14:41:17 INFO ParquetOutputFormat: Max row count for page size check is: 10000
21/01/31 14:41:17 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "distributionid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "advertiserid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "distributionhourjst",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "distributiondatetime",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "requestid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "uid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "uavalue",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "uacategory",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "documentid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "documenturl",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "sitecode",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "documenttitle",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "campaignid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "campaigntype",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "publisherid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "publisherchannelid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "maxcpc",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "bidcpc",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "contractcpc",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "finalscore",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "originalscore",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "distributionorder",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "israndom",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "jobchanneltype",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "buckettype",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "predictctr",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "dt",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "isGsp",
    "type" : "boolean",
    "nullable" : false,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary distributionid (UTF8);
  optional binary advertiserid (UTF8);
  optional binary distributionhourjst (UTF8);
  optional binary distributiondatetime (UTF8);
  optional binary requestid (UTF8);
  optional binary uid (UTF8);
  optional binary uavalue (UTF8);
  optional binary uacategory (UTF8);
  optional binary documentid (UTF8);
  optional binary documenturl (UTF8);
  optional binary sitecode (UTF8);
  optional binary documenttitle (UTF8);
  optional binary campaignid (UTF8);
  optional binary campaigntype (UTF8);
  optional binary publisherid (UTF8);
  optional binary publisherchannelid (UTF8);
  optional binary maxcpc (UTF8);
  optional binary bidcpc (UTF8);
  optional binary contractcpc (UTF8);
  optional binary finalscore (UTF8);
  optional binary originalscore (UTF8);
  optional binary distributionorder (UTF8);
  optional binary israndom (UTF8);
  optional binary jobchanneltype (UTF8);
  optional binary buckettype (UTF8);
  optional binary predictctr (UTF8);
  optional binary dt (UTF8);
  required boolean isGsp;
}

       
21/01/31 14:41:23 INFO MemoryStore: Will not store rdd_12_55
21/01/31 14:41:23 WARN MemoryStore: Not enough space to cache rdd_12_55 in memory! (computed 69.8 MiB so far)
21/01/31 14:41:23 INFO MemoryStore: Memory use = 165.9 MiB (blocks) + 156.9 MiB (scratch space shared across 2 tasks(s)) = 322.8 MiB. Storage limit = 366.3 MiB.
21/01/31 14:41:23 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/01/31 14:41:23 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/01/31 14:41:23 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/01/31 14:41:23 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/01/31 14:41:23 INFO CodecConfig: Compression: SNAPPY
21/01/31 14:41:23 INFO CodecConfig: Compression: SNAPPY
21/01/31 14:41:23 INFO ParquetOutputFormat: Parquet block size to 134217728
21/01/31 14:41:23 INFO ParquetOutputFormat: Parquet page size to 1048576
21/01/31 14:41:23 INFO ParquetOutputFormat: Parquet dictionary page size to 1048576
21/01/31 14:41:23 INFO ParquetOutputFormat: Dictionary is on
21/01/31 14:41:23 INFO ParquetOutputFormat: Validation is off
21/01/31 14:41:23 INFO ParquetOutputFormat: Writer version is: PARQUET_1_0
21/01/31 14:41:23 INFO ParquetOutputFormat: Maximum row group padding size is 8388608 bytes
21/01/31 14:41:23 INFO ParquetOutputFormat: Page size checking is: estimated
21/01/31 14:41:23 INFO ParquetOutputFormat: Min row count for page size check is: 100
21/01/31 14:41:23 INFO ParquetOutputFormat: Max row count for page size check is: 10000
21/01/31 14:41:23 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "distributionid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "advertiserid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "distributionhourjst",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "distributiondatetime",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "requestid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "uid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "uavalue",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "uacategory",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "documentid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "documenturl",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "sitecode",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "documenttitle",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "campaignid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "campaigntype",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "publisherid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "publisherchannelid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "maxcpc",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "bidcpc",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "contractcpc",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "finalscore",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "originalscore",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "distributionorder",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "israndom",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "jobchanneltype",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "buckettype",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "predictctr",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "dt",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "isGsp",
    "type" : "boolean",
    "nullable" : false,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary distributionid (UTF8);
  optional binary advertiserid (UTF8);
  optional binary distributionhourjst (UTF8);
  optional binary distributiondatetime (UTF8);
  optional binary requestid (UTF8);
  optional binary uid (UTF8);
  optional binary uavalue (UTF8);
  optional binary uacategory (UTF8);
  optional binary documentid (UTF8);
  optional binary documenturl (UTF8);
  optional binary sitecode (UTF8);
  optional binary documenttitle (UTF8);
  optional binary campaignid (UTF8);
  optional binary campaigntype (UTF8);
  optional binary publisherid (UTF8);
  optional binary publisherchannelid (UTF8);
  optional binary maxcpc (UTF8);
  optional binary bidcpc (UTF8);
  optional binary contractcpc (UTF8);
  optional binary finalscore (UTF8);
  optional binary originalscore (UTF8);
  optional binary distributionorder (UTF8);
  optional binary israndom (UTF8);
  optional binary jobchanneltype (UTF8);
  optional binary buckettype (UTF8);
  optional binary predictctr (UTF8);
  optional binary dt (UTF8);
  required boolean isGsp;
}

       
21/01/31 14:41:25 INFO InternalParquetRecordWriter: Flushing mem columnStore to file. allocated memory: 38175253
21/01/31 14:41:25 INFO FileOutputCommitter: Saved output of task 'attempt_20210131143854_0001_m_000043_44' to file:/Users/kinsho/Desktop/log/_temporary/0/task_20210131143854_0001_m_000043
21/01/31 14:41:25 INFO SparkHadoopMapRedUtil: attempt_20210131143854_0001_m_000043_44: Committed
21/01/31 14:41:25 INFO Executor: Finished task 43.0 in stage 1.0 (TID 44). 2461 bytes result sent to driver
21/01/31 14:41:25 INFO CoarseGrainedExecutorBackend: Got assigned task 63
21/01/31 14:41:25 INFO Executor: Running task 62.0 in stage 1.0 (TID 63)
21/01/31 14:41:25 INFO FileScanRDD: Reading File path: file:///Users/kinsho/Desktop/impressionLog.csv, range: 8321499136-8455716864, partition values: [empty row]
21/01/31 14:41:30 INFO InternalParquetRecordWriter: Flushing mem columnStore to file. allocated memory: 37692854
21/01/31 14:41:30 INFO FileOutputCommitter: Saved output of task 'attempt_20210131143854_0001_m_000055_56' to file:/Users/kinsho/Desktop/log/_temporary/0/task_20210131143854_0001_m_000055
21/01/31 14:41:30 INFO SparkHadoopMapRedUtil: attempt_20210131143854_0001_m_000055_56: Committed
21/01/31 14:41:30 INFO Executor: Finished task 55.0 in stage 1.0 (TID 56). 2461 bytes result sent to driver
21/01/31 14:41:30 INFO CoarseGrainedExecutorBackend: Got assigned task 75
21/01/31 14:41:30 INFO Executor: Running task 74.0 in stage 1.0 (TID 75)
21/01/31 14:41:30 INFO FileScanRDD: Reading File path: file:///Users/kinsho/Desktop/impressionLog.csv, range: 9932111872-10066329600, partition values: [empty row]
21/01/31 14:41:45 INFO MemoryStore: Will not store rdd_12_74
21/01/31 14:41:45 WARN MemoryStore: Not enough space to cache rdd_12_74 in memory! (computed 68.3 MiB so far)
21/01/31 14:41:45 INFO MemoryStore: Memory use = 165.9 MiB (blocks) + 156.3 MiB (scratch space shared across 2 tasks(s)) = 322.2 MiB. Storage limit = 366.3 MiB.
21/01/31 14:41:45 WARN BlockManager: Persisting block rdd_12_74 to disk instead.
21/01/31 14:41:54 INFO MemoryStore: Will not store rdd_12_62
21/01/31 14:41:54 WARN MemoryStore: Not enough space to cache rdd_12_62 in memory! (computed 135.6 MiB so far)
21/01/31 14:41:54 INFO MemoryStore: Memory use = 165.9 MiB (blocks) + 102.8 MiB (scratch space shared across 1 tasks(s)) = 268.7 MiB. Storage limit = 366.3 MiB.
21/01/31 14:41:54 WARN BlockManager: Persisting block rdd_12_62 to disk instead.
21/01/31 14:42:01 INFO MemoryStore: Will not store rdd_12_62
21/01/31 14:42:01 WARN MemoryStore: Not enough space to cache rdd_12_62 in memory! (computed 135.6 MiB so far)
21/01/31 14:42:01 INFO MemoryStore: Memory use = 165.9 MiB (blocks) + 102.8 MiB (scratch space shared across 1 tasks(s)) = 268.7 MiB. Storage limit = 366.3 MiB.
21/01/31 14:42:01 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/01/31 14:42:01 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/01/31 14:42:01 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/01/31 14:42:01 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/01/31 14:42:01 INFO CodecConfig: Compression: SNAPPY
21/01/31 14:42:01 INFO CodecConfig: Compression: SNAPPY
21/01/31 14:42:01 INFO ParquetOutputFormat: Parquet block size to 134217728
21/01/31 14:42:01 INFO ParquetOutputFormat: Parquet page size to 1048576
21/01/31 14:42:01 INFO ParquetOutputFormat: Parquet dictionary page size to 1048576
21/01/31 14:42:01 INFO ParquetOutputFormat: Dictionary is on
21/01/31 14:42:01 INFO ParquetOutputFormat: Validation is off
21/01/31 14:42:01 INFO ParquetOutputFormat: Writer version is: PARQUET_1_0
21/01/31 14:42:01 INFO ParquetOutputFormat: Maximum row group padding size is 8388608 bytes
21/01/31 14:42:01 INFO ParquetOutputFormat: Page size checking is: estimated
21/01/31 14:42:01 INFO ParquetOutputFormat: Min row count for page size check is: 100
21/01/31 14:42:01 INFO ParquetOutputFormat: Max row count for page size check is: 10000
21/01/31 14:42:01 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "distributionid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "advertiserid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "distributionhourjst",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "distributiondatetime",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "requestid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "uid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "uavalue",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "uacategory",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "documentid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "documenturl",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "sitecode",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "documenttitle",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "campaignid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "campaigntype",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "publisherid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "publisherchannelid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "maxcpc",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "bidcpc",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "contractcpc",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "finalscore",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "originalscore",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "distributionorder",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "israndom",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "jobchanneltype",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "buckettype",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "predictctr",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "dt",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "isGsp",
    "type" : "boolean",
    "nullable" : false,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary distributionid (UTF8);
  optional binary advertiserid (UTF8);
  optional binary distributionhourjst (UTF8);
  optional binary distributiondatetime (UTF8);
  optional binary requestid (UTF8);
  optional binary uid (UTF8);
  optional binary uavalue (UTF8);
  optional binary uacategory (UTF8);
  optional binary documentid (UTF8);
  optional binary documenturl (UTF8);
  optional binary sitecode (UTF8);
  optional binary documenttitle (UTF8);
  optional binary campaignid (UTF8);
  optional binary campaigntype (UTF8);
  optional binary publisherid (UTF8);
  optional binary publisherchannelid (UTF8);
  optional binary maxcpc (UTF8);
  optional binary bidcpc (UTF8);
  optional binary contractcpc (UTF8);
  optional binary finalscore (UTF8);
  optional binary originalscore (UTF8);
  optional binary distributionorder (UTF8);
  optional binary israndom (UTF8);
  optional binary jobchanneltype (UTF8);
  optional binary buckettype (UTF8);
  optional binary predictctr (UTF8);
  optional binary dt (UTF8);
  required boolean isGsp;
}

       
21/01/31 14:42:06 INFO MemoryStore: Will not store rdd_12_74
21/01/31 14:42:06 WARN MemoryStore: Not enough space to cache rdd_12_74 in memory! (computed 68.3 MiB so far)
21/01/31 14:42:06 INFO MemoryStore: Memory use = 165.9 MiB (blocks) + 156.3 MiB (scratch space shared across 2 tasks(s)) = 322.2 MiB. Storage limit = 366.3 MiB.
21/01/31 14:42:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/01/31 14:42:06 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/01/31 14:42:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/01/31 14:42:06 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/01/31 14:42:06 INFO CodecConfig: Compression: SNAPPY
21/01/31 14:42:06 INFO CodecConfig: Compression: SNAPPY
21/01/31 14:42:06 INFO ParquetOutputFormat: Parquet block size to 134217728
21/01/31 14:42:06 INFO ParquetOutputFormat: Parquet page size to 1048576
21/01/31 14:42:06 INFO ParquetOutputFormat: Parquet dictionary page size to 1048576
21/01/31 14:42:06 INFO ParquetOutputFormat: Dictionary is on
21/01/31 14:42:06 INFO ParquetOutputFormat: Validation is off
21/01/31 14:42:06 INFO ParquetOutputFormat: Writer version is: PARQUET_1_0
21/01/31 14:42:06 INFO ParquetOutputFormat: Maximum row group padding size is 8388608 bytes
21/01/31 14:42:06 INFO ParquetOutputFormat: Page size checking is: estimated
21/01/31 14:42:06 INFO ParquetOutputFormat: Min row count for page size check is: 100
21/01/31 14:42:06 INFO ParquetOutputFormat: Max row count for page size check is: 10000
21/01/31 14:42:06 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "distributionid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "advertiserid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "distributionhourjst",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "distributiondatetime",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "requestid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "uid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "uavalue",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "uacategory",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "documentid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "documenturl",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "sitecode",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "documenttitle",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "campaignid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "campaigntype",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "publisherid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "publisherchannelid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "maxcpc",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "bidcpc",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "contractcpc",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "finalscore",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "originalscore",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "distributionorder",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "israndom",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "jobchanneltype",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "buckettype",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "predictctr",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "dt",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "isGsp",
    "type" : "boolean",
    "nullable" : false,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary distributionid (UTF8);
  optional binary advertiserid (UTF8);
  optional binary distributionhourjst (UTF8);
  optional binary distributiondatetime (UTF8);
  optional binary requestid (UTF8);
  optional binary uid (UTF8);
  optional binary uavalue (UTF8);
  optional binary uacategory (UTF8);
  optional binary documentid (UTF8);
  optional binary documenturl (UTF8);
  optional binary sitecode (UTF8);
  optional binary documenttitle (UTF8);
  optional binary campaignid (UTF8);
  optional binary campaigntype (UTF8);
  optional binary publisherid (UTF8);
  optional binary publisherchannelid (UTF8);
  optional binary maxcpc (UTF8);
  optional binary bidcpc (UTF8);
  optional binary contractcpc (UTF8);
  optional binary finalscore (UTF8);
  optional binary originalscore (UTF8);
  optional binary distributionorder (UTF8);
  optional binary israndom (UTF8);
  optional binary jobchanneltype (UTF8);
  optional binary buckettype (UTF8);
  optional binary predictctr (UTF8);
  optional binary dt (UTF8);
  required boolean isGsp;
}

       
21/01/31 14:42:08 INFO InternalParquetRecordWriter: Flushing mem columnStore to file. allocated memory: 37284984
21/01/31 14:42:08 INFO FileOutputCommitter: Saved output of task 'attempt_20210131143854_0001_m_000062_63' to file:/Users/kinsho/Desktop/log/_temporary/0/task_20210131143854_0001_m_000062
21/01/31 14:42:08 INFO SparkHadoopMapRedUtil: attempt_20210131143854_0001_m_000062_63: Committed
21/01/31 14:42:08 INFO Executor: Finished task 62.0 in stage 1.0 (TID 63). 2461 bytes result sent to driver
21/01/31 14:42:08 INFO CoarseGrainedExecutorBackend: Got assigned task 85
21/01/31 14:42:08 INFO Executor: Running task 84.0 in stage 1.0 (TID 85)
21/01/31 14:42:08 INFO FileScanRDD: Reading File path: file:///Users/kinsho/Desktop/impressionLog.csv, range: 11274289152-11408506880, partition values: [empty row]
21/01/31 14:42:13 INFO InternalParquetRecordWriter: Flushing mem columnStore to file. allocated memory: 36691457
21/01/31 14:42:13 INFO FileOutputCommitter: Saved output of task 'attempt_20210131143854_0001_m_000074_75' to file:/Users/kinsho/Desktop/log/_temporary/0/task_20210131143854_0001_m_000074
21/01/31 14:42:13 INFO SparkHadoopMapRedUtil: attempt_20210131143854_0001_m_000074_75: Committed
21/01/31 14:42:13 INFO Executor: Finished task 74.0 in stage 1.0 (TID 75). 2461 bytes result sent to driver
21/01/31 14:42:13 INFO CoarseGrainedExecutorBackend: Got assigned task 95
21/01/31 14:42:13 INFO Executor: Running task 94.0 in stage 1.0 (TID 95)
21/01/31 14:42:13 INFO FileScanRDD: Reading File path: file:///Users/kinsho/Desktop/impressionLog.csv, range: 12616466432-12750684160, partition values: [empty row]
21/01/31 14:42:26 INFO MemoryStore: Will not store rdd_12_94
21/01/31 14:42:26 WARN MemoryStore: Not enough space to cache rdd_12_94 in memory! (computed 69.8 MiB so far)
21/01/31 14:42:26 INFO MemoryStore: Memory use = 165.9 MiB (blocks) + 155.0 MiB (scratch space shared across 2 tasks(s)) = 320.9 MiB. Storage limit = 366.3 MiB.
21/01/31 14:42:26 WARN BlockManager: Persisting block rdd_12_94 to disk instead.
21/01/31 14:42:35 INFO MemoryStore: Will not store rdd_12_84
21/01/31 14:42:35 WARN MemoryStore: Not enough space to cache rdd_12_84 in memory! (computed 134.0 MiB so far)
21/01/31 14:42:35 INFO MemoryStore: Memory use = 165.9 MiB (blocks) + 101.1 MiB (scratch space shared across 1 tasks(s)) = 267.0 MiB. Storage limit = 366.3 MiB.
21/01/31 14:42:35 WARN BlockManager: Persisting block rdd_12_84 to disk instead.
21/01/31 14:42:42 INFO MemoryStore: Will not store rdd_12_84
21/01/31 14:42:42 WARN MemoryStore: Not enough space to cache rdd_12_84 in memory! (computed 134.0 MiB so far)
21/01/31 14:42:42 INFO MemoryStore: Memory use = 165.9 MiB (blocks) + 101.1 MiB (scratch space shared across 1 tasks(s)) = 267.0 MiB. Storage limit = 366.3 MiB.
21/01/31 14:42:42 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/01/31 14:42:42 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/01/31 14:42:42 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/01/31 14:42:42 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/01/31 14:42:42 INFO CodecConfig: Compression: SNAPPY
21/01/31 14:42:42 INFO CodecConfig: Compression: SNAPPY
21/01/31 14:42:42 INFO ParquetOutputFormat: Parquet block size to 134217728
21/01/31 14:42:42 INFO ParquetOutputFormat: Parquet page size to 1048576
21/01/31 14:42:42 INFO ParquetOutputFormat: Parquet dictionary page size to 1048576
21/01/31 14:42:42 INFO ParquetOutputFormat: Dictionary is on
21/01/31 14:42:42 INFO ParquetOutputFormat: Validation is off
21/01/31 14:42:42 INFO ParquetOutputFormat: Writer version is: PARQUET_1_0
21/01/31 14:42:42 INFO ParquetOutputFormat: Maximum row group padding size is 8388608 bytes
21/01/31 14:42:42 INFO ParquetOutputFormat: Page size checking is: estimated
21/01/31 14:42:42 INFO ParquetOutputFormat: Min row count for page size check is: 100
21/01/31 14:42:42 INFO ParquetOutputFormat: Max row count for page size check is: 10000
21/01/31 14:42:42 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "distributionid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "advertiserid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "distributionhourjst",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "distributiondatetime",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "requestid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "uid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "uavalue",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "uacategory",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "documentid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "documenturl",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "sitecode",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "documenttitle",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "campaignid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "campaigntype",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "publisherid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "publisherchannelid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "maxcpc",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "bidcpc",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "contractcpc",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "finalscore",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "originalscore",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "distributionorder",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "israndom",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "jobchanneltype",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "buckettype",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "predictctr",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "dt",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "isGsp",
    "type" : "boolean",
    "nullable" : false,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary distributionid (UTF8);
  optional binary advertiserid (UTF8);
  optional binary distributionhourjst (UTF8);
  optional binary distributiondatetime (UTF8);
  optional binary requestid (UTF8);
  optional binary uid (UTF8);
  optional binary uavalue (UTF8);
  optional binary uacategory (UTF8);
  optional binary documentid (UTF8);
  optional binary documenturl (UTF8);
  optional binary sitecode (UTF8);
  optional binary documenttitle (UTF8);
  optional binary campaignid (UTF8);
  optional binary campaigntype (UTF8);
  optional binary publisherid (UTF8);
  optional binary publisherchannelid (UTF8);
  optional binary maxcpc (UTF8);
  optional binary bidcpc (UTF8);
  optional binary contractcpc (UTF8);
  optional binary finalscore (UTF8);
  optional binary originalscore (UTF8);
  optional binary distributionorder (UTF8);
  optional binary israndom (UTF8);
  optional binary jobchanneltype (UTF8);
  optional binary buckettype (UTF8);
  optional binary predictctr (UTF8);
  optional binary dt (UTF8);
  required boolean isGsp;
}

       
21/01/31 14:42:45 INFO MemoryStore: Will not store rdd_12_94
21/01/31 14:42:45 WARN MemoryStore: Not enough space to cache rdd_12_94 in memory! (computed 69.8 MiB so far)
21/01/31 14:42:45 INFO MemoryStore: Memory use = 165.9 MiB (blocks) + 155.0 MiB (scratch space shared across 2 tasks(s)) = 320.9 MiB. Storage limit = 366.3 MiB.
21/01/31 14:42:45 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/01/31 14:42:45 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/01/31 14:42:45 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/01/31 14:42:45 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/01/31 14:42:45 INFO CodecConfig: Compression: SNAPPY
21/01/31 14:42:45 INFO CodecConfig: Compression: SNAPPY
21/01/31 14:42:45 INFO ParquetOutputFormat: Parquet block size to 134217728
21/01/31 14:42:45 INFO ParquetOutputFormat: Parquet page size to 1048576
21/01/31 14:42:45 INFO ParquetOutputFormat: Parquet dictionary page size to 1048576
21/01/31 14:42:45 INFO ParquetOutputFormat: Dictionary is on
21/01/31 14:42:45 INFO ParquetOutputFormat: Validation is off
21/01/31 14:42:45 INFO ParquetOutputFormat: Writer version is: PARQUET_1_0
21/01/31 14:42:45 INFO ParquetOutputFormat: Maximum row group padding size is 8388608 bytes
21/01/31 14:42:45 INFO ParquetOutputFormat: Page size checking is: estimated
21/01/31 14:42:45 INFO ParquetOutputFormat: Min row count for page size check is: 100
21/01/31 14:42:45 INFO ParquetOutputFormat: Max row count for page size check is: 10000
21/01/31 14:42:45 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "distributionid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "advertiserid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "distributionhourjst",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "distributiondatetime",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "requestid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "uid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "uavalue",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "uacategory",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "documentid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "documenturl",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "sitecode",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "documenttitle",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "campaignid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "campaigntype",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "publisherid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "publisherchannelid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "maxcpc",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "bidcpc",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "contractcpc",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "finalscore",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "originalscore",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "distributionorder",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "israndom",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "jobchanneltype",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "buckettype",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "predictctr",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "dt",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "isGsp",
    "type" : "boolean",
    "nullable" : false,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary distributionid (UTF8);
  optional binary advertiserid (UTF8);
  optional binary distributionhourjst (UTF8);
  optional binary distributiondatetime (UTF8);
  optional binary requestid (UTF8);
  optional binary uid (UTF8);
  optional binary uavalue (UTF8);
  optional binary uacategory (UTF8);
  optional binary documentid (UTF8);
  optional binary documenturl (UTF8);
  optional binary sitecode (UTF8);
  optional binary documenttitle (UTF8);
  optional binary campaignid (UTF8);
  optional binary campaigntype (UTF8);
  optional binary publisherid (UTF8);
  optional binary publisherchannelid (UTF8);
  optional binary maxcpc (UTF8);
  optional binary bidcpc (UTF8);
  optional binary contractcpc (UTF8);
  optional binary finalscore (UTF8);
  optional binary originalscore (UTF8);
  optional binary distributionorder (UTF8);
  optional binary israndom (UTF8);
  optional binary jobchanneltype (UTF8);
  optional binary buckettype (UTF8);
  optional binary predictctr (UTF8);
  optional binary dt (UTF8);
  required boolean isGsp;
}

       
21/01/31 14:42:48 INFO InternalParquetRecordWriter: Flushing mem columnStore to file. allocated memory: 34437669
21/01/31 14:42:48 INFO FileOutputCommitter: Saved output of task 'attempt_20210131143854_0001_m_000084_85' to file:/Users/kinsho/Desktop/log/_temporary/0/task_20210131143854_0001_m_000084
21/01/31 14:42:48 INFO SparkHadoopMapRedUtil: attempt_20210131143854_0001_m_000084_85: Committed
21/01/31 14:42:48 INFO Executor: Finished task 84.0 in stage 1.0 (TID 85). 2461 bytes result sent to driver
21/01/31 14:42:48 INFO CoarseGrainedExecutorBackend: Got assigned task 107
21/01/31 14:42:48 INFO Executor: Running task 106.0 in stage 1.0 (TID 107)
21/01/31 14:42:48 INFO FileScanRDD: Reading File path: file:///Users/kinsho/Desktop/impressionLog.csv, range: 14227079168-14361296896, partition values: [empty row]
21/01/31 14:42:52 INFO InternalParquetRecordWriter: Flushing mem columnStore to file. allocated memory: 36034597
21/01/31 14:42:52 INFO FileOutputCommitter: Saved output of task 'attempt_20210131143854_0001_m_000094_95' to file:/Users/kinsho/Desktop/log/_temporary/0/task_20210131143854_0001_m_000094
21/01/31 14:42:52 INFO SparkHadoopMapRedUtil: attempt_20210131143854_0001_m_000094_95: Committed
21/01/31 14:42:52 INFO Executor: Finished task 94.0 in stage 1.0 (TID 95). 2461 bytes result sent to driver
21/01/31 14:42:52 INFO CoarseGrainedExecutorBackend: Got assigned task 113
21/01/31 14:42:52 INFO Executor: Running task 112.0 in stage 1.0 (TID 113)
21/01/31 14:42:52 INFO FileScanRDD: Reading File path: file:///Users/kinsho/Desktop/impressionLog.csv, range: 15032385536-15166603264, partition values: [empty row]
21/01/31 14:43:10 INFO MemoryStore: Will not store rdd_12_112
21/01/31 14:43:10 WARN MemoryStore: Not enough space to cache rdd_12_112 in memory! (computed 67.7 MiB so far)
21/01/31 14:43:10 INFO MemoryStore: Memory use = 165.9 MiB (blocks) + 151.8 MiB (scratch space shared across 2 tasks(s)) = 317.7 MiB. Storage limit = 366.3 MiB.
21/01/31 14:43:10 WARN BlockManager: Persisting block rdd_12_112 to disk instead.
21/01/31 14:43:25 INFO MemoryStore: Block rdd_12_106 stored as values in memory (estimated size 153.3 MiB, free 47.1 MiB)
21/01/31 14:43:25 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/01/31 14:43:25 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/01/31 14:43:25 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/01/31 14:43:25 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/01/31 14:43:25 INFO CodecConfig: Compression: SNAPPY
21/01/31 14:43:25 INFO CodecConfig: Compression: SNAPPY
21/01/31 14:43:25 INFO ParquetOutputFormat: Parquet block size to 134217728
21/01/31 14:43:25 INFO ParquetOutputFormat: Parquet page size to 1048576
21/01/31 14:43:25 INFO ParquetOutputFormat: Parquet dictionary page size to 1048576
21/01/31 14:43:25 INFO ParquetOutputFormat: Dictionary is on
21/01/31 14:43:25 INFO ParquetOutputFormat: Validation is off
21/01/31 14:43:25 INFO ParquetOutputFormat: Writer version is: PARQUET_1_0
21/01/31 14:43:25 INFO ParquetOutputFormat: Maximum row group padding size is 8388608 bytes
21/01/31 14:43:25 INFO ParquetOutputFormat: Page size checking is: estimated
21/01/31 14:43:25 INFO ParquetOutputFormat: Min row count for page size check is: 100
21/01/31 14:43:25 INFO ParquetOutputFormat: Max row count for page size check is: 10000
21/01/31 14:43:25 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "distributionid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "advertiserid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "distributionhourjst",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "distributiondatetime",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "requestid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "uid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "uavalue",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "uacategory",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "documentid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "documenturl",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "sitecode",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "documenttitle",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "campaignid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "campaigntype",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "publisherid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "publisherchannelid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "maxcpc",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "bidcpc",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "contractcpc",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "finalscore",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "originalscore",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "distributionorder",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "israndom",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "jobchanneltype",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "buckettype",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "predictctr",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "dt",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "isGsp",
    "type" : "boolean",
    "nullable" : false,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary distributionid (UTF8);
  optional binary advertiserid (UTF8);
  optional binary distributionhourjst (UTF8);
  optional binary distributiondatetime (UTF8);
  optional binary requestid (UTF8);
  optional binary uid (UTF8);
  optional binary uavalue (UTF8);
  optional binary uacategory (UTF8);
  optional binary documentid (UTF8);
  optional binary documenturl (UTF8);
  optional binary sitecode (UTF8);
  optional binary documenttitle (UTF8);
  optional binary campaignid (UTF8);
  optional binary campaigntype (UTF8);
  optional binary publisherid (UTF8);
  optional binary publisherchannelid (UTF8);
  optional binary maxcpc (UTF8);
  optional binary bidcpc (UTF8);
  optional binary contractcpc (UTF8);
  optional binary finalscore (UTF8);
  optional binary originalscore (UTF8);
  optional binary distributionorder (UTF8);
  optional binary israndom (UTF8);
  optional binary jobchanneltype (UTF8);
  optional binary buckettype (UTF8);
  optional binary predictctr (UTF8);
  optional binary dt (UTF8);
  required boolean isGsp;
}

       
21/01/31 14:43:30 INFO MemoryStore: Will not store rdd_12_112
21/01/31 14:43:30 WARN MemoryStore: Not enough space to cache rdd_12_112 in memory! (computed 34.7 MiB so far)
21/01/31 14:43:30 INFO MemoryStore: Memory use = 319.2 MiB (blocks) + 2.9 MiB (scratch space shared across 1 tasks(s)) = 322.1 MiB. Storage limit = 366.3 MiB.
21/01/31 14:43:30 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/01/31 14:43:30 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/01/31 14:43:30 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/01/31 14:43:30 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/01/31 14:43:30 INFO CodecConfig: Compression: SNAPPY
21/01/31 14:43:30 INFO CodecConfig: Compression: SNAPPY
21/01/31 14:43:30 INFO ParquetOutputFormat: Parquet block size to 134217728
21/01/31 14:43:30 INFO ParquetOutputFormat: Parquet page size to 1048576
21/01/31 14:43:30 INFO ParquetOutputFormat: Parquet dictionary page size to 1048576
21/01/31 14:43:30 INFO ParquetOutputFormat: Dictionary is on
21/01/31 14:43:30 INFO ParquetOutputFormat: Validation is off
21/01/31 14:43:30 INFO ParquetOutputFormat: Writer version is: PARQUET_1_0
21/01/31 14:43:30 INFO ParquetOutputFormat: Maximum row group padding size is 8388608 bytes
21/01/31 14:43:30 INFO ParquetOutputFormat: Page size checking is: estimated
21/01/31 14:43:30 INFO ParquetOutputFormat: Min row count for page size check is: 100
21/01/31 14:43:30 INFO ParquetOutputFormat: Max row count for page size check is: 10000
21/01/31 14:43:30 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "distributionid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "advertiserid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "distributionhourjst",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "distributiondatetime",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "requestid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "uid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "uavalue",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "uacategory",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "documentid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "documenturl",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "sitecode",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "documenttitle",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "campaignid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "campaigntype",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "publisherid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "publisherchannelid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "maxcpc",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "bidcpc",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "contractcpc",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "finalscore",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "originalscore",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "distributionorder",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "israndom",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "jobchanneltype",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "buckettype",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "predictctr",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "dt",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "isGsp",
    "type" : "boolean",
    "nullable" : false,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary distributionid (UTF8);
  optional binary advertiserid (UTF8);
  optional binary distributionhourjst (UTF8);
  optional binary distributiondatetime (UTF8);
  optional binary requestid (UTF8);
  optional binary uid (UTF8);
  optional binary uavalue (UTF8);
  optional binary uacategory (UTF8);
  optional binary documentid (UTF8);
  optional binary documenturl (UTF8);
  optional binary sitecode (UTF8);
  optional binary documenttitle (UTF8);
  optional binary campaignid (UTF8);
  optional binary campaigntype (UTF8);
  optional binary publisherid (UTF8);
  optional binary publisherchannelid (UTF8);
  optional binary maxcpc (UTF8);
  optional binary bidcpc (UTF8);
  optional binary contractcpc (UTF8);
  optional binary finalscore (UTF8);
  optional binary originalscore (UTF8);
  optional binary distributionorder (UTF8);
  optional binary israndom (UTF8);
  optional binary jobchanneltype (UTF8);
  optional binary buckettype (UTF8);
  optional binary predictctr (UTF8);
  optional binary dt (UTF8);
  required boolean isGsp;
}

       
21/01/31 14:43:31 INFO InternalParquetRecordWriter: Flushing mem columnStore to file. allocated memory: 34669200
21/01/31 14:43:32 INFO FileOutputCommitter: Saved output of task 'attempt_20210131143854_0001_m_000106_107' to file:/Users/kinsho/Desktop/log/_temporary/0/task_20210131143854_0001_m_000106
21/01/31 14:43:32 INFO SparkHadoopMapRedUtil: attempt_20210131143854_0001_m_000106_107: Committed
21/01/31 14:43:32 INFO Executor: Finished task 106.0 in stage 1.0 (TID 107). 2461 bytes result sent to driver
21/01/31 14:43:32 INFO CoarseGrainedExecutorBackend: Got assigned task 125
21/01/31 14:43:32 INFO Executor: Running task 124.0 in stage 1.0 (TID 125)
21/01/31 14:43:32 INFO FileScanRDD: Reading File path: file:///Users/kinsho/Desktop/impressionLog.csv, range: 16642998272-16777216000, partition values: [empty row]
21/01/31 14:43:37 INFO InternalParquetRecordWriter: Flushing mem columnStore to file. allocated memory: 35204974
21/01/31 14:43:38 INFO FileOutputCommitter: Saved output of task 'attempt_20210131143854_0001_m_000112_113' to file:/Users/kinsho/Desktop/log/_temporary/0/task_20210131143854_0001_m_000112
21/01/31 14:43:38 INFO SparkHadoopMapRedUtil: attempt_20210131143854_0001_m_000112_113: Committed
21/01/31 14:43:38 INFO Executor: Finished task 112.0 in stage 1.0 (TID 113). 2461 bytes result sent to driver
21/01/31 14:43:38 INFO CoarseGrainedExecutorBackend: Got assigned task 132
21/01/31 14:43:38 INFO Executor: Running task 131.0 in stage 1.0 (TID 132)
21/01/31 14:43:38 INFO FileScanRDD: Reading File path: file:///Users/kinsho/Desktop/impressionLog.csv, range: 17582522368-17716740096, partition values: [empty row]
21/01/31 14:43:41 INFO MemoryStore: Will not store rdd_12_124
21/01/31 14:43:41 WARN MemoryStore: Not enough space to cache rdd_12_124 in memory! (computed 35.0 MiB so far)
21/01/31 14:43:41 INFO MemoryStore: Memory use = 319.2 MiB (blocks) + 6.2 MiB (scratch space shared across 2 tasks(s)) = 325.4 MiB. Storage limit = 366.3 MiB.
21/01/31 14:43:41 WARN BlockManager: Persisting block rdd_12_124 to disk instead.
21/01/31 14:43:45 INFO MemoryStore: Will not store rdd_12_131
21/01/31 14:43:45 WARN MemoryStore: Not enough space to cache rdd_12_131 in memory! (computed 36.9 MiB so far)
21/01/31 14:43:45 INFO MemoryStore: Memory use = 319.2 MiB (blocks) + 3.1 MiB (scratch space shared across 1 tasks(s)) = 322.3 MiB. Storage limit = 366.3 MiB.
21/01/31 14:43:45 WARN BlockManager: Persisting block rdd_12_131 to disk instead.
21/01/31 14:44:13 INFO MemoryStore: Will not store rdd_12_124
21/01/31 14:44:13 WARN MemoryStore: Not enough space to cache rdd_12_124 in memory! (computed 35.0 MiB so far)
21/01/31 14:44:13 INFO MemoryStore: Memory use = 319.2 MiB (blocks) + 3.1 MiB (scratch space shared across 1 tasks(s)) = 322.3 MiB. Storage limit = 366.3 MiB.
21/01/31 14:44:13 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/01/31 14:44:13 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/01/31 14:44:13 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/01/31 14:44:13 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/01/31 14:44:13 INFO CodecConfig: Compression: SNAPPY
21/01/31 14:44:13 INFO CodecConfig: Compression: SNAPPY
21/01/31 14:44:13 INFO ParquetOutputFormat: Parquet block size to 134217728
21/01/31 14:44:13 INFO ParquetOutputFormat: Parquet page size to 1048576
21/01/31 14:44:13 INFO ParquetOutputFormat: Parquet dictionary page size to 1048576
21/01/31 14:44:13 INFO ParquetOutputFormat: Dictionary is on
21/01/31 14:44:13 INFO ParquetOutputFormat: Validation is off
21/01/31 14:44:13 INFO ParquetOutputFormat: Writer version is: PARQUET_1_0
21/01/31 14:44:13 INFO ParquetOutputFormat: Maximum row group padding size is 8388608 bytes
21/01/31 14:44:13 INFO ParquetOutputFormat: Page size checking is: estimated
21/01/31 14:44:13 INFO ParquetOutputFormat: Min row count for page size check is: 100
21/01/31 14:44:13 INFO ParquetOutputFormat: Max row count for page size check is: 10000
21/01/31 14:44:13 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "distributionid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "advertiserid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "distributionhourjst",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "distributiondatetime",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "requestid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "uid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "uavalue",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "uacategory",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "documentid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "documenturl",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "sitecode",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "documenttitle",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "campaignid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "campaigntype",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "publisherid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "publisherchannelid",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "maxcpc",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "bidcpc",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "contractcpc",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "finalscore",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "originalscore",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "distributionorder",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "israndom",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "jobchanneltype",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "buckettype",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "predictctr",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "dt",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "isGsp",
    "type" : "boolean",
    "nullable" : false,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary distributionid (UTF8);
  optional binary advertiserid (UTF8);
  optional binary distributionhourjst (UTF8);
  optional binary distributiondatetime (UTF8);
  optional binary requestid (UTF8);
  optional binary uid (UTF8);
  optional binary uavalue (UTF8);
  optional binary uacategory (UTF8);
  optional binary documentid (UTF8);
  optional binary documenturl (UTF8);
  optional binary sitecode (UTF8);
  optional binary documenttitle (UTF8);
  optional binary campaignid (UTF8);
  optional binary campaigntype (UTF8);
  optional binary publisherid (UTF8);
  optional binary publisherchannelid (UTF8);
  optional binary maxcpc (UTF8);
  optional binary bidcpc (UTF8);
  optional binary contractcpc (UTF8);
  optional binary finalscore (UTF8);
  optional binary originalscore (UTF8);
  optional binary distributionorder (UTF8);
  optional binary israndom (UTF8);
  optional binary jobchanneltype (UTF8);
  optional binary buckettype (UTF8);
  optional binary predictctr (UTF8);
  optional binary dt (UTF8);
  required boolean isGsp;
}

       
21/01/31 14:45:28 INFO InternalParquetRecordWriter: Flushing mem columnStore to file. allocated memory: 35476460
21/01/31 14:45:33 WARN Executor: Issue communicating with driver in heartbeater
org.apache.spark.rpc.RpcTimeoutException: Futures timed out after [10000 milliseconds]. This timeout is controlled by spark.executor.heartbeatInterval
	at org.apache.spark.rpc.RpcTimeout.org$apache$spark$rpc$RpcTimeout$$createRpcTimeoutException(RpcTimeout.scala:47)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:62)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:58)
	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:38)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:76)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)
	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:913)
	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:200)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1932)
	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.util.concurrent.TimeoutException: Futures timed out after [10000 milliseconds]
	at scala.concurrent.impl.Promise$DefaultPromise.ready(Promise.scala:259)
	at scala.concurrent.impl.Promise$DefaultPromise.result(Promise.scala:263)
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:294)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	... 13 more
21/01/31 14:45:37 WARN TransportResponseHandler: Ignoring response for RPC 4972941576941388231 from /192.168.11.7:57817 (81 bytes) since it is not outstanding
21/01/31 14:45:38 INFO CoarseGrainedExecutorBackend: Driver commanded a shutdown
